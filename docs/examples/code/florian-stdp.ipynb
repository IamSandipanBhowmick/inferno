{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Florian STDP\n",
    "\n",
    "A demonstration replicating a comparison between spike-timing dependent plasticity ([STDP](https://docs.inferno-ai.dev/en/stable/zoo/learning-stdp.html#spike-timing-dependent-plasticity-stdp)), modulated spike-timing dependent plasticity ([MSTDP](https://docs.inferno-ai.dev/en/stable/zoo/learning-stdp.html#modulated-spike-timing-dependent-plasticity-mstdp)), and modulated spike-timing dependent plasticity with eligibility trace ([MSTDPET](https://docs.inferno-ai.dev/en/stable/zoo/learning-stdp.html#modulated-spike-timing-dependent-plasticity-with-eligibility-trace-mstdpet)) given in [10.1162/neco.2007.19.6.1468](https://florian.io/papers/2007_Florian_Modulated_STDP.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inferno\n",
    "from inferno.extra import ExactNeuron\n",
    "from inferno.learn import STDP, MSTDP, MSTDPET\n",
    "from inferno.neural import DeltaCurrent, LinearDirect, Serial\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Training Hyperparameters\n",
    "\n",
    "Here, `lr_post` and `lr_pre` correspond to the amplitude of the spike trace used for calculating the weight update on a postsynaptic spike and presynaptic spike respectively. The time constant for both spike traces is `tc_spike` and for the eligibility trace is `tc_elig`. The weight is initialized to `w_init` and the magnitude of the reward term is `reward_mag`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_post = 0.2\n",
    "lr_pre = -0.2\n",
    "tc_spike = 20.0\n",
    "tc_elig = 25.0\n",
    "w_init = 0.2\n",
    "reward_mag = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the Layers\n",
    "For this example, we're using the [`ExactNeuron`](https://docs.inferno-ai.dev/en/stable/reference/generated/inferno.extra.ExactNeuron.html#inferno.extra.ExactNeuron) provided by `inferno.extra`. This lets us specify the desired output in order to compare STDP, MSTDP, and MSTDPET without needing to concern ourselves with the specific neuronal dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdp_layer = Serial(\n",
    "    LinearDirect(\n",
    "        (1,),\n",
    "        1.0,\n",
    "        synapse=DeltaCurrent.partialconstructor(1.0),\n",
    "        weight_init=lambda x: inferno.full(x, w_init),\n",
    "    ),\n",
    "    ExactNeuron((1,), 1.0, rest_v=-60, thresh_v=-40),\n",
    ")\n",
    "stdp_layer.connection.updater = stdp_layer.connection.defaultupdater()\n",
    "\n",
    "mstdp_layer = Serial(\n",
    "    LinearDirect(\n",
    "        (1,),\n",
    "        1.0,\n",
    "        synapse=DeltaCurrent.partialconstructor(1.0),\n",
    "        weight_init=lambda x: inferno.full(x, w_init),\n",
    "    ),\n",
    "    ExactNeuron((1,), 1.0, rest_v=-60, thresh_v=-40),\n",
    ")\n",
    "mstdp_layer.connection.updater = mstdp_layer.connection.defaultupdater()\n",
    "\n",
    "mstdpet_layer = Serial(\n",
    "    LinearDirect(\n",
    "        (1,),\n",
    "        1.0,\n",
    "        synapse=DeltaCurrent.partialconstructor(1.0),\n",
    "        weight_init=lambda x: inferno.full(x, w_init),\n",
    "    ),\n",
    "    ExactNeuron((1,), 1.0, rest_v=-60, thresh_v=-40),\n",
    ")\n",
    "mstdpet_layer.connection.updater = mstdpet_layer.connection.defaultupdater()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the Trainers\n",
    "\n",
    "For this demo, we'll be using the trainers provided by Inferno: [STDP](https://docs.inferno-ai.dev/en/stable/reference/generated/inferno.learn.STDP.html#inferno.learn.STDP), [MSTDP](https://docs.inferno-ai.dev/en/stable/reference/generated/inferno.learn.MSTDP.html#inferno.learn.MSTDP), and [MSTDPET](https://docs.inferno-ai.dev/en/stable/reference/generated/inferno.learn.MSTDPET.html#inferno.learn.MSTDPET)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdp_trainer = STDP(1.0, lr_post, lr_pre, tc_spike, tc_spike)\n",
    "_ = stdp_trainer.register_cell(\"only\", stdp_layer.cell)\n",
    "\n",
    "mstdp_trainer = MSTDP(1.0, lr_post, lr_pre, tc_spike, tc_spike)\n",
    "_ = mstdp_trainer.register_cell(\"only\", mstdp_layer.cell)\n",
    "\n",
    "mstdpet_trainer = MSTDPET(1.0, lr_post, lr_pre, tc_spike, tc_spike, tc_elig)\n",
    "_ = mstdpet_trainer.register_cell(\"only\", mstdpet_layer.cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Spike and Reward Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presyn_times = [10, 85, 115, 135]\n",
    "postsyn_times = [15, 75, 110, 140]\n",
    "\n",
    "\n",
    "def spikes(step: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    if step in presyn_times:\n",
    "        pre = torch.ones((1, 1), dtype=torch.bool)\n",
    "    else:\n",
    "        pre = torch.zeros((1, 1), dtype=torch.bool)\n",
    "\n",
    "    if step in postsyn_times:\n",
    "        post = torch.ones((1, 1), dtype=torch.bool)\n",
    "    else:\n",
    "        post = torch.zeros((1, 1), dtype=torch.bool)\n",
    "\n",
    "    return pre, post\n",
    "\n",
    "\n",
    "def rewardfn(step: int) -> float:\n",
    "    if step <= 100:\n",
    "        return reward_mag\n",
    "    else:\n",
    "        return -reward_mag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log and Perform the Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = torch.arange(0, 201, 1, dtype=torch.float32)\n",
    "\n",
    "w_stdp = torch.zeros_like(time)\n",
    "w_stdp[0] = w_init\n",
    "w_mstdp = torch.zeros_like(time)\n",
    "w_mstdp[0] = w_init\n",
    "w_mstdpet = torch.zeros_like(time)\n",
    "w_mstdpet[0] = w_init\n",
    "\n",
    "presyn_spikes = torch.tensor(presyn_times, dtype=torch.float32)\n",
    "postsyn_spikes = torch.tensor(postsyn_times, dtype=torch.float32)\n",
    "presyn_trace = torch.zeros_like(time)\n",
    "postsyn_trace = torch.zeros_like(time)\n",
    "\n",
    "elig_trace = torch.zeros_like(time)\n",
    "\n",
    "reward = torch.zeros_like(time)\n",
    "\n",
    "for step in range(1, 201):\n",
    "    # determine pre/post spikes and reward\n",
    "    pre, post = spikes(step)\n",
    "    r = rewardfn(step)\n",
    "\n",
    "    # process inputs\n",
    "    _ = stdp_layer(pre, neuron_kwargs={\"override\": post})\n",
    "    _ = mstdp_layer(pre, neuron_kwargs={\"override\": post})\n",
    "    _ = mstdpet_layer(pre, neuron_kwargs={\"override\": post})\n",
    "\n",
    "    # apply updates\n",
    "    stdp_trainer()\n",
    "    stdp_layer.connection.update()\n",
    "    mstdp_trainer(r)\n",
    "    mstdp_layer.connection.update()\n",
    "    mstdpet_trainer(r)\n",
    "    mstdpet_layer.connection.update()\n",
    "\n",
    "    # record state\n",
    "    w_stdp[step] = stdp_layer.connection.weight.item()\n",
    "    w_mstdp[step] = mstdp_layer.connection.weight.item()\n",
    "    w_mstdpet[step] = mstdpet_layer.connection.weight.item()\n",
    "\n",
    "    presyn_trace[step] = mstdp_trainer.get_monitor(\"only\", \"trace_pre\").peek().item()\n",
    "    postsyn_trace[step] = -mstdp_trainer.get_monitor(\"only\", \"trace_post\").peek().item()\n",
    "\n",
    "    elig_trace[step] = (\n",
    "        mstdpet_trainer.get_monitor(\"only\", \"elig_post\").peek().item()\n",
    "        - mstdpet_trainer.get_monitor(\"only\", \"elig_pre\").peek().item()\n",
    "    )\n",
    "\n",
    "    reward[step] = r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Results\n",
    "\n",
    "Note that if precisely trying to replicate the results from [10.1162/neco.2007.19.6.1468](https://florian.io/papers/2007_Florian_Modulated_STDP.pdf), there may be some difficult as the potentiative and depressive learning rates are incorporated directly into the calculation of eligibility. In order to achieve the exact results described, the postsynaptic and presynaptic learning rates should be set to 1.0 and -1.0 respectively, then the `scale` parameter should be set to the magnitude of the desired learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=8, ncols=1, sharex=True, figsize=(10, 8))\n",
    "\n",
    "axs[0].set_xlim(0, 200)\n",
    "for ax in axs[:-1]:\n",
    "    plt.setp(ax.get_xticklabels(), visible=False)\n",
    "    ax.tick_params(axis='x', which='both', bottom=False)\n",
    "    ax.yaxis.set_label_position(\"right\")\n",
    "axs[-1].yaxis.set_label_position(\"right\")\n",
    "\n",
    "# presyn spikes\n",
    "axs[0].vlines(presyn_spikes.numpy(), 0.0, 1.0, colors=\"tab:purple\")\n",
    "axs[0].set_ylim(0.0, 1.0)\n",
    "axs[0].set_yticks([0.0, 1.0])\n",
    "axs[0].set_ylabel(r\"$s_{pre}$\")\n",
    "\n",
    "# postsyn spikes\n",
    "axs[1].vlines(postsyn_spikes.numpy(), 0.0, 1.0, colors=\"tab:orange\")\n",
    "axs[1].set_ylim(0.0, 1.0)\n",
    "axs[1].set_yticks([0.0, 1.0])\n",
    "axs[1].set_ylabel(r\"$s_{post}$\")\n",
    "\n",
    "# spike trace\n",
    "axs[2].plot(time.numpy(), presyn_trace.numpy(), c=\"tab:purple\")\n",
    "axs[2].plot(time.numpy(), postsyn_trace.numpy(), c=\"tab:orange\")\n",
    "axs[2].set_ylim(-0.4, 0.4)\n",
    "axs[2].set_yticks([-0.4, 0.4])\n",
    "axs[2].set_ylabel(r\"$x_{post}, x_{pre}$\")\n",
    "\n",
    "# reward\n",
    "axs[3].plot(time.numpy(), reward.numpy(), c=\"tab:green\")\n",
    "axs[3].set_ylim(-1.5, 1.5)\n",
    "axs[3].set_yticks([-1.5, 1.5])\n",
    "axs[3].set_ylabel(r\"$r$\")\n",
    "\n",
    "# eligibility trace\n",
    "axs[4].plot(time.numpy(), elig_trace.numpy(), c=\"tab:red\")\n",
    "axs[4].set_ylim(-1e-2, 1e-2)\n",
    "axs[4].set_yticks([-1e-2, 1e-2])\n",
    "axs[4].set_ylabel(r\"$z$\")\n",
    "\n",
    "# weights (updated with STDP)\n",
    "axs[5].plot(time.numpy(), w_stdp.numpy(), c=\"tab:blue\")\n",
    "axs[5].set_ylim(0.0, 0.5)\n",
    "axs[5].set_yticks([0.0, 0.5])\n",
    "axs[5].set_ylabel(r\"$W_{STDP}$\")\n",
    "\n",
    "# weights (updated with MSTDP)\n",
    "axs[6].plot(time.numpy(), w_mstdp.numpy(), c=\"tab:blue\")\n",
    "axs[6].set_ylim(0.0, 0.5)\n",
    "axs[6].set_yticks([0.0, 0.5])\n",
    "axs[6].set_ylabel(r\"$W_{MSTDP}$\")\n",
    "\n",
    "# weights (updated with MSTDPET)\n",
    "axs[7].plot(time.numpy(), w_mstdpet.numpy(), c=\"tab:blue\")\n",
    "axs[7].set_ylim(0.0, 0.5)\n",
    "axs[7].set_yticks([0.0, 0.5])\n",
    "axs[7].set_ylabel(r\"$W_{MSTDPET}$\")\n",
    "axs[7].set_xlabel(r\"Time (ms)\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infernodev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
