<!doctype html>
<html class="no-js" lang="en" data-content_root="">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" />

    <!-- Generated with Sphinx 7.1.2 and Furo 2024.01.29 -->
        <title>inferno.core.infrastructure - Inferno</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=362ab14a" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=eafc0fe6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo-extensions.css?v=36a5483c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/shape.css?v=23eccd26" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../index.html"><div class="brand">Inferno</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../../index.html">
  
  
  <span class="sidebar-brand-text">Inferno</span>
  
</a><form class="sidebar-search-container" method="get" action="../../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../reference/index.html">API Reference</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of API Reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/inferno.html">inferno</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/functional.html">inferno.functional</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/neural.html">inferno.neural</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/neural-functional.html">inferno.neural.functional</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/learn.html">inferno.learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/observe.html">inferno.observe</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/stats.html">inferno.stats</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../guide/index.html">Guidebook</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Guidebook</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../guide/mathematics.html">Mathematical Notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../guide/neurons.html">Neurons and Neuronal Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../guide/considerations.html">Pragmatic Considerations</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../zoo/index.html">Model and Method Zoo</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Model and Method Zoo</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../zoo/neurons-adaptation.html">Neuronal Adaptation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../zoo/neurons-linear.html">Neuron Models, Linear</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../zoo/neurons-nonlinear.html">Neuron Models, Nonlinear</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../zoo/synapses-current.html">Synapse Models, Current-Based</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../zoo/synapses-conductance.html">Synapse Models, Conductance-Based</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../zoo/learning-stdp.html">STDP-Like Learning Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../zoo/learning-resume.html">ReSuMe-Like Learning Methods</a></li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <h1>Source code for inferno.core.infrastructure</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>
<span class="kn">from</span> <span class="nn">.tensor</span> <span class="kn">import</span> <span class="n">empty</span><span class="p">,</span> <span class="n">full</span><span class="p">,</span> <span class="n">zeros</span>
<span class="kn">from</span> <span class="nn">..functional</span> <span class="kn">import</span> <span class="n">Interpolation</span><span class="p">,</span> <span class="n">Extrapolation</span><span class="p">,</span> <span class="n">interp_nearest</span><span class="p">,</span> <span class="n">extrap_nearest</span>
<span class="kn">from</span> <span class="nn">.._internal</span> <span class="kn">import</span> <span class="n">argtest</span><span class="p">,</span> <span class="n">rsetattr</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span><span class="p">,</span> <span class="n">OrderedDict</span>
<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Iterable</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">cache</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">chain</span><span class="p">,</span> <span class="n">repeat</span><span class="p">,</span> <span class="n">starmap</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span>
<span class="kn">import</span> <span class="nn">weakref</span>


<div class="viewcode-block" id="Module"><a class="viewcode-back" href="../../../reference/generated/inferno.Module.html#inferno.Module">[docs]</a><span class="k">class</span> <span class="nc">Module</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;An extension of PyTorch&#39;s Module class.</span>

<span class="sd">    This extends :py:class:`torch.nn.Module` so that &quot;extra state&quot; is handled in a way</span>
<span class="sd">    similar to regular tensor state (e.g. buffers and parameters). This enables simple</span>
<span class="sd">    export to and import from a state dictionary. This does not enforce exact matching</span>
<span class="sd">    keys, and will insert new keys as required.</span>

<span class="sd">    Additionally, attribute assignment will check if the name refers to a property in</span>
<span class="sd">    the class and if so, uses ``object.__setattr__``.</span>

<span class="sd">    Note:</span>
<span class="sd">        Like with :py:class:`torch.nn.Module`, an :py:meth:`__init__` call must be made</span>
<span class="sd">        to the parent class before assignment on the child. This class&#39;s constructor</span>
<span class="sd">        will automatically call PyTorch&#39;s.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_extras</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>

<div class="viewcode-block" id="Module.register_extra"><a class="viewcode-back" href="../../../reference/generated/inferno.Module.html#inferno.Module.register_extra">[docs]</a>    <span class="k">def</span> <span class="nf">register_extra</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Any</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds an extra variable to the module.</span>

<span class="sd">        This is typically used in a manner to</span>
<span class="sd">        :py:meth:`~torch.nn.Module.register_buffer`, except that the value being</span>
<span class="sd">        registered is not limited to being a :py:class:`~torch.Tensor`.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str): name of the extra, which can be accessed from this module</span>
<span class="sd">                using the provided name.</span>
<span class="sd">            value (Any): extra to be registered.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: extra name has to be a string.</span>
<span class="sd">            KeyError: extra name cannot be the empty string and cannot contain &quot;.&quot;.</span>
<span class="sd">            TypeError: extras cannot be instances of :py:class:`~torch.Tensor` or</span>
<span class="sd">                :py:class:`~torch.nn.Module`.</span>

<span class="sd">        Important:</span>
<span class="sd">            In order to be accessed with dot notation, the name must be a valid</span>
<span class="sd">            Python identifier.</span>

<span class="sd">        Note:</span>
<span class="sd">            :py:class:`~torch.Tensor`, :py:class:`~torch.nn.Parameter`, and</span>
<span class="sd">            :py:class:`~torch.nn.Module` objects cannot be registered as extras and</span>
<span class="sd">            should be registered using existing methods.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;extra name must be a string, received </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">name</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="s2">&quot;.&quot;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;extra name cannot contain &#39;.&#39;&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;extra name cannot be empty string &#39;&#39;&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extras</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;attribute &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39; already exists&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;cannot assign &#39;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">&#39; object to &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_extras</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span></div>

<div class="viewcode-block" id="Module.get_extra"><a class="viewcode-back" href="../../../reference/generated/inferno.Module.html#inferno.Module.get_extra">[docs]</a>    <span class="k">def</span> <span class="nf">get_extra</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the extra given by ``target`` if it exists, otherwise throws an error.</span>

<span class="sd">        This functions similarly to, and has the same specification of ``target`` as</span>
<span class="sd">        :py:meth:`~torch.nn.Module.get_submodule`.</span>

<span class="sd">        Args:</span>
<span class="sd">            target (str): fully-qualified string name of the extra for which to look.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Any: the extra referenced ``target``.</span>

<span class="sd">        Raises:</span>
<span class="sd">            AttributeError: if the target string references an invalid path, the</span>
<span class="sd">                terminal module is an instance of :py:class:`torch.nn.Module` but not</span>
<span class="sd">                :py:class:`Module`, or resolves to something that is not an extra.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">module_path</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">extra_name</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">rpartition</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>

        <span class="n">module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_submodule</span><span class="p">(</span><span class="n">module_path</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">Module</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">module</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> &quot;</span> <span class="s2">&quot;is not an inferno Module&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">extra_name</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">module</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> &quot;</span> <span class="sa">f</span><span class="s2">&quot;has no attribute &#39;</span><span class="si">{</span><span class="n">extra_name</span><span class="si">}</span><span class="s2">&#39;&quot;</span>
            <span class="p">)</span>

        <span class="n">extra</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">extra_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">extra_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">_extras</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`</span><span class="si">{</span><span class="n">extra_name</span><span class="si">}</span><span class="s2">` is not an extra&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">extra</span></div>

<div class="viewcode-block" id="Module.get_extra_state"><a class="viewcode-back" href="../../../reference/generated/inferno.Module.html#inferno.Module.get_extra_state">[docs]</a>    <span class="k">def</span> <span class="nf">get_extra_state</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extras</span></div>

<div class="viewcode-block" id="Module.set_extra_state"><a class="viewcode-back" href="../../../reference/generated/inferno.Module.html#inferno.Module.set_extra_state">[docs]</a>    <span class="k">def</span> <span class="nf">set_extra_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_extras</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="k">if</span> <span class="s2">&quot;_extras&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_extras</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__setstate__</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;_extras&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">:</span>
            <span class="n">_extras</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_extras&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">_extras</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">_extras</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>

        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getattr__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># intercept parameter and module assignments</span>
        <span class="n">descriptor</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="n">name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">descriptor</span><span class="p">,</span> <span class="nb">property</span><span class="p">)</span>
            <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">descriptor</span><span class="p">,</span> <span class="s2">&quot;__get__&quot;</span><span class="p">)</span>
            <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">descriptor</span><span class="p">,</span> <span class="s2">&quot;__set__&quot;</span><span class="p">)</span>
            <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">descriptor</span><span class="p">,</span> <span class="s2">&quot;__delete__&quot;</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">descriptor</span><span class="o">.</span><span class="fm">__set__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_extras</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;_extras&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">_extras</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">_extras</span><span class="p">:</span>
                <span class="n">_extras</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__delattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extras</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extras</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__delattr__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__dir__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">module_attrs</span> <span class="o">=</span> <span class="nb">dir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">)</span>
        <span class="n">attrs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">modules</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">buffers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">extras</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_extras</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="n">module_attrs</span> <span class="o">+</span> <span class="n">attrs</span> <span class="o">+</span> <span class="n">parameters</span> <span class="o">+</span> <span class="n">modules</span> <span class="o">+</span> <span class="n">buffers</span> <span class="o">+</span> <span class="n">extras</span>

        <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span> <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">isidentifier</span><span class="p">()]</span>

        <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span></div>


<div class="viewcode-block" id="DimensionalModule"><a class="viewcode-back" href="../../../reference/generated/inferno.DimensionalModule.html#inferno.DimensionalModule">[docs]</a><span class="k">class</span> <span class="nc">DimensionalModule</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Module with support for dimensionally constrained buffers and parameters.</span>

<span class="sd">    Args:</span>
<span class="sd">        *constraints (tuple[int, int]): tuple of (dim, size) dimensional constraints</span>
<span class="sd">            for constrained buffers and parameters.</span>
<span class="sd">        live (bool, optional): if constraints should be evaluated on constrained</span>
<span class="sd">            attribute set. Defaults to False.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: size specified by each constraint must be positive.</span>
<span class="sd">        RuntimeError: two or more constraints have the same dimension.</span>

<span class="sd">    Caution:</span>
<span class="sd">        The names of constrained buffers and parameters will persist via the</span>
<span class="sd">        state dictionary but the constraints themselves will not.</span>

<span class="sd">    Important:</span>
<span class="sd">        The constraints given must refer to unique elements. For example, if a</span>
<span class="sd">        constraint is placed on the dim ``1`` and dim ``-1``, a tensor must be at</span>
<span class="sd">        least three-dimensional, since in a tensor with two dimensions, ``1`` and</span>
<span class="sd">        ``-1`` refer to the same dimension.</span>

<span class="sd">    Important:</span>
<span class="sd">        Constrained values which are either ``None``, scalar (i.e. have zero</span>
<span class="sd">        dimensions), or have no elements (i.e. have a zero-dimension) are</span>
<span class="sd">        automatically ignored.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">constraints</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">live</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="c1"># setter-dependent attribute</span>
        <span class="nb">object</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_live_assert&quot;</span><span class="p">,</span> <span class="n">live</span><span class="p">)</span>

        <span class="c1"># call superclass constructor</span>
        <span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="c1"># transient state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="c1"># persistent state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_extra</span><span class="p">(</span><span class="s2">&quot;_constrained_buffers&quot;</span><span class="p">,</span> <span class="nb">set</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_extra</span><span class="p">(</span><span class="s2">&quot;_constrained_params&quot;</span><span class="p">,</span> <span class="nb">set</span><span class="p">())</span>

        <span class="c1"># cached values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_constraint_cache</span> <span class="o">=</span> <span class="n">cache</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_calc_constraints</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_extra_repr_cache</span> <span class="o">=</span> <span class="n">cache</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_calc_extra_repr</span><span class="p">)</span>

        <span class="c1"># check for consistent constraints</span>
        <span class="k">for</span> <span class="n">d</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">constraints</span><span class="p">:</span>
            <span class="n">dim</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">d</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">size</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;constraint </span><span class="si">{</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span><span class="si">}</span><span class="s2"> specifies an invalid (nonpositive) &quot;</span>
                    <span class="s2">&quot;number of elements&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">dim</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;constraint </span><span class="si">{</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span><span class="si">}</span><span class="s2"> conflicts with constraint &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">[</span><span class="n">dim</span><span class="p">])</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_ignore_tensor</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Checks if a tensor should be ignored for constraints.</span>

<span class="sd">        Args:</span>
<span class="sd">            tensor (torch.Tensor | nn.Parameter | None): tensor to check.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool: if the tensor should be ignored.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">tensor</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ndim</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">liveconstrain</span>
            <span class="ow">and</span> <span class="p">(</span><span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_buffers</span> <span class="ow">or</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_params</span><span class="p">)</span>
            <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore_tensor</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">compatible</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
                <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;tensor of shape </span><span class="si">{</span><span class="nb">tuple</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s2"> being assigned to &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39; &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;is not compatible with constraints (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_extra_repr_cache</span><span class="p">()</span><span class="si">}</span><span class="s2">)&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

<div class="viewcode-block" id="DimensionalModule.dims_"><a class="viewcode-back" href="../../../reference/generated/inferno.DimensionalModule.html#inferno.DimensionalModule.dims_">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">dims_</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">constraints</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes minimum number of required dimensions for a constrained tensor.</span>

<span class="sd">        Args:</span>
<span class="sd">            constraints (dict[int, int]): constraint dictionary of (dim, size).</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: minimum required number of dimensions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">constraints</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>

        <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">constraints</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="nb">min</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">constraints</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span></div>

<div class="viewcode-block" id="DimensionalModule.compatible_"><a class="viewcode-back" href="../../../reference/generated/inferno.DimensionalModule.html#inferno.DimensionalModule.compatible_">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">compatible_</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">constraints</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Test if a tensor is compatible with a set of constraints.</span>

<span class="sd">        Args:</span>
<span class="sd">            tensor (torch.Tensor): value to test.</span>
<span class="sd">            constraints (dict[int, int]): constraint dictionary of (dim, size).</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool: if the tensor is compatible.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># check if the tensor has the minimum dimensionality</span>
        <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;</span> <span class="bp">cls</span><span class="o">.</span><span class="n">dims_</span><span class="p">(</span><span class="n">constraints</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="c1"># test all constraints</span>
        <span class="k">for</span> <span class="n">dim</span><span class="p">,</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">constraints</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">!=</span> <span class="n">size</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>

        <span class="k">return</span> <span class="kc">True</span></div>

<div class="viewcode-block" id="DimensionalModule.compatible_like_"><a class="viewcode-back" href="../../../reference/generated/inferno.DimensionalModule.html#inferno.DimensionalModule.compatible_like_">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">compatible_like_</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Creates a shape or new tensor like the input compatible with a set of constraints.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (torch.Tensor | nn.Parameter | Iterable[int]): _description_</span>
<span class="sd">            constraints (dict[int, int]): constraint dictionary of (dim, size).</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: given shape does not have sufficient dimensionality to be</span>
<span class="sd">                made compatible with constraints.</span>
<span class="sd">            ValueError: size specified by each constraint must be positive.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | nn.Parameter | tuple[int, ...]: new tensor or parameter like</span>
<span class="sd">            the input, or the new compatible shape if not given a tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># put original shape into a mutable</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="k">else</span> <span class="nb">list</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

        <span class="c1"># ensure minimum dimensionality</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">cls</span><span class="o">.</span><span class="n">dims_</span><span class="p">(</span><span class="n">constraints</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;value&#39; of shape </span><span class="si">{</span><span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s2"> with </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s2"> dims cannot be made &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;compatible, requires a minimum dimensionality of </span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="n">dims_</span><span class="p">(</span><span class="n">constraints</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># set new sizes via constraints</span>
        <span class="k">for</span> <span class="n">d</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">constraints</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">s</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;&#39;constraints&#39; specifies nonpositive sized constraint </span><span class="si">{</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">shape</span><span class="p">[</span><span class="n">d</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span>

        <span class="c1"># create a zero-valued tensor or parameter like the input if given a tensor</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                    <span class="n">shape</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                    <span class="n">layout</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">layout</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="n">requires_grad</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">requires_grad</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="n">shape</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">layout</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">layout</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">requires_grad</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">constraints</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Returns the constraint dictionary, sorted by dimension.</span>

<span class="sd">        The results will be sorted by dimension, from first to last. Therefore,</span>
<span class="sd">        positive dimensions are presented first, in increasing order, then negative</span>
<span class="sd">        dimensions also in increasing order.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict[int, int]: active constraints, represented as a dictionary.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constraint_cache</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dims</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Minimum number of required dimensions for a constrained tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: minimum required number of dimensions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dims_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">liveconstrain</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;If constraints should be enforced on attribute assignment.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (bool): if constraints should be enforced on attribute assignment.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool: if constraints should be enforced on attribute assignment.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_live_assert</span>

    <span class="nd">@liveconstrain</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">liveconstrain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_live_assert</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

<div class="viewcode-block" id="DimensionalModule.extra_repr"><a class="viewcode-back" href="../../../reference/generated/inferno.DimensionalModule.html#inferno.DimensionalModule.extra_repr">[docs]</a>    <span class="k">def</span> <span class="nf">extra_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;constraints=(</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_extra_repr_cache</span><span class="p">()</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot;constrained_buffers=(</span><span class="si">{</span><span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_constrained_buffers</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">,</span>
                <span class="sa">f</span><span class="s2">&quot;constrained_parameters=(</span><span class="si">{</span><span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_constrained_params</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_calc_constraints</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Calculates sorted constraints for the cache.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict[int, int]: active constraints, represented as a dictionary.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">fwd</span><span class="p">,</span> <span class="n">rev</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">dim</span><span class="p">,</span> <span class="n">size</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
            <span class="n">rev</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">dim</span><span class="p">,</span> <span class="n">size</span><span class="p">))</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">fwd</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">dim</span><span class="p">,</span> <span class="n">size</span><span class="p">))</span>

        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">fwd</span> <span class="o">+</span> <span class="n">rev</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_calc_extra_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Calculates the extra representation layout of constraints.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: extra representation format of constraints.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># split constraints into forward and reverse (negative) indices, sorted</span>
        <span class="n">fwd</span><span class="p">,</span> <span class="n">rev</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">dim</span><span class="p">,</span> <span class="n">size</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
            <span class="n">rev</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">dim</span><span class="p">,</span> <span class="n">size</span><span class="p">))</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">fwd</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">dim</span><span class="p">,</span> <span class="n">size</span><span class="p">))</span>

        <span class="c1"># representation elements</span>
        <span class="n">elems</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># forward indexed constraints</span>
        <span class="c1"># expect dimension 0</span>
        <span class="n">expc</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">dim</span><span class="p">,</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">fwd</span><span class="p">:</span>
            <span class="c1"># add unconstrained placeholders</span>
            <span class="n">elems</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s2">&quot;_&quot;</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dim</span> <span class="o">-</span> <span class="n">expc</span><span class="p">)])</span>
            <span class="c1"># add contraint value</span>
            <span class="n">elems</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="c1"># set expected next dimension</span>
            <span class="n">expc</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># aribtrary separation</span>
        <span class="n">elems</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;...&quot;</span><span class="p">)</span>

        <span class="c1"># reverse indexed constraints</span>
        <span class="c1"># no expected dimension</span>
        <span class="n">expc</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">dim</span><span class="p">,</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">rev</span><span class="p">:</span>
            <span class="c1"># add unconstrained placeholders</span>
            <span class="k">if</span> <span class="n">expc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">elems</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s2">&quot;_&quot;</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dim</span> <span class="o">-</span> <span class="n">expc</span><span class="p">)])</span>
            <span class="c1"># add contraint value</span>
            <span class="n">elems</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="c1"># set expected next dimension</span>
            <span class="n">expc</span> <span class="o">=</span> <span class="n">dim</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="c1"># final cases</span>
        <span class="k">if</span> <span class="n">expc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">elems</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s2">&quot;_&quot;</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">expc</span><span class="p">,</span> <span class="mi">0</span><span class="p">)])</span>

        <span class="k">return</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">elems</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_trim_constrained</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Deletes constrained buffers and parameters which no longer exist.&quot;&quot;&quot;</span>
        <span class="c1"># remove deleted buffers from constrained set</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_constrained_buffers</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">deregister_constrained</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

        <span class="c1"># remove deleted parameters from constrained set</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_constrained_params</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_parameter</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">deregister_constrained</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_test_constrained</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Validates constraints.&quot;&quot;&quot;</span>
        <span class="c1"># ensure constrained buffers have valid shape</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">map</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="n">n</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_buffers</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ignore_tensor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">compatible</span><span class="p">(</span><span class="n">b</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;constrained buffer &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39; is invalid&quot;</span><span class="p">)</span>

        <span class="c1"># ensure constrained parameters have valid shape</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">map</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_parameter</span><span class="p">(</span><span class="n">n</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_params</span>
        <span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ignore_tensor</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">compatible</span><span class="p">(</span><span class="n">p</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;constrained parameter &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39; is invalid&quot;</span><span class="p">)</span>

<div class="viewcode-block" id="DimensionalModule.compatible"><a class="viewcode-back" href="../../../reference/generated/inferno.DimensionalModule.html#inferno.DimensionalModule.compatible">[docs]</a>    <span class="k">def</span> <span class="nf">compatible</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Test if a tensor is compatible with the constraints.</span>

<span class="sd">        Args:</span>
<span class="sd">            tensor (torch.Tensor): value to test.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool: if the tensor is compatible.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">compatible_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">)</span></div>

<div class="viewcode-block" id="DimensionalModule.compatible_like"><a class="viewcode-back" href="../../../reference/generated/inferno.DimensionalModule.html#inferno.DimensionalModule.compatible_like">[docs]</a>    <span class="k">def</span> <span class="nf">compatible_like</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Creates a shape or new tensor like the input compatible with the constraints.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (torch.Tensor | nn.Parameter | Iterable[int]): _description_</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | nn.Parameter | tuple[int, ...]: new tensor or parameter like</span>
<span class="sd">            the input, or the new compatible shape if not given a tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">compatible_like_</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">)</span></div>

<div class="viewcode-block" id="DimensionalModule.reconstrain"><a class="viewcode-back" href="../../../reference/generated/inferno.DimensionalModule.html#inferno.DimensionalModule.reconstrain">[docs]</a>    <span class="k">def</span> <span class="nf">reconstrain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DimensionalModule</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Modifies constraints.</span>

<span class="sd">        Adding constraints will not modify the constrained tensors, whereas modifying</span>
<span class="sd">        an existing constraint will create a new zero-tensor with the shape of that</span>
<span class="sd">        dimension modified.</span>

<span class="sd">        If the tensor was modified to be compatible with the new constraint ahead</span>
<span class="sd">        of time (i.e. if :py:attr:`liveconstrain` is ``False`` and was set with its new value),</span>
<span class="sd">        then reallocation will not occur.</span>

<span class="sd">        Args:</span>
<span class="sd">            dim (int): dimension to which a constraint should be added, removed,</span>
<span class="sd">                or modified.</span>
<span class="sd">            size (int | None): size of the new constraint, None if the constraint is</span>
<span class="sd">                to be removed.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: constrained buffer or parameter is no longer a compatible shape.</span>
<span class="sd">            RuntimeError: constrained buffer or parameter would not be valid after the</span>
<span class="sd">                change in constraints.</span>

<span class="sd">        Returns:</span>
<span class="sd">            DimensionalModule: self.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># clear cached values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_constraint_cache</span><span class="o">.</span><span class="n">cache_clear</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_extra_repr_cache</span><span class="o">.</span><span class="n">cache_clear</span><span class="p">()</span>

        <span class="c1"># remove deleted buffers and parameters from constrained set</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_trim_constrained</span><span class="p">()</span>

        <span class="c1"># cast and validate arguments</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="n">size</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">argtest</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="s2">&quot;size&quot;</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>

        <span class="c1"># removes constraint</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">size</span><span class="p">:</span>
            <span class="c1"># removes constraint</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>

            <span class="c1"># tests if constrained buffers and parameters are still valid</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_test_constrained</span><span class="p">()</span>

            <span class="c1"># returns self</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="c1"># creates constraint</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span> <span class="ow">and</span> <span class="n">size</span><span class="p">:</span>
            <span class="c1"># ensures constrained values are still valid</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_test_constrained</span><span class="p">()</span>

            <span class="c1"># tests if buffers and parameters will be valid with new constraints</span>
            <span class="n">cns</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="n">size</span><span class="p">}</span>

            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">map</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="n">n</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_buffers</span>
            <span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ignore_tensor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">compatible_</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">cns</span><span class="p">)):</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;constrained buffer &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39; would be invalidated by the &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;addition of constraint </span><span class="si">{</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">map</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_parameter</span><span class="p">(</span><span class="n">n</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_params</span>
            <span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ignore_tensor</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">compatible_</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">cns</span><span class="p">)):</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;constrained parameter &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39; would be invalidated by the &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;addition of constraint </span><span class="si">{</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

            <span class="c1"># adds constraint</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span>

            <span class="c1"># returns self</span>
            <span class="k">return</span> <span class="bp">self</span>

        <span class="c1"># alters constraint</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span> <span class="ow">and</span> <span class="n">size</span><span class="p">:</span>
            <span class="c1"># check that all tensors have minimum required dimensionality</span>
            <span class="n">ndim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dims</span>

            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">map</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="n">n</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_buffers</span>
            <span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ignore_tensor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="ow">or</span> <span class="n">b</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;=</span> <span class="n">ndim</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;constrained buffer &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39; with </span><span class="si">{</span><span class="n">b</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2"> dims cannot be made &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;compatible, requires a minimum dimensionality of </span><span class="si">{</span><span class="n">ndim</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">map</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_parameter</span><span class="p">(</span><span class="n">n</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_params</span>
            <span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ignore_tensor</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="ow">or</span> <span class="n">p</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;=</span> <span class="n">ndim</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;constrained parameter &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39; with </span><span class="si">{</span><span class="n">p</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2"> dims cannot be made &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;compatible, requires a minimum dimensionality of </span><span class="si">{</span><span class="n">ndim</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

            <span class="c1"># edit constraint</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_constraints</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span>

            <span class="c1"># reassign incompatible parameters</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">chain</span><span class="p">(</span>
                <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="n">n</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_buffers</span><span class="p">),</span>
                <span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">n</span><span class="p">:</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_parameter</span><span class="p">(</span><span class="n">n</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_params</span><span class="p">),</span>
            <span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ignore_tensor</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">compatible</span><span class="p">(</span><span class="n">value</span><span class="p">)):</span>
                    <span class="n">rsetattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">compatible_like</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>

            <span class="c1"># returns self</span>
            <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="DimensionalModule.register_constrained"><a class="viewcode-back" href="../../../reference/generated/inferno.DimensionalModule.html#inferno.DimensionalModule.register_constrained">[docs]</a>    <span class="k">def</span> <span class="nf">register_constrained</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registers an existing buffer or parameter as constrained.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str): fully-qualified string name of the buffer or</span>
<span class="sd">                parameter to register.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: shape of the buffer or parameter is invalid.</span>
<span class="sd">            AttributeError: attribute is not a registered buffer or parameter.</span>

<span class="sd">        Caution:</span>
<span class="sd">            A registered :py:class:`~torch.nn.Parameter` with a value of ``None``</span>
<span class="sd">            cannot be constrained as it is not returned by</span>
<span class="sd">            :py:meth:`~torch.nn.Module.get_parameter`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># attempts to register buffer</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ignore_tensor</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">compatible</span><span class="p">(</span><span class="n">b</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;buffer &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39; has shape of </span><span class="si">{</span><span class="nb">tuple</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;incompatible with constrained shape (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_extra_repr_cache</span><span class="p">()</span><span class="si">}</span><span class="s2">), &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;dimensions must match and &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39; must have at least &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dims</span><span class="si">}</span><span class="s2"> dimensions&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_buffers</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="c1"># attempts to register parameter</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_parameter</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_ignore_tensor</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">compatible</span><span class="p">(</span><span class="n">p</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;parameter &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39; has shape of </span><span class="si">{</span><span class="nb">tuple</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;incompatible with constrained shape (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_extra_repr_cache</span><span class="p">()</span><span class="si">}</span><span class="s2">), &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;dimensions must match and &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39; must have at least &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dims</span><span class="si">}</span><span class="s2"> dimensions&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_params</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="c1"># invalid name</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;&#39;nam&#39;` (&#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;) does not specify a registered buffer or parameter&quot;</span>
        <span class="p">)</span></div>

<div class="viewcode-block" id="DimensionalModule.deregister_constrained"><a class="viewcode-back" href="../../../reference/generated/inferno.DimensionalModule.html#inferno.DimensionalModule.deregister_constrained">[docs]</a>    <span class="k">def</span> <span class="nf">deregister_constrained</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Deregisters a buffer or parameter as constrained.</span>

<span class="sd">        If the name given isn&#39;t a constrained buffer or parameter, calling this does</span>
<span class="sd">        nothing.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str): fully-qualified string name of the buffer or</span>
<span class="sd">                parameter to register.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># remove if in buffers</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_buffers</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_buffers</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

        <span class="c1"># remove if in parameters</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_params</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_params</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">name</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">get_constrained</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">:</span>
        <span class="c1"># retrieve from buffers</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_buffers</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

        <span class="c1"># retrieve from parameters</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constrained_params</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_parameter</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;&#39;name&#39; (&#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;) is not a constrained buffer or parameter&quot;</span>
        <span class="p">)</span>

<div class="viewcode-block" id="DimensionalModule.validate"><a class="viewcode-back" href="../../../reference/generated/inferno.DimensionalModule.html#inferno.DimensionalModule.validate">[docs]</a>    <span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Validates constraints.</span>

<span class="sd">        Along with testing constrained buffers and parameters, if a registered</span>
<span class="sd">        constrained name no longer points at a buffer or parameter, that name is removed.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: constrained buffer or parameter is no longer valid.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_trim_constrained</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_test_constrained</span><span class="p">()</span></div></div>


<span class="k">def</span> <span class="nf">_constraint_dimensionality</span><span class="p">(</span><span class="n">constraints</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes the minimum dimensionality for a set of constraints.</span>

<span class="sd">    Args:</span>
<span class="sd">        constraints (dict[int, int]): dictionary of constraints.</span>
<span class="sd">        strict (bool): if constraints should be applied strictly.</span>

<span class="sd">    Returns:</span>
<span class="sd">        int: minimum number of dimensions for a constrained tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">constraints</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">elif</span> <span class="n">strict</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">constraints</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="nb">min</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">constraints</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">constraints</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">abs</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">constraints</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">_constraints_compatible</span><span class="p">(</span>
    <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">,</span> <span class="n">constraints</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Tests if a tensor is compatible with constraints.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor (torch.Tensor | nn.Parameter): tensor to test for compatibility.</span>
<span class="sd">        constraints (dict[int, int]): dictionary of constraints.</span>
<span class="sd">        strict (bool): if constraints should be applied strictly.</span>

<span class="sd">    Returns:</span>
<span class="sd">        bool: if the tensor is valid under the dimensional constraints.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;</span> <span class="n">_constraint_dimensionality</span><span class="p">(</span><span class="n">constraints</span><span class="p">,</span> <span class="n">strict</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">all</span><span class="p">(</span>
            <span class="n">starmap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">d</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span> <span class="n">shape</span><span class="p">[</span><span class="n">d</span><span class="p">]</span> <span class="o">==</span> <span class="n">s</span><span class="p">,</span> <span class="n">constraints</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">_constraints_consistent</span><span class="p">(</span><span class="n">constraints</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">ndims</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Tests if constraints will not conflict.</span>

<span class="sd">    When constraints are applied strictly, the constraints must be consistent regardless</span>
<span class="sd">    of the exact sizes. Otherwise, this must check for consistency since specific</span>
<span class="sd">    sizes may create impossible constraints.</span>

<span class="sd">    Args:</span>
<span class="sd">        constraints (dict[int, int]): dictionary of constraints.</span>
<span class="sd">        ndims (int): dimensionality of the tensor to constrain.</span>

<span class="sd">    Returns:</span>
<span class="sd">        bool: if a tensor of given dimensionality can be constrained consistently.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">hypoth</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">repeat</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">times</span><span class="o">=</span><span class="n">ndims</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">dim</span><span class="p">,</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">constraints</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">hypoth</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">hypoth</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span>
        <span class="k">elif</span> <span class="n">hypoth</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">==</span> <span class="n">size</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

    <span class="k">return</span> <span class="kc">True</span>


<span class="k">def</span> <span class="nf">_shapedtensor_finalization</span><span class="p">(</span><span class="n">owner</span><span class="p">:</span> <span class="n">weakref</span><span class="o">.</span><span class="n">ReferenceType</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Finalizer function for ShapedTensor.&quot;&quot;&quot;</span>
    <span class="n">owner</span> <span class="o">=</span> <span class="n">owner</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">owner</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_data&quot;</span><span class="p">):</span>
            <span class="nb">delattr</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_data&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_constraints&quot;</span><span class="p">):</span>
            <span class="nb">delattr</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_constraints&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="ShapedTensor"><a class="viewcode-back" href="../../../reference/generated/inferno.ShapedTensor.html#inferno.ShapedTensor">[docs]</a><span class="k">class</span> <span class="nc">ShapedTensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Tensor attribute with constrained shape.</span>

<span class="sd">    Some states for ``value`` are ignored for convenience. If it is ``None``,</span>
<span class="sd">    an instance of either :py:class:`~torch.nn.UninitializedBuffer` or</span>
<span class="sd">    :py:class:`~torch.nn.UninitializedParameter`, or has no elements and only a single</span>
<span class="sd">    dimension (such as if created with ``torch.empty(0)``).</span>

<span class="sd">    When ``value`` is ``None``, a registered buffer is created, otherwise a parameter</span>
<span class="sd">    will only be added if an :py:class:`~torch.nn.Parameter` is given. Assignment of</span>
<span class="sd">    a parameter to ``None`` is unsupported.</span>

<span class="sd">    Args:</span>
<span class="sd">        owner (Module): module to which this attribute will belong.</span>
<span class="sd">        name (str): name of the attribute.</span>
<span class="sd">        value (torch.Tensor | nn.Parameter | None): tensor-like data for the attribute.</span>
<span class="sd">        constraints (dict[int, int] | None, optional): constraints given as a</span>
<span class="sd">            dictionary of dimensions to their corresponding size. Defaults to None.</span>
<span class="sd">        persist_data (bool, optional): if the data should persist across the</span>
<span class="sd">            state dictionary, only used with buffers. Defaults to True.</span>
<span class="sd">        persist_constraints (bool, optional): if the constraints should persist</span>
<span class="sd">            across the state dictionary. Defaults to False.</span>
<span class="sd">        strict (bool, optional): if each dimension must specify a unique dimension</span>
<span class="sd">            for the tensor. Defaults to True.</span>
<span class="sd">        live (bool, optional): if constraint validity should be tested on</span>
<span class="sd">            assignment. Defaults to False.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: given data is neither ignored nor compatible with given</span>
<span class="sd">            constraints.</span>

<span class="sd">    Caution:</span>
<span class="sd">        This has a finalizer which will delete the attributes added to the module when</span>
<span class="sd">        its reference count goes to zero.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">LinkedAttributes</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">&quot;ShapedTensorAttributes&quot;</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;constraints&quot;</span><span class="p">))</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">owner</span><span class="p">:</span> <span class="n">Module</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">persist_data</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">persist_constraints</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">live</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># ensure the name is a valid identifier</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">identifier</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>

        <span class="c1"># internal state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__owner</span> <span class="o">=</span> <span class="n">weakref</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="n">owner</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__strict</span> <span class="o">=</span> <span class="n">strict</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__live</span> <span class="o">=</span> <span class="n">live</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__finalizer</span> <span class="o">=</span> <span class="n">weakref</span><span class="o">.</span><span class="n">finalize</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">_shapedtensor_finalization</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__owner</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__name</span>
        <span class="p">)</span>

        <span class="c1"># create constraints dictionary</span>
        <span class="n">constraints</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">constraints</span><span class="p">)</span> <span class="k">if</span> <span class="n">constraints</span> <span class="k">else</span> <span class="p">{}</span>

        <span class="c1"># invalid initial constraints</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="ow">or</span> <span class="n">_constraints_compatible</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">constraints</span><span class="p">,</span> <span class="n">strict</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;initial value of shape </span><span class="si">{</span><span class="nb">tuple</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s2"> is not compatible with &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;constraints: </span><span class="si">{</span><span class="nb">tuple</span><span class="p">(</span><span class="n">constraints</span><span class="o">.</span><span class="n">items</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># registered attribute names</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span> <span class="o">=</span> <span class="n">ShapedTensor</span><span class="o">.</span><span class="n">LinkedAttributes</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__name</span><span class="si">}</span><span class="s2">_data&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__name</span><span class="si">}</span><span class="s2">_constraints&quot;</span>
        <span class="p">)</span>

        <span class="c1"># register data</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">):</span>
            <span class="n">owner</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">persistent</span><span class="o">=</span><span class="n">persist_data</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

        <span class="c1"># register constraints</span>
        <span class="k">if</span> <span class="n">persist_constraints</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="n">Module</span><span class="p">):</span>
            <span class="n">owner</span><span class="o">.</span><span class="n">register_extra</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">constraints</span><span class="p">,</span> <span class="n">constraints</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">constraints</span><span class="p">,</span> <span class="n">constraints</span><span class="p">)</span>

<div class="viewcode-block" id="ShapedTensor.create"><a class="viewcode-back" href="../../../reference/generated/inferno.ShapedTensor.html#inferno.ShapedTensor.create">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">create</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">owner</span><span class="p">:</span> <span class="n">Module</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">persist_data</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">persist_constraints</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">live</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Creates a shaped tensor and adds it as an attribute.</span>

<span class="sd">        The following two calls are equivalent.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            module.attr = ShapedTensor(module, attr, value)</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            ShapedTensor.create(module, attr, value)</span>

<span class="sd">        Args:</span>
<span class="sd">            owner (Module): module to which this attribute will belong.</span>
<span class="sd">            name (str): name of the attribute.</span>
<span class="sd">            value (torch.Tensor | nn.Parameter | None): tensor-like data for the</span>
<span class="sd">                attribute.</span>
<span class="sd">            constraints (dict[int, int] | None, optional): constraints given as a</span>
<span class="sd">                dictionary of dimensions to their corresponding size. Defaults to None.</span>
<span class="sd">            persist_data (bool, optional): if the data should persist across the</span>
<span class="sd">                state dictionary, only used with buffers. Defaults to True.</span>
<span class="sd">            persist_constraints (bool, optional): if the constraints should persist</span>
<span class="sd">                across the state dictionary. Defaults to False.</span>
<span class="sd">            strict (bool, optional): if each dimension must specify a unique dimension</span>
<span class="sd">                for the tensor. Defaults to True.</span>
<span class="sd">            live (bool, optional): if constraint validity should be tested on</span>
<span class="sd">                assignment. Defaults to False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">constrained</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">owner</span><span class="p">,</span>
            <span class="n">name</span><span class="p">,</span>
            <span class="n">value</span><span class="p">,</span>
            <span class="n">constraints</span><span class="p">,</span>
            <span class="n">persist_data</span><span class="o">=</span><span class="n">persist_data</span><span class="p">,</span>
            <span class="n">persist_constraints</span><span class="o">=</span><span class="n">persist_constraints</span><span class="p">,</span>
            <span class="n">strict</span><span class="o">=</span><span class="n">strict</span><span class="p">,</span>
            <span class="n">live</span><span class="o">=</span><span class="n">live</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">constrained</span><span class="o">.</span><span class="n">owner</span><span class="p">,</span> <span class="n">constrained</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">constrained</span><span class="p">)</span></div>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">__make_compatible</span><span class="p">(</span>
        <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Corrects the tensor&#39;s shape.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">size</span><span class="p">:</span>
            <span class="n">slices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">repeat</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">),</span> <span class="n">times</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">ndim</span><span class="p">))</span>
            <span class="n">slices</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">-</span> <span class="n">size</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">tensor</span><span class="p">[</span><span class="o">*</span><span class="n">slices</span><span class="p">]</span>

        <span class="k">elif</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">size</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span> <span class="o">-</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">zeros</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">),</span> <span class="n">tensor</span><span class="p">),</span> <span class="n">dim</span><span class="p">)</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">data</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tensor</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_ignore</span><span class="p">(</span><span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Tests if compatibility for the input should be ignored.</span>

<span class="sd">        Args:</span>
<span class="sd">            tensor (torch.Tensor | nn.Parameter | None): value to check if ignored.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool: if the value will be ignored by constraints.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">tensor</span><span class="p">,</span> <span class="kc">None</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">UninitializedBuffer</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">UninitializedParameter</span>
        <span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="ow">or</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>

<div class="viewcode-block" id="ShapedTensor.resize"><a class="viewcode-back" href="../../../reference/generated/inferno.ShapedTensor.html#inferno.ShapedTensor.resize">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">resize</span><span class="p">(</span>
        <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">,</span>
        <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">preserve_tail</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">fill</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Resizes a tensor&#39;s dimension.</span>

<span class="sd">        A more generalized version of the built-in automatic resizing, this can be</span>
<span class="sd">        used before calling :py:meth:`reconstrain` if more control is needed.</span>

<span class="sd">        If ``value`` is a tensor, then a tensor will be returned, a new tensor if</span>
<span class="sd">        the shape needed to be changed, otherwise the same tensor as was given.</span>

<span class="sd">        If ``value`` is a parameter, then a parameter will be returned. If it needed</span>
<span class="sd">        to be reshaped, the parameter&#39;s data will be set with the reshaped data prior</span>
<span class="sd">        to being returned.</span>

<span class="sd">        When ``preserve_tail`` is ``True``, the tail of the tensor will be kept as-is,</span>
<span class="sd">        otherwise the head of the tensor will be kept. This corresponds to where</span>
<span class="sd">        slices will be removed or appended. Assuming a dimension is not sized to zero,</span>
<span class="sd">        then if ``preserve_tail`` is ``True``, ``tensor[-1]`` will return the same</span>
<span class="sd">        values before and after, otherwise ``tensor[0]`` will.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (torch.Tensor | nn.Parameter): tensor-like value to resize.</span>
<span class="sd">            dim (int): dimension to resize.</span>
<span class="sd">            size (int): new size for the dimension.</span>
<span class="sd">            preserve_tail (bool, optional): if the tail (higher indices) of a tensor</span>
<span class="sd">                should be unaltered. Defaults to True.</span>
<span class="sd">            fill (Any, optional): value with which to fill expanded dimensions.</span>
<span class="sd">                Defaults to 0.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | nn.Parameter: resized tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">gte</span><span class="p">(</span><span class="s2">&quot;size&quot;</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>

        <span class="c1"># shrink dimension</span>
        <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">size</span><span class="p">:</span>
            <span class="n">slices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">repeat</span><span class="p">(</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">),</span> <span class="n">times</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">ndim</span><span class="p">))</span>

            <span class="k">if</span> <span class="n">preserve_tail</span><span class="p">:</span>
                <span class="n">slices</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">-</span> <span class="n">size</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">slices</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>

            <span class="n">data</span> <span class="o">=</span> <span class="n">value</span><span class="p">[</span><span class="o">*</span><span class="n">slices</span><span class="p">]</span>

        <span class="c1"># expand dimension</span>
        <span class="k">elif</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">size</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span> <span class="o">-</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">preserve_tail</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">full</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">fill</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">),</span> <span class="n">value</span><span class="p">),</span> <span class="n">dim</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">value</span><span class="p">,</span> <span class="n">full</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">fill</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">)),</span> <span class="n">dim</span><span class="p">)</span>

        <span class="c1"># no change</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">value</span>

        <span class="c1"># set parameter data before returning if needed</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">):</span>
            <span class="n">value</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span>
            <span class="k">return</span> <span class="n">value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">data</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">__constraints</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Module internal constraint getter.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__owner</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">constraints</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">__data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Module internal data getter.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__owner</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

    <span class="nd">@__data</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">__data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Module internal data setter.&quot;&quot;&quot;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">)</span>
            <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">UninitializedBuffer</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">data</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__owner</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">owner</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Module</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Module which owns this attribute.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Module | None: owner of the attribute if it exists.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__owner</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Name of the attribute.</span>

<span class="sd">        Two attributes with names derived from ``name`` are added to the owner.</span>

<span class="sd">        * ``_{name}_data``, the constrained tensor.</span>
<span class="sd">        * ``_{name}_constraints``, the dictionary of constraints.</span>

<span class="sd">        Returns:</span>
<span class="sd">            str: name of the attribute.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__name</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ShapedTensor</span><span class="o">.</span><span class="n">LinkedAttributes</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Names of the dependent attributes created.</span>

<span class="sd">        This is a named tuple with attributes ``data`` and ``constraints``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ShapedTensor.LinkedAttributes: names of the created attributes in the</span>
<span class="sd">            containing module.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">value</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Value of the constrained tensor.</span>

<span class="sd">        If ``live`` was set on initialization, every setter call will ensure the tensor</span>
<span class="sd">        being set is valid (constrained or ignored).</span>

<span class="sd">        When created as a :py:class:`~torch.nn.Parameter`, assignment to ``None`` is</span>
<span class="sd">        prevented. If the current ``value`` is a :py:class:`~torch.nn.Parameter` but</span>
<span class="sd">        the assigned value is a :py:class:`~torch.Tensor`, it will automatically assign</span>
<span class="sd">        to the ``data`` attribute of ``value``.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (value: torch.Tensor | nn.Parameter | None): value to which the</span>
<span class="sd">                constrained attribute will be set.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | nn.Parameter | None: constrained attribute.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span>

    <span class="nd">@value</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># cannot assign none to parameter</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">)</span> <span class="ow">and</span> <span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;cannot assign None to a constrained parameter&quot;</span><span class="p">)</span>
        <span class="c1"># live constrain</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__live</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="ow">or</span> <span class="n">_constraints_compatible</span><span class="p">(</span>
                <span class="n">value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__constraints</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__strict</span>
            <span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">value</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;cannot set a tensor with shape </span><span class="si">{</span><span class="nb">tuple</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s2"> with &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;constraints: </span><span class="si">{</span><span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__constraints</span><span class="o">.</span><span class="n">items</span><span class="p">())</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">constraints</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Dictionary of registered constraints.</span>

<span class="sd">        Each key corresponds to a dimension of the tensor, and its associated value</span>
<span class="sd">        is the size of that dimension.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict[int, int]: dictionary of constraints.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__constraints</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">ignored</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;If the current tensor is ignored</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool: if the current tensor is ignored.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">live</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;If assignments should be constraint tested.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (bool): if assignments should be constraint tested.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool: if assignments should be constraint tested.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__live</span>

    <span class="nd">@live</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">live</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__live</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">strict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;If constraints should be strictly tested.</span>

<span class="sd">        When strict constraints are used, each constrained dimension must refer to a</span>
<span class="sd">        unique tensor dimension. For example, if constraints are placed on dimensions</span>
<span class="sd">        ``0`` and ``-1``, then ``strict`` would require a tensor to have at least two</span>
<span class="sd">        dimensions. Otherwise, as long as the constraints are all met, regardless of</span>
<span class="sd">        uniqueness, a tensor is considered valid.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (bool): if constraints should be strictly tested.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool: if constraints should be strictly tested.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__strict</span>

    <span class="nd">@strict</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">strict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__strict</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">valid</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;If the shaped tensor is valid.</span>

<span class="sd">        A shaped tensor is considered valid if the value is either ignored or is</span>
<span class="sd">        compatible with the current constraints and its owner still exists.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool: if the shaped tensor is valid.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__owner</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">)</span>
            <span class="ow">or</span> <span class="n">_constraints_compatible</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__constraints</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__strict</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dimensionality</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Minimum number of dimensions a tensor needs to satisfy constraints.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: minimum valid dimensionality.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_constraint_dimensionality</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__constraints</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__strict</span><span class="p">)</span>

<div class="viewcode-block" id="ShapedTensor.compatible"><a class="viewcode-back" href="../../../reference/generated/inferno.ShapedTensor.html#inferno.ShapedTensor.compatible">[docs]</a>    <span class="k">def</span> <span class="nf">compatible</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Checks if a tensor is compatible.</span>

<span class="sd">        Args:</span>
<span class="sd">            tensor (torch.Tensor | nn.Parameter): tensor to test for compatibility.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool: if the given tensor is dimensionally compatible.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_constraints_compatible</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__constraints</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__strict</span><span class="p">)</span></div>

<div class="viewcode-block" id="ShapedTensor.reconstrain"><a class="viewcode-back" href="../../../reference/generated/inferno.ShapedTensor.html#inferno.ShapedTensor.reconstrain">[docs]</a>    <span class="k">def</span> <span class="nf">reconstrain</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Add, edit, or remove a constraint.</span>

<span class="sd">        When ``size`` is ``None``, the corresponding constraint will be removed. When</span>
<span class="sd">        ``dim`` is not in the current constraints, it will add that constraint. When</span>
<span class="sd">        ``dim`` is in the current constraints and ``size`` is not ``None``, that</span>
<span class="sd">        constraint will be altered. Automatic resizing only occurs on editing a</span>
<span class="sd">        constraint, not on adding a constraint.</span>

<span class="sd">        When editing a constraint, if a tensor is already compatible with that</span>
<span class="sd">        constraint, then it will not be altered. If the size of the dimension is</span>
<span class="sd">        reduced, then elements will be cut off, preserving those towards the end.</span>
<span class="sd">        If the size of the dimension is increased, then zero-valued elements will be</span>
<span class="sd">        added to the start.</span>

<span class="sd">        Args:</span>
<span class="sd">            dim (int): dimension on which to modify the constraint.</span>
<span class="sd">            size (int | None): new size for the specified dimension.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: dimension specified for constraint removal is unconstrained.</span>
<span class="sd">            ValueError: constrained tensor would be invalidated by adding this constraint.</span>
<span class="sd">            RuntimeError: previous operation invalidated constrained tensor.</span>
<span class="sd">            RuntimeError: constrained tensor cannot be made valid with constraint.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | nn.Parameter | None: newly constrained value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># cast and validate arguments</span>
        <span class="n">dim</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="n">size</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">argtest</span><span class="o">.</span><span class="n">gte</span><span class="p">(</span><span class="s2">&quot;size&quot;</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>

        <span class="c1"># strongly reference data and constraints</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">constraints</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__constraints</span>

        <span class="c1"># invalid input combination</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">constraints</span> <span class="ow">and</span> <span class="n">size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;cannot remove constraint on unconstrained dim </span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># create constraint</span>
        <span class="k">elif</span> <span class="n">dim</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">constraints</span><span class="p">:</span>
            <span class="c1"># safe to add with an ignored tensor</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
                <span class="n">constraints</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span>

            <span class="c1"># check if the tensor has been invalidated</span>
            <span class="k">elif</span> <span class="n">_constraints_compatible</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">constraints</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__strict</span><span class="p">):</span>

                <span class="c1"># add if compatible</span>
                <span class="k">if</span> <span class="n">_constraints_compatible</span><span class="p">(</span>
                    <span class="n">data</span><span class="p">,</span> <span class="n">constraints</span> <span class="o">|</span> <span class="p">{</span><span class="n">dim</span><span class="p">:</span> <span class="n">size</span><span class="p">},</span> <span class="bp">self</span><span class="o">.</span><span class="n">__strict</span>
                <span class="p">):</span>
                    <span class="n">constraints</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="s2">&quot;constrained tensor would be invalidated by constraint of &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;size </span><span class="si">{</span><span class="n">size</span><span class="si">}</span><span class="s2"> on dim </span><span class="si">{</span><span class="n">dim</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;constrained tensor has been invalidated&quot;</span><span class="p">)</span>

        <span class="c1"># remove constraint</span>
        <span class="k">elif</span> <span class="n">size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># always safe to remove a constraint</span>
            <span class="k">del</span> <span class="n">constraints</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>

            <span class="c1"># check that tensor is still valid</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="ow">or</span> <span class="n">_constraints_compatible</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">constraints</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__strict</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;constrained tensor has been invalidated&quot;</span><span class="p">)</span>

        <span class="c1"># alter constraint</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># safe to edit with an ignored tensor</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
                <span class="n">constraints</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span>

            <span class="c1"># tensor has sufficient dimensionality</span>
            <span class="k">elif</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;=</span> <span class="n">_constraint_dimensionality</span><span class="p">(</span>
                <span class="n">constraints</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__strict</span>
            <span class="p">)</span> <span class="ow">and</span> <span class="n">_constraints_consistent</span><span class="p">(</span><span class="n">constraints</span> <span class="o">|</span> <span class="p">{</span><span class="n">dim</span><span class="p">:</span> <span class="n">size</span><span class="p">},</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span><span class="p">):</span>
                <span class="c1"># edit the constraint</span>
                <span class="n">constraints</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">size</span>

                <span class="c1"># alter if not already compatible</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">_constraints_compatible</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">constraints</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__strict</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__make_compatible</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
                    <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span>

            <span class="c1"># tensor has insufficient dimensionality</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;constrained tensor cannot be made valid with altered constraint&quot;</span>
                <span class="p">)</span>

        <span class="c1"># return altered value</span>
        <span class="k">return</span> <span class="n">data</span></div></div>


<span class="k">def</span> <span class="nf">_unwind_ptr</span><span class="p">(</span><span class="n">pointer</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="nb">float</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">pointer</span> <span class="o">-</span> <span class="nb">int</span><span class="p">(</span><span class="n">offset</span><span class="p">))</span> <span class="o">%</span> <span class="n">size</span>


<span class="k">def</span> <span class="nf">_unwind_tensor_ptr</span><span class="p">(</span><span class="n">pointer</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">offset</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">pointer</span> <span class="o">-</span> <span class="n">offset</span><span class="o">.</span><span class="n">long</span><span class="p">())</span> <span class="o">%</span> <span class="n">size</span>


<span class="k">def</span> <span class="nf">_recordtensor_finalization</span><span class="p">(</span><span class="n">owner</span><span class="p">:</span> <span class="n">weakref</span><span class="o">.</span><span class="n">ReferenceType</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Finalizer function for RecordTensor.&quot;&quot;&quot;</span>
    <span class="n">owner</span> <span class="o">=</span> <span class="n">owner</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">owner</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_dt&quot;</span><span class="p">):</span>
            <span class="nb">delattr</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_dt&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_duration&quot;</span><span class="p">):</span>
            <span class="nb">delattr</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_duration&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_pointer&quot;</span><span class="p">):</span>
            <span class="nb">delattr</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_pointer&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="RecordTensor"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordTensor.html#inferno.RecordTensor">[docs]</a><span class="k">class</span> <span class="nc">RecordTensor</span><span class="p">(</span><span class="n">ShapedTensor</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Tensor attribute with recorded history.</span>

<span class="sd">    Read Operations: :py:meth:`peek`, :py:meth:`pop`, :py:meth:`read`,</span>
<span class="sd">    :py:meth:`readrange`, :py:meth:`select`</span>

<span class="sd">    Write Operations: :py:meth:`push`, :py:meth:`write`, :py:meth:`writerange`,</span>
<span class="sd">    :py:meth:`insert`</span>

<span class="sd">    Args:</span>
<span class="sd">        owner (Module): module to which this attribute will belong.</span>
<span class="sd">        name (str): name of the attribute.</span>
<span class="sd">        step_time (float): length of time between stored values in the record.</span>
<span class="sd">        duration (float): length of time over which prior values are stored.</span>
<span class="sd">        value (torch.Tensor | nn.Parameter | None): tensor-like data for the attribute.</span>
<span class="sd">        constraints (dict[int, int] | None, optional): constraints given as a</span>
<span class="sd">            dictionary of dimensions to their corresponding size. Defaults to None.</span>
<span class="sd">        persist_data (bool, optional): if the data should persist across the</span>
<span class="sd">            state dictionary, only used with buffers. Defaults to True.</span>
<span class="sd">        persist_constraints (bool, optional): if the constraints should persist</span>
<span class="sd">            across the state dictionary. Defaults to False.</span>
<span class="sd">        persist_temporal (bool, optional): if temporal information (step time and</span>
<span class="sd">            duration) should persist across the state dictionary. Defaults to False.</span>
<span class="sd">        strict (bool, optional): if each dimension must specify a unique dimension</span>
<span class="sd">            for the tensor. Defaults to True.</span>
<span class="sd">        live (bool, optional): if constraint validity should be tested on</span>
<span class="sd">            assignment. Defaults to False.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">LinkedAttributes</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span>
        <span class="s2">&quot;RecordTensorAttributes&quot;</span><span class="p">,</span> <span class="p">(</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="s2">&quot;constraints&quot;</span><span class="p">,</span> <span class="s2">&quot;dt&quot;</span><span class="p">,</span> <span class="s2">&quot;duration&quot;</span><span class="p">,</span> <span class="s2">&quot;pointer&quot;</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">owner</span><span class="p">:</span> <span class="n">Module</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">step_time</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">duration</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">persist_data</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">persist_constraints</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">persist_temporal</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">live</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># argument validation</span>
        <span class="n">step_time</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="s2">&quot;step_time&quot;</span><span class="p">,</span> <span class="n">step_time</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">duration</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">gte</span><span class="p">(</span><span class="s2">&quot;duration&quot;</span><span class="p">,</span> <span class="n">duration</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>

        <span class="c1"># size of the history dimension</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">duration</span> <span class="o">/</span> <span class="n">step_time</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># alter constraints</span>
        <span class="n">constraints</span> <span class="o">=</span> <span class="p">{</span>
            <span class="p">(</span><span class="n">d</span> <span class="o">-</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">d</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">d</span><span class="p">):</span> <span class="n">s</span>
            <span class="k">for</span> <span class="n">d</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="p">(</span><span class="n">constraints</span> <span class="k">if</span> <span class="n">constraints</span> <span class="k">else</span> <span class="p">{})</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">}</span> <span class="o">|</span> <span class="p">{</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span> <span class="n">size</span><span class="p">}</span>

        <span class="c1"># reshape value if not ignored</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="n">value</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">):</span>
                <span class="n">value</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                    <span class="o">*</span><span class="n">chain</span><span class="p">(</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">times</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">ndim</span><span class="p">),</span> <span class="p">(</span><span class="n">size</span><span class="p">,))</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span>
                    <span class="o">*</span><span class="n">chain</span><span class="p">(</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">times</span><span class="o">=</span><span class="n">value</span><span class="o">.</span><span class="n">ndim</span><span class="p">),</span> <span class="p">(</span><span class="n">size</span><span class="p">,))</span>
                <span class="p">)</span>

        <span class="c1"># call superclass constructor</span>
        <span class="n">ShapedTensor</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">owner</span><span class="p">,</span>
            <span class="n">name</span><span class="p">,</span>
            <span class="n">value</span><span class="p">,</span>
            <span class="n">constraints</span><span class="p">,</span>
            <span class="n">persist_data</span><span class="o">=</span><span class="n">persist_data</span><span class="p">,</span>
            <span class="n">persist_constraints</span><span class="o">=</span><span class="n">persist_constraints</span><span class="p">,</span>
            <span class="n">strict</span><span class="o">=</span><span class="n">strict</span><span class="p">,</span>
            <span class="n">live</span><span class="o">=</span><span class="n">live</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># finalizer state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__owner</span> <span class="o">=</span> <span class="n">weakref</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="n">owner</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__finalizer</span> <span class="o">=</span> <span class="n">weakref</span><span class="o">.</span><span class="n">finalize</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">_recordtensor_finalization</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__owner</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># registered attribute names</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span> <span class="o">=</span> <span class="n">RecordTensor</span><span class="o">.</span><span class="n">LinkedAttributes</span><span class="p">(</span>
            <span class="n">ShapedTensor</span><span class="o">.</span><span class="n">attributes</span><span class="o">.</span><span class="n">fget</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="p">,</span>
            <span class="n">ShapedTensor</span><span class="o">.</span><span class="n">attributes</span><span class="o">.</span><span class="n">fget</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">constraints</span><span class="p">,</span>
            <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_dt&quot;</span><span class="p">,</span>
            <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_duration&quot;</span><span class="p">,</span>
            <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_pointer&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># register temporal state</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="n">Module</span><span class="p">)</span> <span class="ow">and</span> <span class="n">persist_temporal</span><span class="p">:</span>
            <span class="n">owner</span><span class="o">.</span><span class="n">register_extra</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">dt</span><span class="p">,</span> <span class="n">step_time</span><span class="p">)</span>
            <span class="n">owner</span><span class="o">.</span><span class="n">register_extra</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">duration</span><span class="p">,</span> <span class="n">duration</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">dt</span><span class="p">,</span> <span class="n">step_time</span><span class="p">)</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">duration</span><span class="p">,</span> <span class="n">duration</span><span class="p">)</span>

        <span class="c1"># register the pointer (persist if possible)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="n">Module</span><span class="p">):</span>
            <span class="n">owner</span><span class="o">.</span><span class="n">register_extra</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">pointer</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">pointer</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<div class="viewcode-block" id="RecordTensor.create"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordTensor.html#inferno.RecordTensor.create">[docs]</a>    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">create</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">owner</span><span class="p">:</span> <span class="n">Module</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">step_time</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">duration</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">constraints</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">persist_data</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">persist_constraints</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">persist_temporal</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">strict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">live</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Creates a record tensor and adds it as an attribute.</span>

<span class="sd">        The following two calls are equivalent.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            module.name = RecordTensor(owner, name, step_time, duration, value)</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            RecordTensor.create(module, attr, step_time, duration, value)</span>

<span class="sd">        Args:</span>
<span class="sd">            owner (Module): module to which this attribute will belong.</span>
<span class="sd">            name (str): name of the attribute.</span>
<span class="sd">            step_time (float): length of time between stored values in the record.</span>
<span class="sd">            duration (float): length of time over which prior values are stored.</span>
<span class="sd">            value (torch.Tensor | nn.Parameter | None): tensor-like data for the</span>
<span class="sd">                attribute.</span>
<span class="sd">            constraints (dict[int, int] | None, optional): constraints given as a</span>
<span class="sd">                dictionary of dimensions to their corresponding size. Defaults to None.</span>
<span class="sd">            persist_data (bool, optional): if the data should persist across the</span>
<span class="sd">                state dictionary, only used with buffers. Defaults to True.</span>
<span class="sd">            persist_constraints (bool, optional): if the constraints should persist</span>
<span class="sd">                across the state dictionary. Defaults to False.</span>
<span class="sd">            persist_temporal (bool, optional): if temporal information (step time and</span>
<span class="sd">                duration) should persist across the state dictionary. Defaults to False.</span>
<span class="sd">            strict (bool, optional): if each dimension must specify a unique dimension</span>
<span class="sd">                for the tensor. Defaults to True.</span>
<span class="sd">            live (bool, optional): if constraint validity should be tested on</span>
<span class="sd">                assignment. Defaults to False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">constrained</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">owner</span><span class="p">,</span>
            <span class="n">name</span><span class="p">,</span>
            <span class="n">step_time</span><span class="p">,</span>
            <span class="n">duration</span><span class="p">,</span>
            <span class="n">value</span><span class="p">,</span>
            <span class="n">constraints</span><span class="p">,</span>
            <span class="n">persist_data</span><span class="o">=</span><span class="n">persist_data</span><span class="p">,</span>
            <span class="n">persist_constraints</span><span class="o">=</span><span class="n">persist_constraints</span><span class="p">,</span>
            <span class="n">persist_temporal</span><span class="o">=</span><span class="n">persist_temporal</span><span class="p">,</span>
            <span class="n">strict</span><span class="o">=</span><span class="n">strict</span><span class="p">,</span>
            <span class="n">live</span><span class="o">=</span><span class="n">live</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">constrained</span><span class="o">.</span><span class="n">owner</span><span class="p">,</span> <span class="n">constrained</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">constrained</span><span class="p">)</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">__constraints</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Module internal constraint getter.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__owner</span><span class="p">(),</span> <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__name</span><span class="si">}</span><span class="s2">_constraints&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">__data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Module internal data getter.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__owner</span><span class="p">(),</span> <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__name</span><span class="si">}</span><span class="s2">_data&quot;</span><span class="p">)</span>

    <span class="nd">@__data</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">__data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Module internal data setter.&quot;&quot;&quot;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">)</span>
            <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
            <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">UninitializedBuffer</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="n">data</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__owner</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">__dt</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Module internal step time getter.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__owner</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">dt</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">__duration</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Module internal duration getter.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__owner</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">duration</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">__pointer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Module internal pointer getter.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__owner</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">pointer</span><span class="p">)</span>

    <span class="nd">@__pointer</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">__pointer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Module internal pointer setter.&quot;&quot;&quot;</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__owner</span><span class="p">(),</span> <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__name</span><span class="si">}</span><span class="s2">_pointer&quot;</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">__recordsz</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Module internal record size getter.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__constraints</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RecordTensor</span><span class="o">.</span><span class="n">LinkedAttributes</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Names of the dependent attributes created.</span>

<span class="sd">        This is a named tuple with attributes ``data``, ``constraints``, ``dt``,</span>
<span class="sd">        ``duration``, and ``pointer``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            RecordTensor.LinkedAttributes: names of the created attributes in the</span>
<span class="sd">            containing module.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">constraints</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Dictionary of registered constraints.</span>

<span class="sd">        Each key corresponds to a dimension of the tensor, and its associated value</span>
<span class="sd">        is the size of that dimension. This shifts the dimensions of negative</span>
<span class="sd">        constraints to make the record size transparent.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict[int, int]: dictionary of constraints.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="p">(</span><span class="n">d</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">d</span> <span class="o">&lt;</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="n">d</span><span class="p">):</span> <span class="n">s</span>
            <span class="k">for</span> <span class="n">d</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">__constraints</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">d</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="p">}</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dt</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Length of time between recorded observations.</span>

<span class="sd">        In the same units as :py:attr:`self.duration`.</span>

<span class="sd">        If the step time is changed such that the record size needs to change, a</span>
<span class="sd">        :py:meth:`reconstrain` operation will be performed automatically, preserving</span>
<span class="sd">        the newest entires. Stored values may no longer be logically valid, but will</span>
<span class="sd">        still be accessible.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (torch.Tensor | float): new time step length.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: length of the time step.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__dt</span>

    <span class="nd">@dt</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">dt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># validate argument</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="s2">&quot;dt&quot;</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>

        <span class="c1"># assign updated step time</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__owner</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">dt</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

        <span class="c1"># recompute size of the history dimension</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__duration</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">__dt</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># reconstrain if required</span>
        <span class="k">if</span> <span class="n">size</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__recordsz</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">_</span> <span class="o">=</span> <span class="n">ShapedTensor</span><span class="o">.</span><span class="n">reconstrain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">duration</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Length of time over which prior values are stored.</span>

<span class="sd">        In the same units as :py:attr:`self.dt`.</span>

<span class="sd">        If the step time is changed such that the record size needs to change, a</span>
<span class="sd">        :py:meth:`reconstrain` operation will be performed automatically, preserving</span>
<span class="sd">        the newest entires.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (float): new length of the record.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: length of the record as the length of time.</span>

<span class="sd">        Note:</span>
<span class="sd">            If ``duration`` is not evenly divided by :py:attr:`dt`, then the number</span>
<span class="sd">            of observations stored will be rounded up. This property will always return</span>
<span class="sd">            the duration set although the range of accessible values may be larger.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__duration</span>

    <span class="nd">@duration</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">duration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># validate argument</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">gte</span><span class="p">(</span><span class="s2">&quot;duration&quot;</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>

        <span class="c1"># assign updated duration</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__owner</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">__attributes</span><span class="o">.</span><span class="n">duration</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

        <span class="c1"># recompute size of the history dimension</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__duration</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">__dt</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># reconstrain if required</span>
        <span class="k">if</span> <span class="n">size</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__recordsz</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">_</span> <span class="o">=</span> <span class="n">ShapedTensor</span><span class="o">.</span><span class="n">reconstrain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">recordsz</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Number of observations stored.</span>

<span class="sd">        .. math::</span>
<span class="sd">            N = \left\lceil \frac{T}{\Delta t} \right\rceil + 1</span>

<span class="sd">        For :py:attr:`duration` :math:`T` and :py:attr:`dt` :math:`\Delta t`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: length of the record as the number of observations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__recordsz</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Shape of the observations.</span>

<span class="sd">        Returns:</span>
<span class="sd">            tuple[int, ...] | None: shape of the observations, ``None`` when storage</span>
<span class="sd">            is uninitialized (ignored).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># strongly reference data</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">pointer</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Current index of the pointer.</span>

<span class="sd">        The location of the pointer indicates the location of the next observation</span>
<span class="sd">        which will be overwritten.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: current index of the pointer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">latest</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Most recent stored observation.</span>

<span class="sd">        When used as a getter, this is an alias for :py:meth:`peek`.</span>

<span class="sd">        When used as a setter, this is an alias for :py:meth:`push` with ``inplace`` set</span>
<span class="sd">        to ``False``.</span>

<span class="sd">        When used as a deleter, this is an alias for :py:meth:`decr` with ``pos`` set</span>
<span class="sd">        to ``1``.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (torch.Tensor): observation to push.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | None: value of the most recently recorded observation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">peek</span><span class="p">()</span>

    <span class="nd">@latest</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">latest</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">push</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="nd">@latest</span><span class="o">.</span><span class="n">deleter</span>
    <span class="k">def</span> <span class="nf">latest</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decr</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">value</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Record storage tensor.</span>

<span class="sd">        When created as a :py:class:`~torch.nn.Parameter`, assignment to ``None`` is</span>
<span class="sd">        prevented. If the current ``value`` is a :py:class:`~torch.nn.Parameter` but</span>
<span class="sd">        the assigned value is a :py:class:`~torch.Tensor`, it will automatically assign</span>
<span class="sd">        to the ``data`` attribute of ``value``.</span>

<span class="sd">        When used as a deleter, this acts as an alias for</span>
<span class="sd">        ``self.deinitialize(use_uninitialized=False)``.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (value: torch.Tensor | nn.Parameter | None): value to set the storage</span>
<span class="sd">                tensor to.</span>
<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | nn.Parameter | None: storage tensor.</span>

<span class="sd">        .. admonition:: Shape</span>
<span class="sd">            :class: tensorshape</span>

<span class="sd">            ``value``, ``return``:</span>

<span class="sd">            :math:`S_0 \times \cdots \times N`</span>

<span class="sd">            Where:</span>
<span class="sd">                * :math:`S_0, \ldots` are the dimensions of each observation, given</span>
<span class="sd">                  by :py:attr:`shape`.</span>
<span class="sd">                * :math:`N` is the number of observations the storage can hold,</span>
<span class="sd">                  equal to :py:attr:`recordsz`.</span>

<span class="sd">        Caution:</span>
<span class="sd">            This should be used for setting properties of the underlying storage</span>
<span class="sd">            (device, data type, etc.) and for advanced initialization/deinitialization.</span>
<span class="sd">            General read/write access should generally be performed through the provided</span>
<span class="sd">            if possible.</span>

<span class="sd">        Note:</span>
<span class="sd">            If after assigning the new value, :py:attr:`ignored` is ``True``, the</span>
<span class="sd">            pointer will be moved to ``0``, otherwise it will not be changed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">ShapedTensor</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">fget</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="nd">@value</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">value</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">ShapedTensor</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">fset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">):</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__owner</span><span class="p">(),</span> <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">__name</span><span class="si">}</span><span class="s2">_pointer&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="nd">@value</span><span class="o">.</span><span class="n">deleter</span>
    <span class="k">def</span> <span class="nf">value</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deinitialize</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<div class="viewcode-block" id="RecordTensor.align"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordTensor.html#inferno.RecordTensor.align">[docs]</a>    <span class="k">def</span> <span class="nf">align</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Aligns the storage such that the oldest observation is at a specified index.</span>

<span class="sd">        Args:</span>
<span class="sd">            index (int, optional): index to align to. Defaults to 0.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: cannot align when storage is uninitialized (ignored).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># check for a valid index</span>
        <span class="n">index</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s2">&quot;index&quot;</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__recordsz</span><span class="p">,</span> <span class="s2">&quot;recordsz&quot;</span><span class="p">)</span>

        <span class="c1"># strongly reference data</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span>

        <span class="c1"># only constrained state can be aligned</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">index</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span> <span class="o">=</span> <span class="n">index</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;cannot align uninitialized value&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="RecordTensor.reset"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordTensor.html#inferno.RecordTensor.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fill</span><span class="p">:</span> <span class="n">Any</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fills the storage with a given value and aligns it to zero.</span>

<span class="sd">        Args:</span>
<span class="sd">            fill (Any | None, optional): value with which to fill the storage, or if</span>
<span class="sd">                ``None`` no fill will be applied. Defaults to 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># strongly reference data</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span>

        <span class="k">if</span> <span class="n">fill</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># perform fill if not ignored</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">fill</span><span class="p">)</span>

            <span class="c1"># reset pointer to start</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span></div>

<div class="viewcode-block" id="RecordTensor.initialize"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordTensor.html#inferno.RecordTensor.initialize">[docs]</a>    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fill</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Initializes the storage tensor.</span>

<span class="sd">        Args:</span>
<span class="sd">            shape (tuple[int, ...]): shape, excluding the record dimension, of the</span>
<span class="sd">                storage tensor.</span>
<span class="sd">            device (torch.device | None, optional): overrides the device on which to</span>
<span class="sd">                place the tensor when not ``None``. Defaults to ``None``.</span>
<span class="sd">            dtype (torch.dtype | None, optional): overrides data tyoe of the tensor</span>
<span class="sd">                when not ``None``. Defaults to ``None``.</span>
<span class="sd">            fill (Any, optional): value with which to fill the tensor. Defaults to 0.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | nn.Parameter: initialized buffer or parameter.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># strongly reference data and get record size</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">recordsz</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__recordsz</span>

        <span class="c1"># pytorch uninitialized buffer or parameter</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">UninitializedBuffer</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">UninitializedParameter</span><span class="p">):</span>
            <span class="c1"># materialize, which alters in-place</span>
            <span class="n">data</span><span class="o">.</span><span class="n">materialize</span><span class="p">((</span><span class="o">*</span><span class="n">shape</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

            <span class="c1"># fill in-place</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">fill</span><span class="p">)</span>

        <span class="c1"># initialized but empty tensor or parameter</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># reassign using value defaults, automatic parameter assignment test</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">full</span><span class="p">(</span>
                <span class="n">data</span><span class="p">,</span> <span class="n">fill</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
            <span class="p">)</span>

        <span class="c1"># none value, always a buffer, simple overwrite</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
                <span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">),</span> <span class="n">fill</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
            <span class="p">)</span>

        <span class="c1"># set pointer to zero and return created or materialized attribute</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span></div>

<div class="viewcode-block" id="RecordTensor.deinitialize"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordTensor.html#inferno.RecordTensor.deinitialize">[docs]</a>    <span class="k">def</span> <span class="nf">deinitialize</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">use_uninitialized</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Deinitializes the storage tensor.</span>

<span class="sd">        This either assigns an empty tensor with shape ``[0]`` as the value or either</span>
<span class="sd">        :py:class:`~torch.nn.UninitializedBuffer` or</span>
<span class="sd">        :py:class:`~torch.nn.UninitializedParameter`. The device, data type, and</span>
<span class="sd">        gradient requirement will be preserved.</span>

<span class="sd">        If the storage tensor is already not initialized, it will still be reassigned.</span>
<span class="sd">        If it is ``None``, the defaults of will be used and it will be reassigned either</span>
<span class="sd">        with ``UninitializedBuffer()`` or ``torch.empty(0)``.</span>

<span class="sd">        Args:</span>
<span class="sd">            use_uninitialized (bool, optional): if an uninitalized buffer or</span>
<span class="sd">                uninitialized parameter should be used. Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | nn.Parameter: deinitialized storage.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># strongly reference data</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">use_uninitialized</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">UninitializedParameter</span><span class="p">(</span>
                    <span class="n">requires_grad</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">data</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">empty</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">use_uninitialized</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">UninitializedBuffer</span><span class="p">(</span>
                    <span class="n">requires_grad</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">empty</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">use_uninitialized</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">UninitializedBuffer</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># set pointer to zero and return created tensor or parameter</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span></div>

<div class="viewcode-block" id="RecordTensor.incr"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordTensor.html#inferno.RecordTensor.incr">[docs]</a>    <span class="k">def</span> <span class="nf">incr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pos</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Moves the pointer forward.</span>

<span class="sd">        Args:</span>
<span class="sd">            pos (int, optional): number of steps by which to move the pointer</span>
<span class="sd">                forward. Defaults to 1.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: new location of the pointer.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: cannot modify the pointer when the storage is</span>
<span class="sd">                uninitialized (ignored).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;cannot modify pointer when storage is uninitialized&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span> <span class="o">=</span> <span class="n">_unwind_ptr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span><span class="p">,</span> <span class="o">-</span><span class="n">pos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__recordsz</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span></div>

<div class="viewcode-block" id="RecordTensor.decr"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordTensor.html#inferno.RecordTensor.decr">[docs]</a>    <span class="k">def</span> <span class="nf">decr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pos</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Moves the pointer backward.</span>

<span class="sd">        Args:</span>
<span class="sd">            pos (int, optional): number of steps by which to move the pointer</span>
<span class="sd">                backward. Defaults to 1.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: new location of the pointer.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: cannot modify the pointer when the storage is</span>
<span class="sd">                uninitialized (ignored).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;cannot modify pointer when storage is uninitialized&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span> <span class="o">=</span> <span class="n">_unwind_ptr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__recordsz</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span></div>

<div class="viewcode-block" id="RecordTensor.peek"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordTensor.html#inferno.RecordTensor.peek">[docs]</a>    <span class="k">def</span> <span class="nf">peek</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Retrieves the most recently pushed observation.</span>

<span class="sd">        If the state is uninitialized, then ``None`` will be returned. Otherwise this</span>
<span class="sd">        is an alias for ``self.read(offset=1)``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | None: most recently pushed observation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="RecordTensor.pop"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordTensor.html#inferno.RecordTensor.pop">[docs]</a>    <span class="k">def</span> <span class="nf">pop</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Retrieves the most recently pushed observation and decrements the pointer.</span>

<span class="sd">        If the state is uninitialized, then ``None`` will be returned and the pointer</span>
<span class="sd">        will be unaltered.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | None: most recently pushed observation.</span>

<span class="sd">        Important:</span>
<span class="sd">            Unlike a pop-operation on most data structures, this does not affect the</span>
<span class="sd">            underlying storage. It only moves the pointer back so the next</span>
<span class="sd">            :py:meth:`push` will overwrite that value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">decr</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span></div>

<div class="viewcode-block" id="RecordTensor.push"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordTensor.html#inferno.RecordTensor.push">[docs]</a>    <span class="k">def</span> <span class="nf">push</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Records an observation to the current location and advances the pointer.</span>

<span class="sd">        This is an alias for the following code.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            self.write(value, offset=0, inplace=inplace)</span>
<span class="sd">            self.incr(pos=1)</span>

<span class="sd">        Args:</span>
<span class="sd">            obs (torch.Tensor): observation to write.</span>
<span class="sd">            inplace (bool, optional): if the operation should be performed in-place</span>
<span class="sd">                with :py:func:`torch.no_grad`. Defaults to False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="n">inplace</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">incr</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="RecordTensor.read"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordTensor.html#inferno.RecordTensor.read">[docs]</a>    <span class="k">def</span> <span class="nf">read</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Reads the observation at an index relative to the pointer.</span>

<span class="sd">        The pointer specifies the next observation to overwrite, and the offset</span>
<span class="sd">        specifies the number of observations back from which to read. The default</span>
<span class="sd">        value ``offset=1`` will return the most recently pushed observation.</span>

<span class="sd">        Args:</span>
<span class="sd">            offset (int, optional): number of steps before the pointer. Defaults to 1.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: cannot read from uninitialized (ignored) storage.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: observation at the specified index.</span>

<span class="sd">        .. admonition:: Shape</span>
<span class="sd">            :class: tensorshape</span>

<span class="sd">            ``return``:</span>

<span class="sd">            :math:`S_0 \times \cdots`</span>

<span class="sd">            Where:</span>
<span class="sd">                * :math:`S_0, \ldots` are the dimensions of each observation, given</span>
<span class="sd">                  by :py:attr:`shape`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># strongly reference data and get from internal properties</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">ptr</span><span class="p">,</span> <span class="n">recordsz</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__recordsz</span>

        <span class="c1"># cannot read uninitialized value</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;cannot read from uninitialized storage&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">_unwind_ptr</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">)]</span></div>

<div class="viewcode-block" id="RecordTensor.write"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordTensor.html#inferno.RecordTensor.write">[docs]</a>    <span class="k">def</span> <span class="nf">write</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Writes an observation at an index relative to the pointer.</span>

<span class="sd">        The pointer specifies the next observation to overwrite, and the offset</span>
<span class="sd">        specifies the number of observations back from which to write. The default</span>
<span class="sd">        value ``offset=0`` overwrite the oldest observation.</span>

<span class="sd">        Args:</span>
<span class="sd">            obs (torch.Tensor): observation to write at the specified offset.</span>
<span class="sd">            offset (int, optional): number of steps before the pointer. Defaults to 0.</span>
<span class="sd">            inplace (bool, optional): if the operation should be performed in-place</span>
<span class="sd">                with :py:func:`torch.no_grad`. Defaults to False.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: cannot write to uninitialized (ignored) storage.</span>
<span class="sd">            ValueError: shape of ``value`` must match the shape of an observation.</span>

<span class="sd">        .. admonition:: Shape</span>
<span class="sd">            :class: tensorshape</span>

<span class="sd">            ``obs``:</span>

<span class="sd">            :math:`S_0 \times \cdots`</span>

<span class="sd">            Where:</span>
<span class="sd">                * :math:`S_0, \ldots` are the dimensions of each observation, given</span>
<span class="sd">                  by :py:attr:`shape`.</span>

<span class="sd">        Important:</span>
<span class="sd">            The :py:class:`~torch.dtype` of ``obs`` is not changed, so when ``inplace``</span>
<span class="sd">            is set to ``False``, this may cause the data type of the stored tensor to</span>
<span class="sd">            change.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># strongly reference data and get from internal properties</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">ptr</span><span class="p">,</span> <span class="n">recordsz</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__recordsz</span>

        <span class="c1"># cannot write to uninitialized value</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;cannot write to uninitialized storage&quot;</span><span class="p">)</span>

        <span class="c1"># shape must be the same as a observation</span>
        <span class="k">elif</span> <span class="p">(</span><span class="o">*</span><span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">,)</span> <span class="o">!=</span> <span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;shape of &#39;obs&#39; </span><span class="si">{</span><span class="p">(</span><span class="o">*</span><span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">,)</span><span class="si">}</span><span class="s2"> must have the shape &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],)</span><span class="si">}</span><span class="s2">, like a time slice of the stored value&quot;</span>
            <span class="p">)</span>

        <span class="c1"># in-place overwrite</span>
        <span class="k">elif</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">index</span> <span class="o">=</span> <span class="n">_unwind_ptr</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">)</span>
                <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">obs</span>

        <span class="c1"># splice in</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">_unwind_ptr</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="p">)],</span>
                    <span class="n">obs</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                    <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">)],</span>
                <span class="p">),</span>
                <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span></div>

<div class="viewcode-block" id="RecordTensor.readrange"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordTensor.html#inferno.RecordTensor.readrange">[docs]</a>    <span class="k">def</span> <span class="nf">readrange</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">forward</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Reads multiple sequential observations.</span>

<span class="sd">        When ``forward`` is ``False``, then ``length`` observations will be read</span>
<span class="sd">        from the following interval.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            [pointer - offset - length - 1, pointer - offset]</span>

<span class="sd">        When ``forward`` is ``True``, then ``length`` observations will be read</span>
<span class="sd">        from the following interval.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            [pointer - offset, pointer - offset + length - 1]</span>

<span class="sd">        Args:</span>
<span class="sd">            length (int): number of observations to read`.</span>
<span class="sd">            offset (int, optional): number of steps before the pointer. Defaults to 1.</span>
<span class="sd">            forward (bool, optional): if the offset pointer indicates the index of the</span>
<span class="sd">                first observation. Defaults to ``False``.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: _description_</span>
<span class="sd">            ValueError: _description_</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: _description_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># strongly reference data and get from internal properties</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">ptr</span><span class="p">,</span> <span class="n">recordsz</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__recordsz</span>

        <span class="c1"># cannot read from uninitialized value</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;cannot read from an uninitialized value&quot;</span><span class="p">)</span>

        <span class="c1"># shift offset if using noninitial offset</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">forward</span><span class="p">:</span>
            <span class="n">offset</span> <span class="o">=</span> <span class="n">offset</span> <span class="o">+</span> <span class="p">(</span><span class="n">length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># scalar offset</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">start</span> <span class="o">=</span> <span class="n">_unwind_ptr</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">)</span>
            <span class="n">end</span> <span class="o">=</span> <span class="n">_unwind_ptr</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">offset</span> <span class="o">-</span> <span class="n">length</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">start</span> <span class="o">&gt;</span> <span class="n">end</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="kc">None</span><span class="p">)],</span> <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="p">)]),</span> <span class="o">-</span><span class="mi">1</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">)]</span>

        <span class="c1"># shape must be the same as a slice</span>
        <span class="k">elif</span> <span class="p">(</span><span class="o">*</span><span class="n">offset</span><span class="o">.</span><span class="n">shape</span><span class="p">,)</span> <span class="o">!=</span> <span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;shape of &#39;offset&#39; </span><span class="si">{</span><span class="p">(</span><span class="o">*</span><span class="n">offset</span><span class="o">.</span><span class="n">shape</span><span class="p">,)</span><span class="si">}</span><span class="s2"> must have the shape &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],)</span><span class="si">}</span><span class="s2">, like a time slice of the stored value&quot;</span>
            <span class="p">)</span>

        <span class="c1"># tensor offset</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span>
                <span class="n">data</span><span class="p">,</span>
                <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">_unwind_tensor_ptr</span><span class="p">(</span>
                    <span class="n">ptr</span><span class="p">,</span>
                    <span class="n">offset</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">offset</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
                    <span class="n">recordsz</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">writerange</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">forward</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># strongly reference data and get record size and pointer</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">,</span> <span class="n">ptr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__recordsz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span>

        <span class="c1"># shift offset if using noninitial offset</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">forward</span><span class="p">:</span>
            <span class="n">offset</span> <span class="o">=</span> <span class="n">offset</span> <span class="o">+</span> <span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># cannot write to uninitialized value</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;cannot write to an uninitialized value&quot;</span><span class="p">)</span>

        <span class="c1"># test shape of value</span>
        <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;&#39;value&#39; must have the same number of dimensions as the underlying&quot;</span>
                <span class="s2">&quot;data and must have the same shape in all but the final dimension,&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;shapes are </span><span class="si">{</span><span class="p">(</span><span class="o">*</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">,)</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">,)</span><span class="si">}</span><span class="s2"> respectively&quot;</span>
            <span class="p">)</span>

        <span class="c1"># cannot write beyond the data shape</span>
        <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;size of the final dimension of &#39;value&#39; (</span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">) cannot &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;exceed the length of the record (</span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">)&quot;</span>
            <span class="p">)</span>

        <span class="c1"># scalar offset</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">offset</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">ptr</span> <span class="o">=</span> <span class="n">_unwind_ptr</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">)</span>
            <span class="n">length</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="c1"># in-place</span>
            <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">indices</span> <span class="o">=</span> <span class="n">_unwind_tensor_ptr</span><span class="p">(</span>
                        <span class="n">ptr</span><span class="p">,</span>
                        <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span>
                            <span class="mi">0</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">offset</span><span class="o">.</span><span class="n">device</span>
                        <span class="p">),</span>
                        <span class="n">recordsz</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">indices</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

            <span class="c1"># noncontiguous range</span>
            <span class="k">elif</span> <span class="n">ptr</span> <span class="o">+</span> <span class="n">length</span> <span class="o">&gt;</span> <span class="n">recordsz</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="n">value</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">recordsz</span> <span class="o">-</span> <span class="n">ptr</span><span class="p">)],</span>
                        <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="n">length</span> <span class="o">-</span> <span class="p">(</span><span class="n">recordsz</span> <span class="o">-</span> <span class="n">ptr</span><span class="p">),</span> <span class="n">ptr</span><span class="p">)],</span>
                        <span class="n">value</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="n">recordsz</span> <span class="o">-</span> <span class="n">ptr</span><span class="p">,</span> <span class="kc">None</span><span class="p">)],</span>
                    <span class="p">),</span>
                    <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="c1"># contiguous range</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ptr</span><span class="p">)],</span>
                        <span class="n">value</span><span class="p">,</span>
                        <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="n">ptr</span> <span class="o">+</span> <span class="n">length</span><span class="p">,</span> <span class="kc">None</span><span class="p">)],</span>
                    <span class="p">),</span>
                    <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="c1"># shape must be the same as a slice</span>
        <span class="k">elif</span> <span class="p">(</span><span class="o">*</span><span class="n">offset</span><span class="o">.</span><span class="n">shape</span><span class="p">,)</span> <span class="o">!=</span> <span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;shape of &#39;offset&#39; </span><span class="si">{</span><span class="p">(</span><span class="o">*</span><span class="n">offset</span><span class="o">.</span><span class="n">shape</span><span class="p">,)</span><span class="si">}</span><span class="s2"> must have the shape &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],)</span><span class="si">}</span><span class="s2">, like a time slice of the stored value&quot;</span>
            <span class="p">)</span>

        <span class="c1"># tensor offset</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">indices</span> <span class="o">=</span> <span class="n">_unwind_tensor_ptr</span><span class="p">(</span>
                <span class="n">ptr</span><span class="p">,</span>
                <span class="n">offset</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">offset</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
                <span class="n">recordsz</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># write to storage</span>
            <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">data</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">value</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">value</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

<div class="viewcode-block" id="RecordTensor.insert"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordTensor.html#inferno.RecordTensor.insert">[docs]</a>    <span class="k">def</span> <span class="nf">insert</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">time</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">extrap</span><span class="p">:</span> <span class="n">Extrapolation</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
        <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">extrap_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Inserts new elements into the record tensor by time.</span>

<span class="sd">        If ``time`` is a scalar and is within tolerance of an integer index, then</span>
<span class="sd">        the slice will be inserted (with a scalar time, multiple inserts are not</span>
<span class="sd">        supported).</span>

<span class="sd">        If ``time`` is a tensor, interpolation will be called regardless, and the time</span>
<span class="sd">        passed into the extrapolation call will be set to either ``0`` or</span>
<span class="sd">        :py:attr:`self.dt`. Extrapolation results are then overwritten with exact values</span>
<span class="sd">        before returning.</span>

<span class="sd">        The :py:class:`~torch.dtype` of elements inserted into the underlying tensor</span>
<span class="sd">        will be cast back to the type of that tensor after extrapolation.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (torch.Tensor): _description_</span>
<span class="sd">            time (torch.Tensor | float): _description_</span>
<span class="sd">            extrap (Extrapolation | None, optional): _description_. Defaults to None.</span>
<span class="sd">            tolerance (float, optional): _description_. Defaults to 1e-6.</span>
<span class="sd">            offset (int, optional): _description_. Defaults to 0.</span>
<span class="sd">            inplace (bool, optional): _description_. Defaults to False.</span>
<span class="sd">            extrap_kwargs (dict[str, Any] | None, optional): _description_. Defaults to None.</span>

<span class="sd">        .. admonition:: Shape</span>
<span class="sd">            :class: tensorshape</span>

<span class="sd">            ``value``, ``time``:</span>

<span class="sd">            :math:`N_0 \times \cdots \times [D]`</span>

<span class="sd">            Where:</span>
<span class="sd">                * :math:`N_0, \ldots` are the dimensions of the underlying tensor,</span>
<span class="sd">                  excluding the record dimension.</span>
<span class="sd">                * :math:`D` is the number of times for each value to select.</span>

<span class="sd">        Warning:</span>
<span class="sd">            If there are multiple values/indices for each element being inserted (i.e.</span>
<span class="sd">            :math:`D &gt; 1`), if the indices are not unique, then the one of the values</span>
<span class="sd">            will be non-deterministically chosen and the gradient will be propagated</span>
<span class="sd">            incorrectly. Each ``time`` will correspond to two indices. If multiple</span>
<span class="sd">            values for each observation are to be inserted at once, there must be no</span>
<span class="sd">            overlap in the resultant indices. Use of :py:meth:`writerange` is suggested</span>
<span class="sd">            as an alternative.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__insert_tensor</span><span class="p">(</span>
                <span class="n">value</span><span class="p">,</span>
                <span class="n">time</span><span class="p">,</span>
                <span class="n">extrap</span><span class="p">,</span>
                <span class="n">tolerance</span><span class="o">=</span><span class="n">tolerance</span><span class="p">,</span>
                <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span>
                <span class="n">inplace</span><span class="o">=</span><span class="n">inplace</span><span class="p">,</span>
                <span class="n">extrap_kwargs</span><span class="o">=</span><span class="n">extrap_kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__insert_scalar</span><span class="p">(</span>
                <span class="n">value</span><span class="p">,</span>
                <span class="n">time</span><span class="p">,</span>
                <span class="n">extrap</span><span class="p">,</span>
                <span class="n">tolerance</span><span class="o">=</span><span class="n">tolerance</span><span class="p">,</span>
                <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span>
                <span class="n">inplace</span><span class="o">=</span><span class="n">inplace</span><span class="p">,</span>
                <span class="n">extrap_kwargs</span><span class="o">=</span><span class="n">extrap_kwargs</span><span class="p">,</span>
            <span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__insert_tensor</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">time</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">extrap</span><span class="p">:</span> <span class="n">Extrapolation</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
        <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">extrap_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># use nearest extrapolation by default</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">extrap</span><span class="p">:</span>
            <span class="n">extrap</span> <span class="o">=</span> <span class="n">extrap_nearest</span>

        <span class="c1"># strongly reference data and get record size and step time</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">,</span> <span class="n">dt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__recordsz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__dt</span>

        <span class="c1"># cannot insert into uninitialized value</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;cannot insert into uninitialized value&quot;</span><span class="p">)</span>

        <span class="c1"># apply offset to the pointer</span>
        <span class="n">ptr</span> <span class="o">=</span> <span class="n">_unwind_ptr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">)</span>

        <span class="c1"># conditionally unsqueeze value</span>
        <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">value</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;value&#39; has an incompatible number of dimensions (</span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2">), &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;it must have either </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="si">}</span><span class="s2"> or </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2"> dimensions&quot;</span>
            <span class="p">)</span>

        <span class="c1"># conditionally unsqueeze time</span>
        <span class="k">if</span> <span class="n">time</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">time</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;time&#39; has an incompatible number of dimensions (</span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2">), &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;it must have either </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="si">}</span><span class="s2"> or </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2"> dimensions&quot;</span>
            <span class="p">)</span>

        <span class="c1"># check that value and time are compatible</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">time</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;&#39;value&#39; and &#39;time&#39; must be of the same shape, or only differ by a &quot;</span>
                <span class="s2">&quot;final singleton dimension&quot;</span>
            <span class="p">)</span>

        <span class="c1"># check that times are in range</span>
        <span class="n">tmin</span><span class="p">,</span> <span class="n">tmax</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">amin</span><span class="p">(),</span> <span class="n">time</span><span class="o">.</span><span class="n">amax</span><span class="p">()</span>
        <span class="k">if</span> <span class="o">-</span><span class="n">tolerance</span> <span class="o">&lt;=</span> <span class="n">tmin</span> <span class="ow">or</span> <span class="n">tmax</span> <span class="o">&lt;=</span> <span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="n">recordsz</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">tolerance</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;all elements of &#39;time&#39; (min=</span><span class="si">{</span><span class="n">tmin</span><span class="si">}</span><span class="s2">, max=</span><span class="si">{</span><span class="n">tmax</span><span class="si">}</span><span class="s2">) must be within &quot;</span>
                <span class="sa">f</span><span class="s2">&quot; the valid range of observations including tolerance, the interval &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="o">-</span><span class="n">tolerance</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="n">recordsz</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">tolerance</span><span class="si">}</span><span class="s2">]&quot;</span>
            <span class="p">)</span>

        <span class="c1"># compute continuous offsets</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="n">time</span> <span class="o">/</span> <span class="n">dt</span>
        <span class="n">rounded</span> <span class="o">=</span> <span class="n">offset</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">dt</span> <span class="o">*</span> <span class="n">rounded</span> <span class="o">-</span> <span class="n">time</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">tolerance</span><span class="p">,</span> <span class="n">rounded</span><span class="p">,</span> <span class="n">offset</span>
        <span class="p">)</span>

        <span class="c1"># access data by index and extrapolate</span>
        <span class="n">prev_idx</span> <span class="o">=</span> <span class="n">_unwind_tensor_ptr</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">offset</span><span class="o">.</span><span class="n">ceil</span><span class="p">(),</span> <span class="n">recordsz</span><span class="p">)</span>
        <span class="n">next_idx</span> <span class="o">=</span> <span class="n">_unwind_tensor_ptr</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">offset</span><span class="o">.</span><span class="n">floor</span><span class="p">(),</span> <span class="n">recordsz</span><span class="p">)</span>

        <span class="n">prev_data</span><span class="p">,</span> <span class="n">next_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor_split</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">prev_idx</span><span class="p">,</span> <span class="n">next_idx</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="n">offset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],),</span>
        <span class="p">)</span>

        <span class="n">prev_exdata</span><span class="p">,</span> <span class="n">next_exdata</span> <span class="o">=</span> <span class="n">extrap</span><span class="p">(</span>
            <span class="n">value</span><span class="p">,</span>
            <span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="n">offset</span> <span class="o">%</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">prev_data</span><span class="p">,</span>
            <span class="n">next_data</span><span class="p">,</span>
            <span class="n">dt</span><span class="p">,</span>
            <span class="o">**</span><span class="p">({</span><span class="n">extrap_kwargs</span> <span class="k">if</span> <span class="n">extrap_kwargs</span> <span class="k">else</span> <span class="p">{}}),</span>
        <span class="p">)</span>

        <span class="c1"># bypass extrapolation for exact indices</span>
        <span class="n">bypass</span> <span class="o">=</span> <span class="n">prev_idx</span> <span class="o">==</span> <span class="n">next_idx</span>
        <span class="n">prev_exdata</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">bypass</span><span class="p">,</span> <span class="n">prev_data</span><span class="p">,</span> <span class="n">prev_exdata</span><span class="p">)</span>
        <span class="n">next_exdata</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">bypass</span><span class="p">,</span> <span class="n">next_data</span><span class="p">,</span> <span class="n">next_exdata</span><span class="p">)</span>

        <span class="c1"># write to storage</span>
        <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">data</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span>
                    <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">prev_idx</span><span class="p">,</span> <span class="n">next_idx</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">prev_exdata</span><span class="p">,</span> <span class="n">next_exdata</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
                <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="n">data</span><span class="p">,</span>
                <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">prev_idx</span><span class="p">,</span> <span class="n">next_idx</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">prev_exdata</span><span class="p">,</span> <span class="n">next_exdata</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">__insert_scalar</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">time</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">extrap</span><span class="p">:</span> <span class="n">Extrapolation</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
        <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">extrap_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># use nearest extrapolation by default</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">extrap</span><span class="p">:</span>
            <span class="n">extrap</span> <span class="o">=</span> <span class="n">extrap_nearest</span>

        <span class="c1"># strongly reference data and get record size and step time</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">,</span> <span class="n">dt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__recordsz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__dt</span>

        <span class="c1"># cannot insert into uninitialized value</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;cannot insert into uninitialized value&quot;</span><span class="p">)</span>

        <span class="c1"># apply offset to the pointer</span>
        <span class="n">ptr</span> <span class="o">=</span> <span class="n">_unwind_ptr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">)</span>

        <span class="c1"># conditionally unsqueeze value</span>
        <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">value</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;when specified with </span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2"> dimensions, &#39;value&#39; must have a &quot;</span>
                    <span class="s2">&quot;final dimension of size 1&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;value&#39; has an incompatible number of dimensions (</span><span class="si">{</span><span class="n">value</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2">), &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;it must have either </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="si">}</span><span class="s2"> or </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2"> dimensions&quot;</span>
            <span class="p">)</span>

        <span class="c1"># cast time and check for a valid range</span>
        <span class="n">disptime</span><span class="p">,</span> <span class="n">time</span> <span class="o">=</span> <span class="n">time</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
        <span class="k">if</span> <span class="o">-</span><span class="n">tolerance</span> <span class="o">&lt;=</span> <span class="n">time</span> <span class="o">&lt;=</span> <span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="n">recordsz</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">tolerance</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;time&#39; (</span><span class="si">{</span><span class="n">disptime</span><span class="si">}</span><span class="s2">) must be within the valid range of observations &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;including tolerance, the interval [</span><span class="si">{</span><span class="o">-</span><span class="n">tolerance</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="n">recordsz</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">tolerance</span><span class="si">}</span><span class="s2">]&quot;</span>
            <span class="p">)</span>

        <span class="c1"># compute continuous offset</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="n">time</span> <span class="o">/</span> <span class="n">dt</span>

        <span class="c1"># index is within tolerance of an observation</span>
        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">dt</span> <span class="o">*</span> <span class="nb">round</span><span class="p">(</span><span class="n">offset</span><span class="p">)</span> <span class="o">-</span> <span class="n">time</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">tolerance</span><span class="p">:</span>
            <span class="c1"># index of the observation to replace</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">_unwind_ptr</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">offset</span><span class="p">),</span> <span class="n">recordsz</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="p">)],</span>
                        <span class="n">value</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
                        <span class="n">data</span><span class="p">[:,</span> <span class="nb">slice</span><span class="p">(</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">)],</span>
                    <span class="p">),</span>
                    <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="c1"># extrapolate to neighboring observations</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># indices of the nearest observations</span>
            <span class="n">prev_idx</span> <span class="o">=</span> <span class="n">_unwind_ptr</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">offset</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">)</span>
            <span class="n">next_idx</span> <span class="o">=</span> <span class="n">_unwind_ptr</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">)</span>

            <span class="c1"># extrapolates data to write</span>
            <span class="n">prev_exdata</span><span class="p">,</span> <span class="n">next_exdata</span> <span class="o">=</span> <span class="n">extrap</span><span class="p">(</span>
                <span class="n">value</span><span class="p">,</span>
                <span class="n">full</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="n">offset</span> <span class="o">%</span> <span class="mi">1</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)),</span>
                <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">prev_idx</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">next_idx</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                <span class="n">dt</span><span class="p">,</span>
                <span class="o">**</span><span class="p">({</span><span class="n">extrap_kwargs</span> <span class="k">if</span> <span class="n">extrap_kwargs</span> <span class="k">else</span> <span class="p">{}}),</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">prev_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">prev_exdata</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">next_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">next_exdata</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># previous sample is at the final tensor index</span>
            <span class="k">elif</span> <span class="n">prev_idx</span> <span class="o">&gt;</span> <span class="n">next_idx</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="n">next_exdata</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
                        <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="n">next_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">prev_idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)],</span>
                        <span class="n">prev_exdata</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
                    <span class="p">),</span>
                    <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="c1"># previous sample is not at the final tensor index</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">prev_idx</span><span class="p">)],</span>
                        <span class="n">prev_exdata</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
                        <span class="n">next_exdata</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
                        <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="n">next_idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">)],</span>
                    <span class="p">),</span>
                    <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                <span class="p">)</span>

<div class="viewcode-block" id="RecordTensor.select"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordTensor.html#inferno.RecordTensor.select">[docs]</a>    <span class="k">def</span> <span class="nf">select</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">time</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">interp</span><span class="p">:</span> <span class="n">Interpolation</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
        <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">interp_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Selects previously observed elements of the record tensor by time.</span>

<span class="sd">        If ``time`` is a scalar and is within tolerance of an integer index, then</span>
<span class="sd">        a slice will be returned without ever attempting interpolation.</span>

<span class="sd">        If ``time`` is a tensor, interpolation will be called regardless, and the time</span>
<span class="sd">        passed into the interpolation call will be set to either ``0`` or</span>
<span class="sd">        :py:attr:`self.dt`. Interpolation results are then overwritten with exact values</span>
<span class="sd">        before returning.</span>

<span class="sd">        If ``time`` is a tensor, then ``tolerance`` can also be a tensor.</span>

<span class="sd">        Args:</span>
<span class="sd">            time (torch.Tensor | float): time or times for each element before present</span>
<span class="sd">                to select.</span>
<span class="sd">            interp (Interpolation | None, optional): method to interpolate between</span>
<span class="sd">                discrete time steps, selects the nearest when ``None``.</span>
<span class="sd">                Defaults to ``None``.</span>
<span class="sd">            tolerance (float, optional): maximum difference in time from</span>
<span class="sd">                a discrete sample to consider a time co-occuring with the sample.</span>
<span class="sd">                Defaults to 1e-6.</span>
<span class="sd">            offset (int, optional): number of steps before the pointer to consider the</span>
<span class="sd">                zero point. Defaults to 1.</span>
<span class="sd">            interp_kwargs (dict[str, Any] | None, optional): dictionary of keyword</span>
<span class="sd">                arguments to pass to ``interp``. Defaults to ``None``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: interpolated values selected at a prior times.</span>

<span class="sd">        .. admonition:: Shape</span>
<span class="sd">            :class: tensorshape</span>

<span class="sd">            ``time``:</span>

<span class="sd">            :math:`N_0 \times \cdots \times [D]`</span>

<span class="sd">            ``return``:</span>

<span class="sd">            :math:`N_0 \times \cdots \times [D]`</span>

<span class="sd">            Where:</span>
<span class="sd">                * :math:`N_0, \ldots` are the dimensions of the constrained tensor.</span>
<span class="sd">                * :math:`D` is the number of times for each value to select.</span>

<span class="sd">        Tip:</span>
<span class="sd">            Mimicing the behavior of :py:func:`torch.gather`, if ``time`` is out of the</span>
<span class="sd">            valid range, a :py:class:`ValueError` will be thrown. To avoid this, clamp</span>
<span class="sd">            ``time`` like ``time.clamp(0, recordtensor.duration)``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__select_tensor</span><span class="p">(</span>
                <span class="n">time</span><span class="p">,</span>
                <span class="n">interp</span><span class="p">,</span>
                <span class="n">tolerance</span><span class="o">=</span><span class="n">tolerance</span><span class="p">,</span>
                <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span>
                <span class="n">interp_kwargs</span><span class="o">=</span><span class="n">interp_kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__select_scalar</span><span class="p">(</span>
                <span class="n">time</span><span class="p">,</span>
                <span class="n">interp</span><span class="p">,</span>
                <span class="n">tolerance</span><span class="o">=</span><span class="n">tolerance</span><span class="p">,</span>
                <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span>
                <span class="n">interp_kwargs</span><span class="o">=</span><span class="n">interp_kwargs</span><span class="p">,</span>
            <span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__select_tensor</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">time</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">interp</span><span class="p">:</span> <span class="n">Interpolation</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
        <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">interp_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># use nearest interpolation by default</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">interp</span><span class="p">:</span>
            <span class="n">interp</span> <span class="o">=</span> <span class="n">interp_nearest</span>

        <span class="c1"># strongly reference data and get record size and step time</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">,</span> <span class="n">dt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__recordsz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__dt</span>

        <span class="c1"># cannot select from uninitialized value</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;cannot select from uninitialized value&quot;</span><span class="p">)</span>

        <span class="c1"># apply offset to the pointer</span>
        <span class="n">ptr</span> <span class="o">=</span> <span class="n">_unwind_ptr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">)</span>

        <span class="c1"># check that times are in range</span>
        <span class="n">tmin</span><span class="p">,</span> <span class="n">tmax</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">amin</span><span class="p">(),</span> <span class="n">time</span><span class="o">.</span><span class="n">amax</span><span class="p">()</span>
        <span class="k">if</span> <span class="o">-</span><span class="n">tolerance</span> <span class="o">&lt;=</span> <span class="n">tmin</span> <span class="ow">or</span> <span class="n">tmax</span> <span class="o">&lt;=</span> <span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="n">recordsz</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">tolerance</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;all elements of &#39;time&#39; (min=</span><span class="si">{</span><span class="n">tmin</span><span class="si">}</span><span class="s2">, max=</span><span class="si">{</span><span class="n">tmax</span><span class="si">}</span><span class="s2">) must be within &quot;</span>
                <span class="sa">f</span><span class="s2">&quot; the valid range of observations including tolerance, the interval &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="o">-</span><span class="n">tolerance</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="n">recordsz</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">tolerance</span><span class="si">}</span><span class="s2">]&quot;</span>
            <span class="p">)</span>

        <span class="c1"># check if the output should be squeezed</span>
        <span class="k">if</span> <span class="n">time</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">squeeze</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">time</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
            <span class="n">squeeze</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;time&#39; has an incompatible number of dimensions (</span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2">), &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;it must have either </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="si">}</span><span class="s2"> or </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2"> dimensions&quot;</span>
            <span class="p">)</span>

        <span class="c1"># compute continuous offsets</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="n">time</span> <span class="o">/</span> <span class="n">dt</span>
        <span class="n">rounded</span> <span class="o">=</span> <span class="n">offset</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">dt</span> <span class="o">*</span> <span class="n">rounded</span> <span class="o">-</span> <span class="n">time</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">tolerance</span><span class="p">,</span> <span class="n">rounded</span><span class="p">,</span> <span class="n">offset</span>
        <span class="p">)</span>

        <span class="c1"># access data by index and interpolate</span>
        <span class="n">prev_idx</span> <span class="o">=</span> <span class="n">_unwind_tensor_ptr</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">offset</span><span class="o">.</span><span class="n">ceil</span><span class="p">(),</span> <span class="n">recordsz</span><span class="p">)</span>
        <span class="n">next_idx</span> <span class="o">=</span> <span class="n">_unwind_tensor_ptr</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">offset</span><span class="o">.</span><span class="n">floor</span><span class="p">(),</span> <span class="n">recordsz</span><span class="p">)</span>

        <span class="n">prev_data</span><span class="p">,</span> <span class="n">next_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor_split</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">prev_idx</span><span class="p">,</span> <span class="n">next_idx</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)),</span>
            <span class="p">(</span><span class="n">offset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],),</span>
        <span class="p">)</span>

        <span class="n">res</span> <span class="o">=</span> <span class="n">interp</span><span class="p">(</span>
            <span class="n">prev_data</span><span class="p">,</span>
            <span class="n">next_data</span><span class="p">,</span>
            <span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="n">offset</span> <span class="o">%</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">dt</span><span class="p">,</span>
            <span class="o">**</span><span class="p">(</span><span class="n">interp_kwargs</span> <span class="k">if</span> <span class="n">interp_kwargs</span> <span class="k">else</span> <span class="p">{}),</span>
        <span class="p">)</span>

        <span class="c1"># bypass interpolation for exact indices</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">prev_idx</span> <span class="o">==</span> <span class="n">next_idx</span><span class="p">,</span> <span class="n">prev_data</span><span class="p">,</span> <span class="n">res</span><span class="p">)</span>

        <span class="c1"># conditionally squeeze and return</span>
        <span class="k">return</span> <span class="n">res</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">squeeze</span> <span class="k">else</span> <span class="n">res</span>

    <span class="k">def</span> <span class="nf">__select_scalar</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">time</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">interp</span><span class="p">:</span> <span class="n">Interpolation</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
        <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">interp_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="c1"># use nearest interpolation by default</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">interp</span><span class="p">:</span>
            <span class="n">interp</span> <span class="o">=</span> <span class="n">interp_nearest</span>

        <span class="c1"># strongly reference data and get record size and step time</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">,</span> <span class="n">dt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__recordsz</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__dt</span>

        <span class="c1"># cannot select from uninitialized value</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;cannot select from uninitialized value&quot;</span><span class="p">)</span>

        <span class="c1"># apply offset to the pointer</span>
        <span class="n">ptr</span> <span class="o">=</span> <span class="n">_unwind_ptr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__pointer</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">)</span>

        <span class="c1"># cast time and check for a valid range</span>
        <span class="n">disptime</span><span class="p">,</span> <span class="n">time</span> <span class="o">=</span> <span class="n">time</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
        <span class="k">if</span> <span class="o">-</span><span class="n">tolerance</span> <span class="o">&lt;=</span> <span class="n">time</span> <span class="o">&lt;=</span> <span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="n">recordsz</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">tolerance</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;time&#39; (</span><span class="si">{</span><span class="n">disptime</span><span class="si">}</span><span class="s2">) must be within the valid range of observations &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;including tolerance, the interval [</span><span class="si">{</span><span class="o">-</span><span class="n">tolerance</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="n">recordsz</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">tolerance</span><span class="si">}</span><span class="s2">]&quot;</span>
            <span class="p">)</span>

        <span class="c1"># compute continuous offset</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="n">time</span> <span class="o">/</span> <span class="n">dt</span>

        <span class="c1"># index is within tolerance of an observation</span>
        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">dt</span> <span class="o">*</span> <span class="nb">round</span><span class="p">(</span><span class="n">offset</span><span class="p">)</span> <span class="o">-</span> <span class="n">time</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">tolerance</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">_unwind_ptr</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">offset</span><span class="p">),</span> <span class="n">recordsz</span><span class="p">)]</span>

        <span class="c1"># interpolate between observation</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">interp</span><span class="p">(</span>
                <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">_unwind_ptr</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">offset</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">)],</span>
                <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">_unwind_ptr</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="n">offset</span><span class="p">,</span> <span class="n">recordsz</span><span class="p">)],</span>
                <span class="n">full</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="n">offset</span> <span class="o">%</span> <span class="mi">1</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)),</span>
                <span class="n">dt</span><span class="p">,</span>
                <span class="o">**</span><span class="p">(</span><span class="n">interp_kwargs</span> <span class="k">if</span> <span class="n">interp_kwargs</span> <span class="k">else</span> <span class="p">{}),</span>
            <span class="p">)</span>

<div class="viewcode-block" id="RecordTensor.reconstrain"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordTensor.html#inferno.RecordTensor.reconstrain">[docs]</a>    <span class="k">def</span> <span class="nf">reconstrain</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Add, edit, or remove a constraint.</span>

<span class="sd">        Like :py:meth:`ShapeTensor.reconstrain`, except ``dim`` is modified</span>
<span class="sd">        to account for the record dimension. Negative values of ``dim`` will have</span>
<span class="sd">        ``1`` subtracted from them.</span>

<span class="sd">        Args:</span>
<span class="sd">            dim (int): dimension on which to modify the constraint.</span>
<span class="sd">            size (int | None): new size for the specified dimension.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | nn.Parameter | None: newly constrained value.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># align so oldest data are overwritten or prepended to</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__data</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">align</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">ShapedTensor</span><span class="o">.</span><span class="n">reconstrain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span> <span class="o">-</span> <span class="p">(</span><span class="n">dim</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">),</span> <span class="n">size</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="RecordModule"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordModule.html#inferno.RecordModule">[docs]</a><span class="k">class</span> <span class="nc">RecordModule</span><span class="p">(</span><span class="n">DimensionalModule</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Module with support for buffers and parameters with time-based indexing.</span>

<span class="sd">    Args:</span>
<span class="sd">        step_time (float): length of time between stored values in the record.</span>
<span class="sd">        duration (float): length of time over which prior values are stored.</span>

<span class="sd">    Caution:</span>
<span class="sd">        When restoring from a state dictionary, the &quot;pointer&quot; to the next time slice to</span>
<span class="sd">        overwrite is preserved along with the names of added constrained buffers and</span>
<span class="sd">        parameters, but the step time and duration are not.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">step_time</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">duration</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># argument validation</span>
        <span class="n">step_time</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="s2">&quot;step_time&quot;</span><span class="p">,</span> <span class="n">step_time</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
        <span class="n">duration</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">gte</span><span class="p">(</span><span class="s2">&quot;duration&quot;</span><span class="p">,</span> <span class="n">duration</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>

        <span class="c1"># size of the history dimension</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">duration</span> <span class="o">/</span> <span class="n">step_time</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># call superclass constructor</span>
        <span class="n">DimensionalModule</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="p">))</span>

        <span class="c1"># transient state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__step_time</span> <span class="o">=</span> <span class="n">step_time</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__duration</span> <span class="o">=</span> <span class="n">duration</span>

        <span class="c1"># persistent state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_extra</span><span class="p">(</span><span class="s2">&quot;_pointers&quot;</span><span class="p">,</span> <span class="nb">dict</span><span class="p">())</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dt</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Length of time between stored values in history.</span>

<span class="sd">        In the same units as :py:attr:`self.duration`.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (float): new time step length.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: length of the time step.</span>

<span class="sd">        Note:</span>
<span class="sd">            If a :py:meth:`reconstrain` operation needs to be performed, all state will</span>
<span class="sd">            be overwritten with zeros.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__step_time</span>

    <span class="nd">@dt</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">dt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># cast value as float and validate</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>

        <span class="c1"># recompute size of the history dimension</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__duration</span> <span class="o">/</span> <span class="n">value</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># reconstrain if required</span>
        <span class="k">if</span> <span class="n">size</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">recordsz</span><span class="p">:</span>
            <span class="n">DimensionalModule</span><span class="o">.</span><span class="n">reconstrain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>

        <span class="c1"># set revised step time</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__step_time</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">duration</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Length of time over which prior values are stored.</span>

<span class="sd">        In the same units as :py:attr:`self.dt`.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (float): new length of the history to store.</span>

<span class="sd">        Returns:</span>
<span class="sd">            float: length of the record.</span>

<span class="sd">        Note:</span>
<span class="sd">            If a :py:meth:`reconstrain` operation needs to be performed, all state will</span>
<span class="sd">            be overwritten with zeros.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__duration</span>

    <span class="nd">@duration</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">duration</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># cast value as float and validate</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">gte</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>

        <span class="c1"># recompute size of the history dimension</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">value</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">__step_time</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="c1"># reconstrain if required</span>
        <span class="k">if</span> <span class="n">size</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">recordsz</span><span class="p">:</span>
            <span class="n">DimensionalModule</span><span class="o">.</span><span class="n">reconstrain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>

        <span class="c1"># set revised history length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__duration</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">recordsz</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Number of stored time slices for each record tensor.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: length of the record, in number of slices.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">constraints</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_constrained_record</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Gets the value of a constraint which is a record.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str): name of the buffer or parameter.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: the name specifies a buffer or parameter which was not</span>
<span class="sd">                constrained by :py:class:`RecordModule`.</span>
<span class="sd">            RuntimeError: the name specifies an uninitialized attribute, i.e. one which</span>
<span class="sd">                is ``None``, has no elements, or is a scalar (a 0-dimensional tensor).</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | nn.Parameter: constrained record tensor.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_constrained</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pointers</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;name&#39; (&#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;) specifies an improperly constrained attribute&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ignore_tensor</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;name&#39; (&#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;) specifies an uninitialized attribute&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">data</span>

<div class="viewcode-block" id="RecordModule.register_constrained"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordModule.html#inferno.RecordModule.register_constrained">[docs]</a>    <span class="k">def</span> <span class="nf">register_constrained</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registers an existing buffer or parameter as constrained.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str): fully-qualified string name of the buffer or</span>
<span class="sd">                parameter to register.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: shape of the buffer or parameter is invalid.</span>
<span class="sd">            AttributeError: attribute is not a registered buffer or parameter.</span>

<span class="sd">        Caution:</span>
<span class="sd">            A registered :py:class:`~torch.nn.Parameter` with a value of ``None``</span>
<span class="sd">            cannot be constrained as it is not returned by</span>
<span class="sd">            :py:meth:`~torch.nn.Module.get_parameter`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">DimensionalModule</span><span class="o">.</span><span class="n">register_constrained</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pointers</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_pointers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span></div>

<div class="viewcode-block" id="RecordModule.deregister_constrained"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordModule.html#inferno.RecordModule.deregister_constrained">[docs]</a>    <span class="k">def</span> <span class="nf">deregister_constrained</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Deregisters a buffer or parameter as constrained.</span>

<span class="sd">        If the name given isn&#39;t a constrained buffer or parameter, calling this does</span>
<span class="sd">        nothing.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str): fully-qualified string name of the buffer or</span>
<span class="sd">                parameter to register.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">DimensionalModule</span><span class="o">.</span><span class="n">deregister_constrained</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pointers</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pointers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span></div>

<div class="viewcode-block" id="RecordModule.reconstrain"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordModule.html#inferno.RecordModule.reconstrain">[docs]</a>    <span class="k">def</span> <span class="nf">reconstrain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">RecordModule</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Modifies constraints.</span>

<span class="sd">        Adding constraints will not modify the constrained tensors, whereas modifying</span>
<span class="sd">        an existing constraint will create a new zero-tensor with the shape of that</span>
<span class="sd">        dimension modified.</span>

<span class="sd">        If the tensor was modified to be compatible with the new constraint ahead</span>
<span class="sd">        of time (i.e. if :py:attr:`liveconstrain` is ``False`` and was set with its new value),</span>
<span class="sd">        then reallocation will not occur.</span>

<span class="sd">        Args:</span>
<span class="sd">            dim (int): dimension to which a constraint should be added, removed,</span>
<span class="sd">                or modified.</span>
<span class="sd">            size (int | None): size of the new constraint, None if the constraint is</span>
<span class="sd">                to be removed.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: constrained buffer or parameter is no longer a compatible shape.</span>
<span class="sd">            RuntimeError: constrained buffer or parameter would not be valid after the</span>
<span class="sd">                change in constraints.</span>

<span class="sd">        Returns:</span>
<span class="sd">            RecordModule: self.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">dim</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(RecordModule) cannot reconstrain the record &quot;</span>
                <span class="s2">&quot;dimension (-1)&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">DimensionalModule</span><span class="o">.</span><span class="n">reconstrain</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span></div>

<div class="viewcode-block" id="RecordModule.reset"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordModule.html#inferno.RecordModule.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Resets a constrained attribute to some value or values.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str): name of the attribute to target.</span>
<span class="sd">            data (Any): data to insert.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_constrained_record</span><span class="p">(</span><span class="n">name</span><span class="p">)[:]</span> <span class="o">=</span> <span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pointers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span></div>

<div class="viewcode-block" id="RecordModule.latest"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordModule.html#inferno.RecordModule.latest">[docs]</a>    <span class="k">def</span> <span class="nf">latest</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Retrieves the most recent slice of a constrained attribute.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str): name of the attribute to target.</span>
<span class="sd">            offset (int, optional): number of steps before present to select from.</span>
<span class="sd">                Defaults to 1.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: most recent slice of the tensor selected.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_constrained_record</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_pointers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">-</span> <span class="nb">int</span><span class="p">(</span><span class="n">offset</span><span class="p">))</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">recordsz</span><span class="p">]</span></div>

<div class="viewcode-block" id="RecordModule.record"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordModule.html#inferno.RecordModule.record">[docs]</a>    <span class="k">def</span> <span class="nf">record</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Overwrites the record at the current slice and increments the pointer.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str): name of the attribute to target.</span>
<span class="sd">            value (torch.Tensor): value to write into the current time step.</span>
<span class="sd">            offset (int, optional): number of steps before present to update.</span>
<span class="sd">                Defaults to 0.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_constrained_record</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;value&#39; has shape of </span><span class="si">{</span><span class="nb">tuple</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s2"> which does not match the &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;required shape of </span><span class="si">{</span><span class="nb">tuple</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_pointers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">-</span> <span class="nb">int</span><span class="p">(</span><span class="n">offset</span><span class="p">))</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">recordsz</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pointers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_pointers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">recordsz</span></div>

<div class="viewcode-block" id="RecordModule.select"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordModule.html#inferno.RecordModule.select">[docs]</a>    <span class="k">def</span> <span class="nf">select</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">time</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">interp</span><span class="p">:</span> <span class="n">Interpolation</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">tolerance</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
        <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Selects elements of a constrained attribute based on prior time.</span>

<span class="sd">        If ``time`` is a scalar and is within tolerance of an integer index, then</span>
<span class="sd">        a slice will be returned without ever attempting interpolation.</span>

<span class="sd">        If ``time`` is a tensor, interpolation will be called regardless, and the time</span>
<span class="sd">        passed into the interpolation call will be set to either ``0`` or</span>
<span class="sd">        :py:attr:`self.dt`. Interpolation results are then overwritten with exact values</span>
<span class="sd">        before returning. If ``time`` is a tensor, then ``tolerance`` can also be</span>
<span class="sd">        a tensor.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str): name of the attribute from which to select.</span>
<span class="sd">            time (float | torch.Tensor): time(s) before present to select from.</span>
<span class="sd">            interp (Interpolation): method to interpolate between discrete time steps.</span>
<span class="sd">            tolerance (float, optional): maximum difference in time from</span>
<span class="sd">                a discrete sample to consider a time co-occuring with the sample.</span>
<span class="sd">                Defaults to 1e-6.</span>
<span class="sd">            offset (int, optional): window index offset as number of steps prior to the</span>
<span class="sd">                location of the next time slice to overwrite. Defaults to 1.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: interpolated values selected at a prior time(s).</span>

<span class="sd">        .. admonition:: Shape</span>
<span class="sd">            :class: tensorshape</span>

<span class="sd">            ``time``:</span>

<span class="sd">            :math:`N_0 \times \cdots \times [D]`</span>

<span class="sd">            ``return``:</span>

<span class="sd">            :math:`N_0 \times \cdots \times [D]`</span>

<span class="sd">            Where:</span>
<span class="sd">                * :math:`N_0, \ldots` are the dimensions of the constrained tensor.</span>
<span class="sd">                * :math:`D` is the number of times for each value to select.</span>

<span class="sd">        Tip:</span>
<span class="sd">            Mimicing the behavior of :py:func:`torch.gather`, if ``time`` is out of the</span>
<span class="sd">            valid range, a :py:class:`ValueError` will be thrown. To avoid this, clamp</span>
<span class="sd">            ``time`` like ``time.clamp(0, module.duration)``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># get underlying data</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_constrained_record</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

        <span class="c1"># apply offset to pointer</span>
        <span class="n">pointer</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_pointers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">-</span> <span class="nb">int</span><span class="p">(</span><span class="n">offset</span><span class="p">))</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">recordsz</span>

        <span class="c1"># tensor selector</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># cast values and test</span>
            <span class="n">time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">time</span><span class="o">.</span><span class="n">is_floating_point</span><span class="p">():</span>
                <span class="n">time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">_</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">gte</span><span class="p">(</span><span class="s2">&quot;time&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">amin</span><span class="p">(),</span> <span class="o">-</span><span class="n">tolerance</span><span class="p">)</span>
            <span class="n">_</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">lte</span><span class="p">(</span>
                <span class="s2">&quot;time&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">.</span><span class="n">amax</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recordsz</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">tolerance</span>
            <span class="p">)</span>

            <span class="c1"># check if the output should be squeezed</span>
            <span class="k">if</span> <span class="n">time</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">squeeze</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="n">time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">time</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
                <span class="n">squeeze</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;&#39;time&#39; has incompatible number of dimensions </span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2">, &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;must have either </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2"> or </span><span class="si">{</span><span class="n">data</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="si">}</span><span class="s2"> dimensions&quot;</span>
                <span class="p">)</span>

            <span class="c1"># compute continuous index</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">time</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span>
            <span class="n">rindex</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dt</span> <span class="o">*</span> <span class="n">rindex</span> <span class="o">-</span> <span class="n">time</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="n">tolerance</span><span class="p">,</span> <span class="n">rindex</span><span class="p">,</span> <span class="n">index</span>
            <span class="p">)</span>

            <span class="c1"># access data by index and interpolate</span>
            <span class="n">prev_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">pointer</span> <span class="o">-</span> <span class="n">index</span><span class="o">.</span><span class="n">ceil</span><span class="p">()</span><span class="o">.</span><span class="n">long</span><span class="p">())</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">recordsz</span>
            <span class="n">prev_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">prev_idx</span><span class="p">)</span>

            <span class="n">next_idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">pointer</span> <span class="o">-</span> <span class="n">index</span><span class="o">.</span><span class="n">floor</span><span class="p">()</span><span class="o">.</span><span class="n">long</span><span class="p">())</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">recordsz</span>
            <span class="n">next_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">next_idx</span><span class="p">)</span>

            <span class="n">res</span> <span class="o">=</span> <span class="n">interp</span><span class="p">(</span><span class="n">prev_data</span><span class="p">,</span> <span class="n">next_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="n">index</span> <span class="o">%</span> <span class="mi">1</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">)</span>

            <span class="c1"># bypass interpolation for exact indices</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">prev_idx</span> <span class="o">==</span> <span class="n">next_idx</span><span class="p">,</span> <span class="n">prev_data</span><span class="p">,</span> <span class="n">res</span><span class="p">)</span>

            <span class="c1"># conditionally squeeze</span>
            <span class="k">return</span> <span class="n">res</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">squeeze</span> <span class="k">else</span> <span class="n">res</span>

        <span class="c1"># scalar selector</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># cast values and test</span>
            <span class="n">time</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">minmax_incl</span><span class="p">(</span>
                <span class="s2">&quot;time&quot;</span><span class="p">,</span>
                <span class="n">time</span><span class="p">,</span>
                <span class="o">-</span><span class="n">tolerance</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recordsz</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">tolerance</span><span class="p">,</span>
                <span class="nb">float</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># compute continuous index</span>
            <span class="n">index</span> <span class="o">=</span> <span class="n">time</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">dt</span>
            <span class="n">rindex</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">index</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dt</span> <span class="o">*</span> <span class="n">rindex</span> <span class="o">-</span> <span class="n">time</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">tolerance</span><span class="p">:</span>
                <span class="n">index</span> <span class="o">=</span> <span class="n">rindex</span>

            <span class="c1"># integer index (no interpolation)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">(</span><span class="n">pointer</span> <span class="o">-</span> <span class="n">index</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">recordsz</span><span class="p">]</span>

            <span class="c1"># float index (interpolation)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">interp</span><span class="p">(</span>
                    <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">(</span><span class="n">pointer</span> <span class="o">-</span> <span class="nb">int</span><span class="p">(</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">recordsz</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                    <span class="n">data</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">(</span><span class="n">pointer</span> <span class="o">-</span> <span class="nb">int</span><span class="p">(</span><span class="n">index</span><span class="p">))</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">recordsz</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span>
                        <span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">dt</span> <span class="o">*</span> <span class="p">(</span><span class="n">index</span> <span class="o">%</span> <span class="mi">1</span><span class="p">),</span>
                        <span class="n">dtype</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                        <span class="n">device</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">dt</span><span class="p">,</span>
                <span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span></div>

<div class="viewcode-block" id="RecordModule.aligned"><a class="viewcode-back" href="../../../reference/generated/inferno.RecordModule.html#inferno.RecordModule.aligned">[docs]</a>    <span class="k">def</span> <span class="nf">aligned</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">latest_first</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">offset</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Full aligned record of a recorded tensor.</span>

<span class="sd">        The native storage order is latest data at the last index (after being aligned</span>
<span class="sd">        with :py:func:`torch.roll`). By default this will return the latest data at</span>
<span class="sd">        the first index.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str): name of the attribute to target.</span>
<span class="sd">            latest_first (bool, optional): if the most recent slice should be at the</span>
<span class="sd">                zeroth index. Defaults to True.</span>
<span class="sd">            offset (int, optional): window index offset as number of steps prior to the</span>
<span class="sd">                location of the next time slice to overwrite. Defaults to 1.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: _description_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># access raw data</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_constrained_record</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

        <span class="c1"># align based on pointer and offset (latest is last, native ordering)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">roll</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">offset</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pointers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># reverse if latest is first</span>
        <span class="k">if</span> <span class="n">latest_first</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">data</span></div></div>


<span class="k">def</span> <span class="nf">_detach_handles</span><span class="p">(</span><span class="o">*</span><span class="n">handles</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">handles</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">h</span><span class="p">:</span>
            <span class="n">h</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>


<div class="viewcode-block" id="Hook"><a class="viewcode-back" href="../../../reference/generated/inferno.Hook.html#inferno.Hook">[docs]</a><span class="k">class</span> <span class="nc">Hook</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Provides and manages forward hook and prehook functionality.</span>

<span class="sd">    `Hook` provides functionality to register and deregister itself as</span>
<span class="sd">    forward hook with a :py:class:`~torch.nn.Module` object. This is performed using</span>
<span class="sd">    :py:meth:`~torch.nn.Module.register_forward_hook` to register itself as a forward</span>
<span class="sd">    hook and it manages the returned :py:class:`~torch.utils.hooks.RemovableHandle`</span>
<span class="sd">    to deregister itself.</span>

<span class="sd">    Args:</span>
<span class="sd">        prehook (Callable | None, optional): function to call before hooked module&#39;s</span>
<span class="sd">            :py:meth:`~torch.nn.Module.forward`. Defaults to ``None``.</span>
<span class="sd">        posthook (Callable | None, optional): function to call after hooked module&#39;s</span>
<span class="sd">            :py:meth:`~torch.nn.Module.forward`. Defaults to ``None``.</span>
<span class="sd">        prehook_kwargs (dict[str, Any] | None, optional): keyword arguments passed to</span>
<span class="sd">            :py:meth:`~torch.nn.Module.register_forward_pre_hook`. Defaults to ``None``.</span>
<span class="sd">        posthook_kwargs (dict[str, Any] | None, optional): keyword arguments passed to</span>
<span class="sd">            :py:meth:`~torch.nn.Module.register_forward_hook`. Defaults to ``None``.</span>
<span class="sd">        train_update (bool, optional): if the hooks should be run when hooked module is</span>
<span class="sd">            in train mode. Defaults to ``True``.</span>
<span class="sd">        eval_update (bool, optional): if the hooks should be run when hooked module is</span>
<span class="sd">            in eval mode. Defaults to ``True``.</span>

<span class="sd">    Note:</span>
<span class="sd">        If not ``None``, the signature of the prehook must be of the following form.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            hook(module, args) -&gt; None or modified input</span>

<span class="sd">        Or, if ``with_kwargs`` is passed as a keyword argument.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            hook(module, args, kwargs) -&gt; None or modified input</span>

<span class="sd">        See :py:meth:`~torch.nn.Module.register_forward_pre_hook` for</span>
<span class="sd">        further information.</span>

<span class="sd">    Note:</span>
<span class="sd">        If not ``None``, the signature of the posthook must be of the following form.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            hook(module, args, output) -&gt; None or modified output</span>

<span class="sd">        Or, if ``with_kwargs`` is passed as a keyword argument.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            hook(module, args, kwargs, output) -&gt; None or modified output</span>

<span class="sd">        See :py:meth:`~torch.nn.Module.register_forward_hook` for further information.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: at least one of ``prehook`` and ``posthook`` must not be None.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">prehook</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posthook</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">prehook_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posthook_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">train_update</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">eval_update</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># check if at least one callable is defined</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">onedefined</span><span class="p">((</span><span class="s2">&quot;prehook&quot;</span><span class="p">,</span> <span class="n">prehook</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;posthook&quot;</span><span class="p">,</span> <span class="n">posthook</span><span class="p">))</span>

        <span class="c1"># prehook and posthook functions</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prehook</span><span class="p">,</span> <span class="n">Callable</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_prehook_call</span> <span class="o">=</span> <span class="n">prehook</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_prehook_call</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">posthook</span><span class="p">,</span> <span class="n">Callable</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_posthook_call</span> <span class="o">=</span> <span class="n">posthook</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_posthook_call</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># set returned handle</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__prehook_handle</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__posthook_handle</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># set hook registering kwargs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__prehook_kwargs</span> <span class="o">=</span> <span class="n">prehook_kwargs</span> <span class="k">if</span> <span class="n">prehook_kwargs</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__posthook_kwargs</span> <span class="o">=</span> <span class="n">posthook_kwargs</span> <span class="k">if</span> <span class="n">posthook_kwargs</span> <span class="k">else</span> <span class="p">{}</span>

        <span class="c1"># set training conditionals</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__call_train</span> <span class="o">=</span> <span class="n">train_update</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__call_eval</span> <span class="o">=</span> <span class="n">eval_update</span>

        <span class="c1"># finalizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__finalizer</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">__wrapped_prehook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainexec</span> <span class="ow">and</span> <span class="n">module</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prehook_call</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">evalexec</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">module</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prehook_call</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__wrapped_posthook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainexec</span> <span class="ow">and</span> <span class="n">module</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_posthook_call</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">evalexec</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">module</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_posthook_call</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">trainexec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;If the hook is called when the module passed in is in training mode.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (bool): if the hook should be called when the module is training.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool: if the hook is called when the module is training.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__call_train</span>

    <span class="nd">@trainexec</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">trainexec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__call_train</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">evalexec</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;If the hook is called when the module passed in is in evaluation mode.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (bool): if the hook should be called when the module is evaluating.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool: if the hook is called when the module is evaluating.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__call_eval</span>

    <span class="nd">@evalexec</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">evalexec</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__call_eval</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">registered</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;If there is a module to which this hook is registered</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool: if a module to which this hook is registred.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__prehook_handle</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">__posthook_handle</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

<div class="viewcode-block" id="Hook.register"><a class="viewcode-back" href="../../../reference/generated/inferno.Hook.html#inferno.Hook.register">[docs]</a>    <span class="k">def</span> <span class="nf">register</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registers the hook as a forward hook and/or prehook.</span>

<span class="sd">        Args:</span>
<span class="sd">            module (~torch.nn.Module): PyTorch module to which the forward hook</span>
<span class="sd">                will be registered.</span>

<span class="sd">        Raises:</span>
<span class="sd">            TypeError: parameter ``module`` must be an instance of</span>
<span class="sd">                :py:class:`~torch.nn.Module`.</span>

<span class="sd">        Warns:</span>
<span class="sd">            RuntimeWarning: each :py:class:`Hook` can only be registered to one</span>
<span class="sd">                :py:class:`~torch.nn.Module` and will ignore :py:meth:`register`</span>
<span class="sd">                if already registered.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">registered</span><span class="p">:</span>
            <span class="n">_</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">instance</span><span class="p">(</span><span class="s2">&quot;module&quot;</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prehook_call</span><span class="p">:</span>
                <span class="n">weakself</span> <span class="o">=</span> <span class="n">weakref</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__prehook_handle</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">register_forward_pre_hook</span><span class="p">(</span>
                    <span class="k">lambda</span> <span class="n">module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">weakself</span><span class="p">()</span><span class="o">.</span><span class="n">__wrapped_prehook</span><span class="p">(</span>
                        <span class="n">module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
                    <span class="p">),</span>
                    <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">__prehook_kwargs</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_posthook_call</span><span class="p">:</span>
                <span class="n">weakself</span> <span class="o">=</span> <span class="n">weakref</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__posthook_handle</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">register_forward_hook</span><span class="p">(</span>
                    <span class="k">lambda</span> <span class="n">module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">weakself</span><span class="p">()</span><span class="o">.</span><span class="n">__wrapped_posthook</span><span class="p">(</span>
                        <span class="n">module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
                    <span class="p">),</span>
                    <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">__posthook_kwargs</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__finalizer</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">__finalizer</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__finalizer</span> <span class="o">=</span> <span class="n">weakref</span><span class="o">.</span><span class="n">finalize</span><span class="p">(</span>
                <span class="bp">self</span><span class="p">,</span> <span class="n">_detach_handles</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__prehook_handle</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__posthook_handle</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;this </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> is already registered to a module &quot;</span>
                <span class="s2">&quot;so new register() was ignored&quot;</span>
            <span class="p">)</span></div>

<div class="viewcode-block" id="Hook.deregister"><a class="viewcode-back" href="../../../reference/generated/inferno.Hook.html#inferno.Hook.deregister">[docs]</a>    <span class="k">def</span> <span class="nf">deregister</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Deregisters the hook as a forward hook and/or prehook.</span>

<span class="sd">        If the :py:class:`Hook` is not registered, this is still safe to call.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_detach_handles</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">__prehook_handle</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">__posthook_handle</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__prehook_handle</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__posthook_handle</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">__finalizer</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__finalizer</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__finalizer</span> <span class="o">=</span> <span class="kc">None</span></div></div>


<div class="viewcode-block" id="ContextualHook"><a class="viewcode-back" href="../../../reference/generated/inferno.ContextualHook.html#inferno.ContextualHook">[docs]</a><span class="k">class</span> <span class="nc">ContextualHook</span><span class="p">(</span><span class="n">Hook</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Provides forward hook and prehook functionality for subclasses.</span>

<span class="sd">    This is used to manage references to the ``ContextualHook`` in a safe way for the</span>
<span class="sd">    garbage collector (i.e. without cyclic references).</span>

<span class="sd">    Args:</span>
<span class="sd">        prehook (str | None, optional): name of the prehook method, if any, to execute,</span>
<span class="sd">            no prehook when ``None``. Defaults to ``None``.</span>
<span class="sd">        posthook (str | None, optional): name of the posthook method, if any, to execute,</span>
<span class="sd">            no posthook when ``None``. Defaults to ``None``.</span>
<span class="sd">        prehook_kwargs (dict[str, Any] | None, optional): keyword arguments passed to</span>
<span class="sd">            :py:meth:`~torch.nn.Module.register_forward_pre_hook`. Defaults to ``None``.</span>
<span class="sd">        posthook_kwargs (dict[str, Any] | None, optional): keyword arguments passed to</span>
<span class="sd">            :py:meth:`~torch.nn.Module.register_forward_hook`. Defaults to ``None``.</span>
<span class="sd">        train_update (bool, optional): if the hooks should be run when hooked module is</span>
<span class="sd">            in train mode. Defaults to ``True``.</span>
<span class="sd">        eval_update (bool, optional): if the hooks should be run when hooked module is</span>
<span class="sd">            in eval mode. Defaults to ``True``.</span>

<span class="sd">    Raises:</span>
<span class="sd">        RuntimeError: at least one of ``prehook`` and ``posthook`` must not be None.</span>

<span class="sd">    Note:</span>
<span class="sd">        If not ``None``, the signature of the prehook must be of the following form.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            hook(module, args) -&gt; None or modified input</span>

<span class="sd">        Or, if ``with_kwargs`` is passed as a keyword argument.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            hook(module, args, kwargs) -&gt; None or modified input</span>

<span class="sd">        See :py:meth:`~torch.nn.Module.register_forward_pre_hook` for</span>
<span class="sd">        further information.</span>

<span class="sd">    Note:</span>
<span class="sd">        If not ``None``, the signature of the posthook must be of the following form.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            hook(module, args, output) -&gt; None or modified output</span>

<span class="sd">        Or, if ``with_kwargs`` is passed as a keyword argument.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            hook(module, args, kwargs, output) -&gt; None or modified output</span>

<span class="sd">        See :py:meth:`~torch.nn.Module.register_forward_hook` for further information.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">prehook</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posthook</span><span class="p">:</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">prehook_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">posthook_kwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">train_update</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">eval_update</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># check that something will occur on call</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">onedefined</span><span class="p">((</span><span class="s2">&quot;prehook&quot;</span><span class="p">,</span> <span class="n">prehook</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;posthook&quot;</span><span class="p">,</span> <span class="n">posthook</span><span class="p">))</span>

        <span class="c1"># weakly reference self for prehook</span>
        <span class="n">weakself_bfc</span> <span class="o">=</span> <span class="n">weakref</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">context_prehook</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="nb">getattr</span><span class="p">(</span><span class="n">weakself_bfc</span><span class="p">(),</span> <span class="n">prehook</span><span class="p">)(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># weakly reference self for posthook</span>
        <span class="n">weakself_afc</span> <span class="o">=</span> <span class="n">weakref</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">context_posthook</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="nb">getattr</span><span class="p">(</span><span class="n">weakself_afc</span><span class="p">(),</span> <span class="n">posthook</span><span class="p">)(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># call superclass constructor</span>
        <span class="n">Hook</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">prehook</span><span class="o">=</span><span class="n">context_prehook</span> <span class="k">if</span> <span class="n">prehook</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">posthook</span><span class="o">=</span><span class="n">context_posthook</span> <span class="k">if</span> <span class="n">posthook</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">prehook_kwargs</span><span class="o">=</span><span class="n">prehook_kwargs</span> <span class="k">if</span> <span class="n">prehook</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">posthook_kwargs</span><span class="o">=</span><span class="n">posthook_kwargs</span> <span class="k">if</span> <span class="n">posthook</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">train_update</span><span class="o">=</span><span class="n">train_update</span><span class="p">,</span>
            <span class="n">eval_update</span><span class="o">=</span><span class="n">eval_update</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="StateHook"><a class="viewcode-back" href="../../../reference/generated/inferno.StateHook.html#inferno.StateHook">[docs]</a><span class="k">class</span> <span class="nc">StateHook</span><span class="p">(</span><span class="n">Module</span><span class="p">,</span> <span class="n">ContextualHook</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Interactable hook which only acts on module state.</span>

<span class="sd">    Args:</span>
<span class="sd">        module (nn.Module): module to which the hook should be registered.</span>
<span class="sd">        train_update (bool, optional): if the hook should be run when hooked module is</span>
<span class="sd">            in train mode. Defaults to ``True``.</span>
<span class="sd">        eval_update (bool, optional): if the hook should be run when hooked module is</span>
<span class="sd">            in eval mode. Defaults to ``True``.</span>
<span class="sd">        as_prehook (bool, optional): if the hook should be run prior to the hooked</span>
<span class="sd">            module&#39;s :py:meth:`~torch.nn.Module.forward` call. Defaults to ``False``.</span>
<span class="sd">        prepend (bool, optional): if the hook should be run prior to the hooked</span>
<span class="sd">            module&#39;s previously registered forward hooks. Defaults to ``False``.</span>
<span class="sd">        always_call (bool, optional): if the hook should be run even if an exception</span>
<span class="sd">            occurs, only applies when ``as_prehook`` is ``False``. Defaults to ``False``.</span>

<span class="sd">    Note:</span>
<span class="sd">        To trigger the hook regardless of the hooked module&#39;s training state,</span>
<span class="sd">        call the ``StateHook`` object. The hook will not run if it is not registered.</span>

<span class="sd">    Note:</span>
<span class="sd">        Unlike with :py:class:`Hook`, the ``hook`` here will only be passed a single</span>
<span class="sd">        argument (the registered module itself) and any output will be ignored.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">train_update</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">eval_update</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">as_prehook</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">prepend</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">always_call</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># construct module superclass</span>
        <span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="c1"># subclass state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_hooked_module</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">instance</span><span class="p">(</span><span class="s2">&quot;module&quot;</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span>

        <span class="c1"># construct hook superclass</span>
        <span class="n">ContextualHook</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">prehook</span><span class="o">=</span><span class="s2">&quot;_StateHook__wrapped_hook&quot;</span> <span class="k">if</span> <span class="n">as_prehook</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">posthook</span><span class="o">=</span><span class="s2">&quot;_StateHook__wrapped_hook&quot;</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">as_prehook</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">prehook_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;prepend&quot;</span><span class="p">:</span> <span class="n">prepend</span><span class="p">},</span>
            <span class="n">posthook_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;prepend&quot;</span><span class="p">:</span> <span class="n">prepend</span><span class="p">,</span> <span class="s2">&quot;always_call&quot;</span><span class="p">:</span> <span class="n">always_call</span><span class="p">},</span>
            <span class="n">train_update</span><span class="o">=</span><span class="n">train_update</span><span class="p">,</span>
            <span class="n">eval_update</span><span class="o">=</span><span class="n">eval_update</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">__wrapped_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>

<div class="viewcode-block" id="StateHook.hook"><a class="viewcode-back" href="../../../reference/generated/inferno.StateHook.html#inferno.StateHook.hook">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Function to be called on the registered module&#39;s call.</span>

<span class="sd">        Args:</span>
<span class="sd">            module (nn.Module): registered module.</span>

<span class="sd">        Raises:</span>
<span class="sd">            NotImplementedError: ``hook`` must be implemented by the subclass.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(StateHook) must implement the method &#39;hook&#39;&quot;</span>
        <span class="p">)</span></div>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">module</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Module to which the hook is applied.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ~torch.nn.Module: module to which the hook is applied.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hooked_module</span>

<div class="viewcode-block" id="StateHook.register"><a class="viewcode-back" href="../../../reference/generated/inferno.StateHook.html#inferno.StateHook.register">[docs]</a>    <span class="k">def</span> <span class="nf">register</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registers state the hook as a forward hook or prehook.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">registered</span><span class="p">:</span>
            <span class="n">Hook</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">)</span></div>

<div class="viewcode-block" id="StateHook.forward"><a class="viewcode-back" href="../../../reference/generated/inferno.StateHook.html#inferno.StateHook.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">force</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">ignore_mode</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Executes the hook at any time, by default only when registered.</span>

<span class="sd">        Args:</span>
<span class="sd">            force (bool, optional): run the hook even if it is unregistered.</span>
<span class="sd">                Defaults to ``False``.</span>
<span class="sd">            ignore_mode (bool, optional): run the hook even if it the current mode</span>
<span class="sd">                would normally prevent execution. Defaults to ``False``.</span>

<span class="sd">        Note:</span>
<span class="sd">            This will respect if the hooked module, registered or not, is in</span>
<span class="sd">            training or evaluation mode (only relevant if manually configured).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">registered</span> <span class="ow">or</span> <span class="n">force</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ignore_mode</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">hook</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainexec</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">hook</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">)</span>
            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">evalexec</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">hook</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">)</span></div></div>
</pre></div>
        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, MD
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js?v=b3ba4146"></script>
    <script src="../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../../../_static/scripts/furo.js?v=32e29ea5"></script>
    <script src="../../../_static/design-tabs.js?v=36754332"></script>
    </body>
</html>