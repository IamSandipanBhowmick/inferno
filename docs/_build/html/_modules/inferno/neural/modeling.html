<!doctype html>
<html class="no-js" lang="en" data-content_root="../../../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" />

    <!-- Generated with Sphinx 7.2.6 and Furo 2023.09.10 -->
        <title>inferno.neural.modeling - Inferno</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=eafc0fe6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo-extensions.css?v=36a5483c" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/shape.css?v=23eccd26" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../index.html"><div class="brand">Inferno</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../../index.html">
  
  
  <span class="sidebar-brand-text">Inferno</span>
  
</a><form class="sidebar-search-container" method="get" action="../../../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../reference/index.html">API Reference</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of API Reference</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/inferno.html">inferno</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/neural.html">inferno.neural</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/neural-functional.html">inferno.neural.functional</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/learn.html">inferno.learn</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/learn-functional.html">inferno.learn.functional</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/observe.html">inferno.observe</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/infernotypes.html">inferno.infernotypes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/bounding.html">inferno.bounding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../reference/stats.html">inferno.stats</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../guide/index.html">Guidebook</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of Guidebook</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../guide/mathematics.html">Mathematical Notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../guide/neurons.html">Neurons and Neuronal Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../guide/considerations.html">Pragmatic Considerations</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../zoo/index.html">Model and Method Zoo</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Model and Method Zoo</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../zoo/neurons-adaptation.html">Neuronal Adaptation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../zoo/neurons-linear.html">Neuron Models, Linear</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../zoo/neurons-nonlinear.html">Neuron Models, Nonlinear</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../zoo/synapses-current.html">Synapse Models, Current-Based</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../zoo/synapses-conductance.html">Synapse Models, Conductance-Based</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../zoo/learning-stdp.html">STDP-Like Learning Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../zoo/learning-resume.html">ReSuMe-Like Learning Methods</a></li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <h1>Source code for inferno.neural.modeling</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">Connection</span><span class="p">,</span> <span class="n">Neuron</span><span class="p">,</span> <span class="n">Synapse</span>
<span class="kn">from</span> <span class="nn">.hooks</span> <span class="kn">import</span> <span class="n">Normalization</span><span class="p">,</span> <span class="n">Clamping</span>  <span class="c1"># noqa:F401; ignore, used for docs</span>
<span class="kn">from</span> <span class="nn">..</span> <span class="kn">import</span> <span class="n">Module</span>
<span class="kn">from</span> <span class="nn">..bounding</span> <span class="kn">import</span> <span class="n">HalfBounding</span><span class="p">,</span> <span class="n">FullBounding</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Iterable</span>
<span class="kn">import</span> <span class="nn">einops</span> <span class="k">as</span> <span class="nn">ein</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">inferno._internal</span> <span class="kn">import</span> <span class="n">argtest</span><span class="p">,</span> <span class="n">rgetattr</span><span class="p">,</span> <span class="n">Proxy</span>
<span class="kn">from</span> <span class="nn">inferno.observe</span> <span class="kn">import</span> <span class="n">ManagedMonitor</span><span class="p">,</span> <span class="n">MonitorConstructor</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Literal</span>


<div class="viewcode-block" id="Updater">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Updater.html#inferno.neural.Updater">[docs]</a>
<span class="k">class</span> <span class="nc">Updater</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Wraps a connection for updates and on-update hooks.</span>

<span class="sd">    This encloses a connection object and provides some top-level properties, for others</span>
<span class="sd">    the enclosed connection can be called through :py:attr:`connection`.</span>

<span class="sd">    Specifically, this is used to accumulate multiple updates through different</span>
<span class="sd">    trainers, perform any additional logic on the updates, the apply them. It also</span>
<span class="sd">    allows for hooks like :py:class:`Normalization` and :py:class:`Clamping` to be</span>
<span class="sd">    tied to updates rather than inference steps.</span>

<span class="sd">    Updaters should call the :py:meth:`update_weight`, :py:meth:`update_bias`, and</span>
<span class="sd">    :py:meth:`update_delay` functions to add their own updates. Hooks which target</span>
<span class="sd">    updates (such as bounding hooks) should target the properties ending in ``_update``.</span>
<span class="sd">    Once these are altered, no more updates can be accumulated until after the next call.</span>

<span class="sd">    The arguments ending in ``_reduction`` should have a signature as follows:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        reduction(input: torch.Tensor, dim: int) -&gt; torch.Tensor</span>

<span class="sd">    and examples include :py:func:`torch.mean`, :py:func:`torch.sum`,</span>
<span class="sd">    :py:func`torch.amin`, and :py:func`torch.amax`.</span>

<span class="sd">    The reduced potentiative updates are added to the value and the depressive updates</span>
<span class="sd">    are subtracted from the value.</span>

<span class="sd">    Args:</span>
<span class="sd">        connection (Connection): wrapped connection.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        weight_reduction (Callable[[torch.Tensor, int], torch.Tensor] | None, optional):</span>
<span class="sd">            function to reduce weights from multiple trainers. Defaults to None.</span>
<span class="sd">        bias_reduction (Callable[[torch.Tensor, int], torch.Tensor] | None, optional):</span>
<span class="sd">            function to reduce biases from multiple trainers. Defaults to None.</span>
<span class="sd">        delay_reduction (Callable[[torch.Tensor, int], torch.Tensor] | None, optional):</span>
<span class="sd">            function to reduce delays from multiple trainers. Defaults to None.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">connection</span><span class="p">:</span> <span class="n">Connection</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">weight_reduction</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">bias_reduction</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">delay_reduction</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># call superclass constructor</span>
        <span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="c1"># composed connection</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">connection_</span> <span class="o">=</span> <span class="n">connection</span>

        <span class="c1"># internal reduction functions</span>
        <span class="k">if</span> <span class="n">weight_reduction</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_reduction_</span> <span class="o">=</span> <span class="n">weight_reduction</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_reduction_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span>

        <span class="k">if</span> <span class="n">bias_reduction</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias_reduction_</span> <span class="o">=</span> <span class="n">bias_reduction</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bias_reduction_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span>

        <span class="k">if</span> <span class="n">delay_reduction</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">delay_reduction_</span> <span class="o">=</span> <span class="n">delay_reduction</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">delay_reduction_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span>

        <span class="c1"># internal update values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pos_weight_updates</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_pos_w_up&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_neg_weight_updates</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_neg_w_up&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_pos_bias_updates</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_pos_b_up&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_neg_bias_updates</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_neg_b_up&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_pos_delay_updates</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_pos_d_up&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_neg_delay_updates</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;_neg_d_up&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># parameter dependence</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weight_bounding_upper</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weight_bounding_lower</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weight_bounding</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">weight_reduction</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Reduction used for multiple weight updates, positive and negative.</span>

<span class="sd">        This function should have the following signature.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            reduction(input: torch.Tensor, dim: int) -&gt; torch.Tensor</span>

<span class="sd">        The argument ``dim`` can also take a tuple of integers as with most appropriate</span>
<span class="sd">        functions in PyTorch but is never given a tuple here. Dimensions reduced along</span>
<span class="sd">        should not be kept by default. Valid PyTorch functions include byt are not</span>
<span class="sd">        limited to :py:func:`torch.mean`, :py:func:`torch.sum`, :py:func`torch.amin`,</span>
<span class="sd">        and :py:func`torch.amax`.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (Callable[[torch.Tensor, int], torch.Tensor]): function for</span>
<span class="sd">                reducing weight updates.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Callable[[torch.Tensor, int], torch.Tensor]: function for reducing</span>
<span class="sd">            weight updates.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_reduction_</span>

    <span class="nd">@weight_reduction</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">weight_reduction</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_reduction_</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">bias_reduction</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Reduction used for multiple bias updates, positive and negative.</span>

<span class="sd">        This function should have the following signature.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            reduction(input: torch.Tensor, dim: int) -&gt; torch.Tensor</span>

<span class="sd">        The argument ``dim`` can also take a tuple of integers as with most appropriate</span>
<span class="sd">        functions in PyTorch but is never given a tuple here. Dimensions reduced along</span>
<span class="sd">        should not be kept by default. Valid PyTorch functions include byt are not</span>
<span class="sd">        limited to :py:func:`torch.mean`, :py:func:`torch.sum`, :py:func`torch.amin`,</span>
<span class="sd">        and :py:func`torch.amax`.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (Callable[[torch.Tensor, int], torch.Tensor]): function for</span>
<span class="sd">                reducing bias updates.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Callable[[torch.Tensor, int], torch.Tensor]: function for reducing</span>
<span class="sd">            bias updates.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias_reduction_</span>

    <span class="nd">@bias_reduction</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">bias_reduction</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias_reduction_</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">delay_reduction</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Reduction used for multiple delay updates, positive and negative.</span>

<span class="sd">        This function should have the following signature.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            reduction(input: torch.Tensor, dim: int) -&gt; torch.Tensor</span>

<span class="sd">        The argument ``dim`` can also take a tuple of integers as with most appropriate</span>
<span class="sd">        functions in PyTorch but is never given a tuple here. Dimensions reduced along</span>
<span class="sd">        should not be kept by default. Valid PyTorch functions include byt are not</span>
<span class="sd">        limited to :py:func:`torch.mean`, :py:func:`torch.sum`, :py:func`torch.amin`,</span>
<span class="sd">        and :py:func`torch.amax`.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (Callable[[torch.Tensor, int], torch.Tensor]): function for</span>
<span class="sd">                reducing delay updates.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Callable[[torch.Tensor, int], torch.Tensor]: function for reducing</span>
<span class="sd">            delay updates.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">delay_reduction_</span>

    <span class="nd">@delay_reduction</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">delay_reduction</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">delay_reduction_</span> <span class="o">=</span> <span class="n">value</span>

<div class="viewcode-block" id="Updater.weight_upper_bounding">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Updater.html#inferno.neural.Updater.weight_upper_bounding">[docs]</a>
    <span class="k">def</span> <span class="nf">weight_upper_bounding</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">bounding</span><span class="p">:</span> <span class="n">HalfBounding</span><span class="p">,</span>
        <span class="nb">max</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds upper bounding to weights.</span>

<span class="sd">        Args:</span>
<span class="sd">            bounding (HalfBounding): bounding function to use.</span>
<span class="sd">            max (float): upper bound of weights</span>
<span class="sd">            **kwargs (Any): passed as keyword arguments to ``bounding``.</span>

<span class="sd">        Note:</span>
<span class="sd">            This clears away anything set by :py:meth:`weight_bounding`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">weight_ub</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">bounding</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">limit</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_weight_bounding</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weight_bounding_upper</span> <span class="o">=</span> <span class="n">weight_ub</span></div>


<div class="viewcode-block" id="Updater.weight_lower_bounding">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Updater.html#inferno.neural.Updater.weight_lower_bounding">[docs]</a>
    <span class="k">def</span> <span class="nf">weight_lower_bounding</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">bounding</span><span class="p">:</span> <span class="n">HalfBounding</span><span class="p">,</span>
        <span class="nb">min</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds lower bounding to weights.</span>

<span class="sd">        Args:</span>
<span class="sd">            bounding (HalfBounding): bounding function to use.</span>
<span class="sd">            min (float): lower bound of weights</span>
<span class="sd">            **kwargs (Any): passed as keyword arguments to ``bounding``.</span>

<span class="sd">        Note:</span>
<span class="sd">            This clears away anything set by :py:meth:`weight_bounding`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">weight_lb</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">bounding</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">limit</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_weight_bounding</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weight_bounding_lower</span> <span class="o">=</span> <span class="n">weight_lb</span></div>


<div class="viewcode-block" id="Updater.weight_bounding">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Updater.html#inferno.neural.Updater.weight_bounding">[docs]</a>
    <span class="k">def</span> <span class="nf">weight_bounding</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">bounding</span><span class="p">:</span> <span class="n">FullBounding</span><span class="p">,</span>
        <span class="nb">max</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="nb">min</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds full bounding to weights.</span>

<span class="sd">        Args:</span>
<span class="sd">            bounding (FullBounding): bounding function to use.</span>
<span class="sd">            max (float): upper bound of weights.</span>
<span class="sd">            min (float): lower bound of weights</span>
<span class="sd">            **kwargs (Any): passed as keyword arguments to ``bounding``.</span>

<span class="sd">        Note:</span>
<span class="sd">            This clears away anything set by :py:meth:`weight_upper_bounding` and</span>
<span class="sd">            :py:meth:`weight_lower_bounding`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">weight_fb</span><span class="p">(</span>
            <span class="n">param</span><span class="p">,</span> <span class="n">pos_update</span><span class="p">,</span> <span class="n">neg_update</span><span class="p">,</span> <span class="n">max_limit</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span> <span class="n">min_limit</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="n">bounding</span><span class="p">(</span>
                <span class="n">param</span><span class="p">,</span> <span class="n">pos_update</span><span class="p">,</span> <span class="n">neg_update</span><span class="p">,</span> <span class="n">max_limit</span><span class="p">,</span> <span class="n">min_limit</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_weight_bounding_lower</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weight_bounding_upper</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_weight_bounding</span> <span class="o">=</span> <span class="n">weight_fb</span></div>


<div class="viewcode-block" id="Updater.bias_upper_bounding">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Updater.html#inferno.neural.Updater.bias_upper_bounding">[docs]</a>
    <span class="k">def</span> <span class="nf">bias_upper_bounding</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">bounding</span><span class="p">:</span> <span class="n">HalfBounding</span><span class="p">,</span>
        <span class="nb">max</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds upper bounding to biases.</span>

<span class="sd">        Args:</span>
<span class="sd">            bounding (HalfBounding): bounding function to use.</span>
<span class="sd">            max (float): upper bound of biases</span>
<span class="sd">            **kwargs (Any): passed as keyword arguments to ``bounding``.</span>

<span class="sd">        Note:</span>
<span class="sd">            This clears away anything set by :py:meth:`bias_bounding`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">bias_ub</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">bounding</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">limit</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_bias_bounding</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_bias_bounding_upper</span> <span class="o">=</span> <span class="n">bias_ub</span></div>


<div class="viewcode-block" id="Updater.bias_lower_bounding">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Updater.html#inferno.neural.Updater.bias_lower_bounding">[docs]</a>
    <span class="k">def</span> <span class="nf">bias_lower_bounding</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">bounding</span><span class="p">:</span> <span class="n">HalfBounding</span><span class="p">,</span>
        <span class="nb">min</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds lower bounding to biases.</span>

<span class="sd">        Args:</span>
<span class="sd">            bounding (HalfBounding): bounding function to use.</span>
<span class="sd">            min (float): lower bound of biases</span>
<span class="sd">            **kwargs (Any): passed as keyword arguments to ``bounding``.</span>

<span class="sd">        Note:</span>
<span class="sd">            This clears away anything set by :py:meth:`bias_bounding`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">bias_lb</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">bounding</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">limit</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_bias_bounding</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_bias_bounding_lower</span> <span class="o">=</span> <span class="n">bias_lb</span></div>


<div class="viewcode-block" id="Updater.bias_bounding">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Updater.html#inferno.neural.Updater.bias_bounding">[docs]</a>
    <span class="k">def</span> <span class="nf">bias_bounding</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">bounding</span><span class="p">:</span> <span class="n">FullBounding</span><span class="p">,</span>
        <span class="nb">max</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="nb">min</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds full bounding to biases.</span>

<span class="sd">        Args:</span>
<span class="sd">            bounding (FullBounding): bounding function to use.</span>
<span class="sd">            max (float): upper bound of biases.</span>
<span class="sd">            min (float): lower bound of biases</span>
<span class="sd">            **kwargs (Any): passed as keyword arguments to ``bounding``.</span>

<span class="sd">        Note:</span>
<span class="sd">            This clears away anything set by :py:meth:`bias_upper_bounding` and</span>
<span class="sd">            :py:meth:`bias_lower_bounding`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">bias_fb</span><span class="p">(</span>
            <span class="n">param</span><span class="p">,</span> <span class="n">pos_update</span><span class="p">,</span> <span class="n">neg_update</span><span class="p">,</span> <span class="n">max_limit</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span> <span class="n">min_limit</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="n">bounding</span><span class="p">(</span>
                <span class="n">param</span><span class="p">,</span> <span class="n">pos_update</span><span class="p">,</span> <span class="n">neg_update</span><span class="p">,</span> <span class="n">max_limit</span><span class="p">,</span> <span class="n">min_limit</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_bias_bounding_lower</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_bias_bounding_upper</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_bias_bounding</span> <span class="o">=</span> <span class="n">bias_fb</span></div>


<div class="viewcode-block" id="Updater.delay_upper_bounding">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Updater.html#inferno.neural.Updater.delay_upper_bounding">[docs]</a>
    <span class="k">def</span> <span class="nf">delay_upper_bounding</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">bounding</span><span class="p">:</span> <span class="n">HalfBounding</span><span class="p">,</span>
        <span class="nb">max</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds upper bounding to delays.</span>

<span class="sd">        Args:</span>
<span class="sd">            bounding (HalfBounding): bounding function to use.</span>
<span class="sd">            max (float): upper bound of delays</span>
<span class="sd">            **kwargs (Any): passed as keyword arguments to ``bounding``.</span>

<span class="sd">        Note:</span>
<span class="sd">            This clears away anything set by :py:meth:`delay_bounding`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">delay_ub</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">bounding</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">limit</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_delay_bounding</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_delay_bounding_upper</span> <span class="o">=</span> <span class="n">delay_ub</span></div>


<div class="viewcode-block" id="Updater.delay_lower_bounding">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Updater.html#inferno.neural.Updater.delay_lower_bounding">[docs]</a>
    <span class="k">def</span> <span class="nf">delay_lower_bounding</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">bounding</span><span class="p">:</span> <span class="n">HalfBounding</span><span class="p">,</span>
        <span class="nb">min</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds lower bounding to delays.</span>

<span class="sd">        Args:</span>
<span class="sd">            bounding (HalfBounding): bounding function to use.</span>
<span class="sd">            min (float): lower bound of delays</span>
<span class="sd">            **kwargs (Any): passed as keyword arguments to ``bounding``.</span>

<span class="sd">        Note:</span>
<span class="sd">            This clears away anything set by :py:meth:`delay_bounding`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">delay_lb</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">bounding</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">limit</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_delay_bounding</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_delay_bounding_lower</span> <span class="o">=</span> <span class="n">delay_lb</span></div>


<div class="viewcode-block" id="Updater.delay_bounding">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Updater.html#inferno.neural.Updater.delay_bounding">[docs]</a>
    <span class="k">def</span> <span class="nf">delay_bounding</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">bounding</span><span class="p">:</span> <span class="n">FullBounding</span><span class="p">,</span>
        <span class="nb">max</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="nb">min</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds full bounding to delays.</span>

<span class="sd">        Args:</span>
<span class="sd">            bounding (FullBounding): bounding function to use.</span>
<span class="sd">            max (float): upper bound of delays.</span>
<span class="sd">            min (float): lower bound of delays</span>
<span class="sd">            **kwargs (Any): passed as keyword arguments to ``bounding``.</span>

<span class="sd">        Note:</span>
<span class="sd">            This clears away anything set by :py:meth:`delay_upper_bounding` and</span>
<span class="sd">            :py:meth:`delay_lower_bounding`.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">delay_fb</span><span class="p">(</span>
            <span class="n">param</span><span class="p">,</span> <span class="n">pos_update</span><span class="p">,</span> <span class="n">neg_update</span><span class="p">,</span> <span class="n">max_limit</span><span class="o">=</span><span class="nb">max</span><span class="p">,</span> <span class="n">min_limit</span><span class="o">=</span><span class="nb">min</span><span class="p">,</span> <span class="n">kwargs</span><span class="o">=</span><span class="n">kwargs</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="n">bounding</span><span class="p">(</span>
                <span class="n">param</span><span class="p">,</span> <span class="n">pos_update</span><span class="p">,</span> <span class="n">neg_update</span><span class="p">,</span> <span class="n">max_limit</span><span class="p">,</span> <span class="n">min_limit</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_delay_bounding_lower</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_delay_bounding_upper</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_delay_bounding</span> <span class="o">=</span> <span class="n">delay_fb</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">pos_weight_update</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Positive component of weight updates.</span>

<span class="sd">        If this value hasn&#39;t been overridden with a setter call, it will reduce the</span>
<span class="sd">        stored updates and return that. Otherwise it will return the value used to</span>
<span class="sd">        override. This is reset upon applying updates.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (torch.Tensor): overwrite value of positive weight updates.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | None: current positive weight updates.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos_w_up</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_reduction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos_weight_updates</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos_w_up</span>

    <span class="nd">@pos_weight_update</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">pos_weight_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pos_w_up</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">neg_weight_update</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Negative component of weight updates.</span>

<span class="sd">        If this value hasn&#39;t been overridden with a setter call, it will reduce the</span>
<span class="sd">        stored updates and return that. Otherwise it will return the value used to</span>
<span class="sd">        override. This is reset upon applying updates.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (torch.Tensor): overwrite value of negative weight updates.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | None: current positive negative updates.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_neg_w_up</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_reduction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_neg_weight_updates</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_neg_w_up</span>

    <span class="nd">@neg_weight_update</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">neg_weight_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_neg_w_up</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">pos_bias_update</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Positive component of bias updates.</span>

<span class="sd">        If this value hasn&#39;t been overridden with a setter call, it will reduce the</span>
<span class="sd">        stored updates and return that. Otherwise it will return the value used to</span>
<span class="sd">        override. This is reset upon applying updates.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (torch.Tensor): overwrite value of positive bias updates.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | None: current positive bias updates.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos_b_up</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_reduction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos_bias_updates</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos_b_up</span>

    <span class="nd">@pos_bias_update</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">pos_bias_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pos_b_up</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">neg_bias_update</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Negative component of bias updates.</span>

<span class="sd">        If this value hasn&#39;t been overridden with a setter call, it will reduce the</span>
<span class="sd">        stored updates and return that. Otherwise it will return the value used to</span>
<span class="sd">        override. This is reset upon applying updates.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (torch.Tensor): overwrite value of negative bias updates.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | None: current positive negative updates.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_neg_b_up</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bias_reduction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_neg_bias_updates</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_neg_b_up</span>

    <span class="nd">@neg_bias_update</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">neg_bias_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_neg_b_up</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">pos_delay_update</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Positive component of delay updates.</span>

<span class="sd">        If this value hasn&#39;t been overridden with a setter call, it will reduce the</span>
<span class="sd">        stored updates and return that. Otherwise it will return the value used to</span>
<span class="sd">        override. This is reset upon applying updates.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (torch.Tensor): overwrite value of positive delay updates.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | None: current positive delay updates.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos_d_up</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delay_reduction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos_delay_updates</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos_d_up</span>

    <span class="nd">@pos_delay_update</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">pos_delay_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pos_d_up</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">neg_delay_update</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Negative component of delay updates.</span>

<span class="sd">        If this value hasn&#39;t been overridden with a setter call, it will reduce the</span>
<span class="sd">        stored updates and return that. Otherwise it will return the value used to</span>
<span class="sd">        override. This is reset upon applying updates.</span>

<span class="sd">        Args:</span>
<span class="sd">            value (torch.Tensor): overwrite value of negative delay updates.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | None: current positive negative updates.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_neg_d_up</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">delay_reduction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_neg_delay_updates</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_neg_d_up</span>

    <span class="nd">@neg_delay_update</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">neg_delay_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_neg_d_up</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">connection</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Connection</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Connection submodule.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Connection: existing connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">connection_</span>

    <span class="k">def</span> <span class="nf">_add_update</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">update</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">,</span> <span class="n">store</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Module Internal: adds update tensor to an update store.</span>

<span class="sd">        Args:</span>
<span class="sd">            update (torch.Tensor | nn.Parameter): tensor containing the update.</span>
<span class="sd">            store (nn.ParameterList): store the update is added to.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">update</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">):</span>
            <span class="n">store</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">update</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">store</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">update</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="n">update</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_get_update</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">reduction</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">store</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Module Internal: reduces and retrieves an update.</span>

<span class="sd">        Args:</span>
<span class="sd">            reduction (Callable[[torch.Tensor, int], torch.Tensor]):</span>
<span class="sd">            store (nn.ParameterList): store the update is retrieved from.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: updates stacked and reduced.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">store</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">reduction</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="o">*</span><span class="n">store</span><span class="p">],</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

<div class="viewcode-block" id="Updater.weight_update">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Updater.html#inferno.neural.Updater.weight_update">[docs]</a>
    <span class="k">def</span> <span class="nf">weight_update</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">pos_update</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="n">neg_update</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds weight update terms.</span>

<span class="sd">        The weight updates are applied in the following manner.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            weight = weight + pos_update - neg_update</span>

<span class="sd">        Args:</span>
<span class="sd">            pos_update (torch.Tensor | None): positive weight update component.</span>
<span class="sd">            neg_update (torch.Tensor | None): negative weight update component.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">pos_update</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_add_update</span><span class="p">(</span><span class="n">pos_update</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos_weight_updates</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">neg_update</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_add_update</span><span class="p">(</span><span class="n">neg_update</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_neg_weight_updates</span><span class="p">)</span></div>


<div class="viewcode-block" id="Updater.bias_update">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Updater.html#inferno.neural.Updater.bias_update">[docs]</a>
    <span class="k">def</span> <span class="nf">bias_update</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">pos_update</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="n">neg_update</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds bias update terms.</span>

<span class="sd">        The bias updates are applied in the following manner.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            bias = bias + pos_update - neg_update</span>

<span class="sd">        Args:</span>
<span class="sd">            pos_update (torch.Tensor | None): positive bias update component.</span>
<span class="sd">            neg_update (torch.Tensor | None): negative bias update component.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">pos_update</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_add_update</span><span class="p">(</span><span class="n">pos_update</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos_bias_updates</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">neg_update</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_add_update</span><span class="p">(</span><span class="n">neg_update</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_neg_bias_updates</span><span class="p">)</span></div>


<div class="viewcode-block" id="Updater.delay_update">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Updater.html#inferno.neural.Updater.delay_update">[docs]</a>
    <span class="k">def</span> <span class="nf">delay_update</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">pos_update</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="n">neg_update</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds delay update terms.</span>

<span class="sd">        The delay updates are applied in the following manner.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            delay = delay + pos_update - neg_update</span>

<span class="sd">        Args:</span>
<span class="sd">            pos_update (torch.Tensor | None): positive delay update component.</span>
<span class="sd">            neg_update (torch.Tensor | None): negative delay update component.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">pos_update</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_add_update</span><span class="p">(</span><span class="n">pos_update</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pos_delay_updates</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">neg_update</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_add_update</span><span class="p">(</span><span class="n">neg_update</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_neg_delay_updates</span><span class="p">)</span></div>


<div class="viewcode-block" id="Updater.forward">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Updater.html#inferno.neural.Updater.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Applies stored updates and resets for the next set.</span>

<span class="sd">        Note:</span>
<span class="sd">            This does not check if a connection has a trainable bias or trainable delay</span>
<span class="sd">            before performing the update. If the updates are not manually set nor added</span>
<span class="sd">            by a trainer, this behaves normally. If they are, the included connections</span>
<span class="sd">            will silently not update parameters they don&#39;t have, but this isn&#39;t</span>
<span class="sd">            guaranteed behavior for 3rd party ones.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># weight updates</span>
        <span class="n">w_pos</span><span class="p">,</span> <span class="n">w_neg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_weight_update</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">neg_weight_update</span>
        <span class="k">if</span> <span class="n">w_pos</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">w_neg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">w_pos</span><span class="p">,</span> <span class="n">w_neg</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">w_pos</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">w_pos</span><span class="p">,</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">w_neg</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">w_neg</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">connection</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">connection</span><span class="o">.</span><span class="n">weight</span> <span class="o">+</span> <span class="n">w_pos</span> <span class="o">-</span> <span class="n">w_neg</span>

        <span class="c1"># bias updates</span>
        <span class="n">b_pos</span><span class="p">,</span> <span class="n">b_neg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_bias_update</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">neg_bias_update</span>
        <span class="k">if</span> <span class="n">b_pos</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">b_neg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">b_pos</span><span class="p">,</span> <span class="n">b_neg</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">b_pos</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">b_pos</span><span class="p">,</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">b_neg</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">b_neg</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">connection</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">connection</span><span class="o">.</span><span class="n">bias</span> <span class="o">+</span> <span class="n">b_pos</span> <span class="o">-</span> <span class="n">b_neg</span>

        <span class="c1"># delay updates</span>
        <span class="n">d_pos</span><span class="p">,</span> <span class="n">d_neg</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_delay_update</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">neg_delay_update</span>
        <span class="k">if</span> <span class="n">d_pos</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">d_neg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">d_pos</span><span class="p">,</span> <span class="n">d_neg</span> <span class="o">=</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">d_pos</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">d_pos</span><span class="p">,</span> <span class="mi">0</span> <span class="k">if</span> <span class="n">d_neg</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">d_neg</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">connection</span><span class="o">.</span><span class="n">delay</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">connection</span><span class="o">.</span><span class="n">delay</span> <span class="o">+</span> <span class="n">d_pos</span> <span class="o">-</span> <span class="n">d_neg</span>

        <span class="c1"># wipes internal state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pos_weight_updates</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pos_w_up</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_neg_weight_updates</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_neg_w_up</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_pos_bias_updates</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pos_b_up</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_neg_bias_updates</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_neg_b_up</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_pos_delay_updates</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pos_d_up</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_neg_delay_updates</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_neg_d_up</span> <span class="o">=</span> <span class="kc">None</span></div>
</div>



<div class="viewcode-block" id="Trainable">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Trainable.html#inferno.neural.Trainable">[docs]</a>
<span class="k">class</span> <span class="nc">Trainable</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;A trainable connection-neuron pair.</span>

<span class="sd">    Generally, objects of this class should never be constructed by the</span>
<span class="sd">    end-user directly unless they are creating a new class like :py:class:`Layer`</span>
<span class="sd">    which does not subclass it.</span>

<span class="sd">    This is a construct used to associate a single connection and neuron object</span>
<span class="sd">    for the purposes of training. The contained connection may produce output for</span>
<span class="sd">    multiple neurons and the neuron may take input from multiple connections.</span>

<span class="sd">    When implementing a new updater, the properties here should be used when</span>
<span class="sd">    accessing or alering the model parameters.</span>

<span class="sd">    If the connection is passed without being wrapped in an updater, it will be</span>
<span class="sd">    wrapped in an updater with the default constructor arguments.</span>

<span class="sd">    Args:</span>
<span class="sd">        connection (Updater | Connection): connection which produces output for the</span>
<span class="sd">            neuron, optionally wrapped in an updater.</span>
<span class="sd">        neuron (Neuron): neuron which takes output from the connection.</span>
<span class="sd">        add_monitor_callback (Callable | None, optional): layer callback for</span>
<span class="sd">            adding a monitor from this trainable. Defaults to None.</span>
<span class="sd">        del_monitor_callback (Callable | None, optional): layer callback for</span>
<span class="sd">            deleting a monitor from this trainable. Defaults to None.</span>

<span class="sd">    Note:</span>
<span class="sd">        The callbacks supplied are done so by :py:class:`Layer`. In general, these</span>
<span class="sd">        should not be supplied by the user. If required, see the implementation of</span>
<span class="sd">        :py:meth:`Layer.add_input` or :py:meth:`Layer.add_output` for the signature.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">connection</span><span class="p">:</span> <span class="n">Updater</span> <span class="o">|</span> <span class="n">Connection</span><span class="p">,</span>
        <span class="n">neuron</span><span class="p">:</span> <span class="n">Neuron</span><span class="p">,</span>
        <span class="n">add_monitor_callback</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">del_monitor_callback</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># call superclass constructor</span>
        <span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="c1"># component elements</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">connection</span><span class="p">,</span> <span class="n">Updater</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">updater_</span> <span class="o">=</span> <span class="n">Updater</span><span class="p">(</span><span class="n">connection</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">updater_</span> <span class="o">=</span> <span class="n">connection</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neuron_</span> <span class="o">=</span> <span class="n">neuron</span>

        <span class="c1"># callbacks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_add_monitor_callback</span> <span class="o">=</span> <span class="n">add_monitor_callback</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_del_monitor_callback</span> <span class="o">=</span> <span class="n">del_monitor_callback</span>

        <span class="c1"># reserve state for trainers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer_state_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">()</span>

<div class="viewcode-block" id="Trainable.trainer_state">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Trainable.html#inferno.neural.Trainable.trainer_state">[docs]</a>
    <span class="k">def</span> <span class="nf">trainer_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Module</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds or retrieves trainer state module.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str): name of the trainer.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Module: module containing trainer state</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer_state_</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer_state_</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">Module</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer_state_</span><span class="p">[</span><span class="n">name</span><span class="p">]</span></div>


<div class="viewcode-block" id="Trainable.del_trainer_state">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Trainable.html#inferno.neural.Trainable.del_trainer_state">[docs]</a>
    <span class="k">def</span> <span class="nf">del_trainer_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Deletes trainer state if it exists.</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str): name of the trainer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer_state_</span><span class="p">:</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer_state_</span><span class="p">[</span><span class="n">name</span><span class="p">]</span></div>


<div class="viewcode-block" id="Trainable.add_monitor">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Trainable.html#inferno.neural.Trainable.add_monitor">[docs]</a>
    <span class="k">def</span> <span class="nf">add_monitor</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">caller</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">attr</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">monitor</span><span class="p">:</span> <span class="n">MonitorConstructor</span><span class="p">,</span>
        <span class="n">unpooled</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ManagedMonitor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds a managed monitor associated with a trainer.</span>

<span class="sd">        This works in conjunction with :py:class:`Layer` to ensure that the added</span>
<span class="sd">        monitors are not duplicated if it is unneeded. This non-duplication is only</span>
<span class="sd">        enforced across a single layer and single trainer.</span>

<span class="sd">        For example, if a layer goes from two connections to one neuron, and both</span>
<span class="sd">        resultant trainables are trained with the same trainer, both monitors have</span>
<span class="sd">        equivalent attribute chains (defined by ``attr``), and the same name as</span>
<span class="sd">        defined by ``name``, then rather than creating a new monitor, the existing one</span>
<span class="sd">        will be returned.</span>

<span class="sd">        The check of if two trainers are the same is based on the string passed as</span>
<span class="sd">        ``caller``. Trainers should take this as a constructor argument, and as such,</span>
<span class="sd">        it is possible to share monitors across trainers. This behavior is dangerous</span>
<span class="sd">        and should only be done if it can be ensured this will not cause issues.</span>

<span class="sd">        Because of this, ``name`` must also capture any information which may be unique</span>
<span class="sd">        to a specific trainable.</span>

<span class="sd">        All monitor&#39;s added this way will be added to the lifecycle of the ``Layer``</span>
<span class="sd">        which created them.</span>

<span class="sd">        Args:</span>
<span class="sd">            caller (str): instance-name of the trainer which will use the monitor.</span>
<span class="sd">            name (str): name of the monitor to add.</span>
<span class="sd">            attr (str): dot-seperated attribute path, relative to this trainable, to</span>
<span class="sd">                monitor.</span>
<span class="sd">            monitor (MonitorConstructor): partial constructor for the monitor to add.</span>
<span class="sd">            unpooled (bool): if the monitor should not be aliased from the pool</span>
<span class="sd">                regardless. Defaults to False.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: attribute must be a member of this trainable.</span>
<span class="sd">            RuntimeError: &#39;updater.connection&#39; is the only valid head of the attribute</span>
<span class="sd">                chain starting with &#39;updater&#39;.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ManagedMonitor: added monitor.</span>

<span class="sd">        Tip:</span>
<span class="sd">            If the monitor&#39;s behavior for the targeted attribute may vary with</span>
<span class="sd">            hyperparameters or other configuration state, ``unpooled`` should be</span>
<span class="sd">            set to ``True``. This does not keep this monitor from being aliased however,</span>
<span class="sd">            so the setting of ``unpooled`` should be consistent across all monitors</span>
<span class="sd">            with the same name.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># check that the attribute is a valid dot-chain identifier</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">nestedidentifier</span><span class="p">(</span><span class="s2">&quot;attr&quot;</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span>

        <span class="c1"># split the identifier and check for ownership</span>
        <span class="n">attrchain</span> <span class="o">=</span> <span class="n">attr</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>

        <span class="c1"># ensure the top-level attribute is in this trainable</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attrchain</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;this trainable does not have an attribute &#39;</span><span class="si">{</span><span class="n">attrchain</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&#39;&quot;</span>
            <span class="p">)</span>

        <span class="c1"># remap the top-level target if pointing to a private attribute</span>
        <span class="n">attrchain</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;updater_&quot;</span><span class="p">:</span> <span class="s2">&quot;updater&quot;</span><span class="p">,</span>
            <span class="s2">&quot;neuron_&quot;</span><span class="p">:</span> <span class="s2">&quot;neuron&quot;</span><span class="p">,</span>
        <span class="p">}</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">attrchain</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">attrchain</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># special case targeting updater</span>
        <span class="k">if</span> <span class="n">attrchain</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;updater&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">attrchain</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;&#39;updater&#39; itself cannot be the target for monitoring&quot;</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">attrchain</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;connection&quot;</span><span class="p">,</span> <span class="s2">&quot;connection_&quot;</span><span class="p">):</span>
                <span class="n">attrchain</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;connection&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">attrchain</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;only &#39;connection&#39; is a valid subtarget of &#39;updater&#39;&quot;</span>
                <span class="p">)</span>

        <span class="c1"># test against Inferno-defined alias attributes</span>
        <span class="n">attrsub</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;synapse&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;connection&quot;</span><span class="p">,</span> <span class="s2">&quot;synapse&quot;</span><span class="p">],</span>
            <span class="s2">&quot;precurrent&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;connection&quot;</span><span class="p">,</span> <span class="s2">&quot;syncurrent&quot;</span><span class="p">],</span>
            <span class="s2">&quot;prespike&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;connection&quot;</span><span class="p">,</span> <span class="s2">&quot;synspike&quot;</span><span class="p">],</span>
            <span class="s2">&quot;postvoltage&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;neuron&quot;</span><span class="p">,</span> <span class="s2">&quot;voltage&quot;</span><span class="p">],</span>
            <span class="s2">&quot;postspike&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;neuron&quot;</span><span class="p">,</span> <span class="s2">&quot;spike&quot;</span><span class="p">],</span>
        <span class="p">}</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">attrchain</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="n">attrchain</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
        <span class="n">attrchain</span> <span class="o">=</span> <span class="n">attrsub</span> <span class="o">+</span> <span class="n">attrchain</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>

        <span class="c1"># split the chain into target and attribute</span>
        <span class="k">if</span> <span class="n">unpooled</span><span class="p">:</span>
            <span class="n">target</span><span class="p">,</span> <span class="n">attr</span> <span class="o">=</span> <span class="s2">&quot;trainable&quot;</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">attrchain</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">match</span> <span class="n">attrchain</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="k">case</span> <span class="s2">&quot;connection&quot;</span><span class="p">:</span>
                    <span class="n">target</span><span class="p">,</span> <span class="n">attr</span> <span class="o">=</span> <span class="s2">&quot;connection&quot;</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">attrchain</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
                <span class="k">case</span> <span class="s2">&quot;neuron&quot;</span><span class="p">:</span>
                    <span class="n">target</span><span class="p">,</span> <span class="n">attr</span> <span class="o">=</span> <span class="s2">&quot;neuron&quot;</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">attrchain</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
                <span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>
                    <span class="n">target</span><span class="p">,</span> <span class="n">attr</span> <span class="o">=</span> <span class="s2">&quot;trainable&quot;</span><span class="p">,</span> <span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">attrchain</span><span class="p">)</span>

        <span class="c1"># use layer callback to add the monitor to its pool and return</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_monitor_callback</span><span class="p">(</span><span class="n">caller</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">monitor</span><span class="p">)</span></div>


<div class="viewcode-block" id="Trainable.del_monitor">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Trainable.html#inferno.neural.Trainable.del_monitor">[docs]</a>
    <span class="k">def</span> <span class="nf">del_monitor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">caller</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Deletes a managed monitor associated with a trainer.</span>

<span class="sd">        This &quot;frees&quot; a monitor from the enclosing :py:class:`Layer` that is associated</span>
<span class="sd">        with this trainable.</span>

<span class="sd">        Args:</span>
<span class="sd">            caller (str): instance-name of the trainer which is associated with</span>
<span class="sd">                the monitor.</span>
<span class="sd">            name (str): name of the monitor to remove.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_del_monitor_callback</span><span class="p">(</span><span class="n">caller</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">updater</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Updater</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Updater submodule.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Updater: composed updater.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">updater_</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">connection</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Connection</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Connection submodule.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Connection: composed connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">updater</span><span class="o">.</span><span class="n">connection</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">neuron</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Neuron</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Neuron submodule.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Neuron: composed neuron.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">neuron_</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">synapse</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Synapse</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Synapse submodule.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Synapse: composed synapse.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">connection</span><span class="o">.</span><span class="n">synapse</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">precurrent</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Currents from the synapse at the time last used by the connection.</span>

<span class="sd">        Alias for ``connection.syncurrent``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: delay-offset synaptic currents.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">connection</span><span class="o">.</span><span class="n">syncurrent</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">prespike</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Spikes to the synapse at the time last used by the connection.</span>

<span class="sd">        Alias for ``connection.synspike``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: delay-offset synaptic spikes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">connection</span><span class="o">.</span><span class="n">synspike</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">postvoltage</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Membrane voltages in millivolts.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: membrane voltages.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">neuron</span><span class="o">.</span><span class="n">voltage</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">postspike</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Action potentials last generated.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor: membrane voltages.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">neuron</span><span class="o">.</span><span class="n">spike</span>

<div class="viewcode-block" id="Trainable.forward">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Trainable.html#inferno.neural.Trainable.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward call.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: Trainable cannot have its forward method called.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;&#39;forward&#39; method of </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(Trainable) cannot be called&quot;</span>
        <span class="p">)</span></div>
</div>



<div class="viewcode-block" id="Layer">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Layer.html#inferno.neural.Layer">[docs]</a>
<span class="k">class</span> <span class="nc">Layer</span><span class="p">(</span><span class="n">Module</span><span class="p">,</span> <span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Representation of simultaneously processed connections and neurons.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># call superclass constructor</span>
        <span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="c1"># inner modules</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">updaters_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neurons_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainables_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">()</span>

<div class="viewcode-block" id="Layer.add_input">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Layer.html#inferno.neural.Layer.add_input">[docs]</a>
    <span class="k">def</span> <span class="nf">add_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">module</span><span class="p">:</span> <span class="n">Updater</span> <span class="o">|</span> <span class="n">Connection</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Updater</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds a module that receives input from outside the layer.</span>

<span class="sd">        This registers either a :py:class:`Connection` or :py:class:`Updater` as a</span>
<span class="sd">        module that receives input from outside of the layer. If the module given is</span>
<span class="sd">        not an ``Updater``, this will wrap it in one before registering. This will be</span>
<span class="sd">        visible to PyTorch as a submodule.</span>

<span class="sd">        This can be accessed later as an ``Updater`` via :py:attr:`updaters`,</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            layer.updaters.name</span>

<span class="sd">        a ``Connection`` via :py:attr:`connections`,</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            layer.connections.name</span>

<span class="sd">        or a ``Synapse`` via :py:attr:`synapses`.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            layer.synapses.name</span>

<span class="sd">        Any :py:class:`Trainable` objects are also constructed from this input to all</span>
<span class="sd">        existing outputs. For each output with name ``output_name``, it can be accessed</span>
<span class="sd">        via :py:attr:`trainables` as follows.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            layer.trainables.name.output_name</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str): attribute name of the module receiving input from</span>
<span class="sd">                outside the layer.</span>
<span class="sd">            module (Updater | Connection): module which receives the input and</span>
<span class="sd">                generates intermediate output.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: the name must be unique amongst added inputs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Updater: added input module.</span>

<span class="sd">        Tip:</span>
<span class="sd">            If an input module is to be added to multiple :py:class:`Layer` objects,</span>
<span class="sd">            then it should be passed to all of them as the same ``Updater`` object.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># test that the name is a valid identifier</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">identifier</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>

        <span class="c1"># check that the name is not taken</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">updaters_</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;name&#39; (&#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;) already assigned to an input&quot;</span><span class="p">)</span>

        <span class="c1"># wraps connection if it is not an updater and assigns</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">Updater</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">updaters_</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">Updater</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">updaters_</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">module</span>

        <span class="c1"># automatically add trainables</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainables_</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;name&#39; (&#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;) already a first-order trainable key&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainables_</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">oname</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">neurons_</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">trainables_</span><span class="p">[</span><span class="n">name</span><span class="p">][</span><span class="n">oname</span><span class="p">]</span> <span class="o">=</span> <span class="n">Trainable</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">updaters_</span><span class="p">[</span><span class="n">name</span><span class="p">],</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">neurons_</span><span class="p">[</span><span class="n">oname</span><span class="p">],</span>
                    <span class="n">partial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_add_monitor</span><span class="p">,</span> <span class="n">inputn</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">outputn</span><span class="o">=</span><span class="n">oname</span><span class="p">),</span>
                    <span class="n">partial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_del_monitor</span><span class="p">,</span> <span class="n">inputn</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">outputn</span><span class="o">=</span><span class="n">oname</span><span class="p">),</span>
                <span class="p">)</span>

        <span class="c1"># return assigned value</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">updaters_</span><span class="p">[</span><span class="n">name</span><span class="p">]</span></div>


<div class="viewcode-block" id="Layer.add_output">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Layer.html#inferno.neural.Layer.add_output">[docs]</a>
    <span class="k">def</span> <span class="nf">add_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">module</span><span class="p">:</span> <span class="n">Neuron</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Neuron</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Adds a module that generates output from input modules.</span>

<span class="sd">        This registers a :py:class:`Neuron` as a module that receives intermediate</span>
<span class="sd">        input and will generate output external to the layer. This will be visible to</span>
<span class="sd">        PyTorch as a submodule.</span>


<span class="sd">        This can be accessed later as a ``Neuron`` via :py:attr:`neurons`.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            layer.neurons.name</span>

<span class="sd">        Args:</span>
<span class="sd">            name (str): attribute name of the module generating output to</span>
<span class="sd">                outside the layer.</span>
<span class="sd">            module (Neuron): module which receives intermediate output and generates</span>
<span class="sd">                the final output.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: the name must be unique amongst added outputs.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Neuron: added output module.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># test that the name is a valid identifier</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">argtest</span><span class="o">.</span><span class="n">identifier</span><span class="p">(</span><span class="s2">&quot;name&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>

        <span class="c1"># check that the name is not taken</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">neurons_</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;name&#39; (&#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;) already assigned to an output&quot;</span><span class="p">)</span>

        <span class="c1"># assigns value</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neurons_</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">module</span>

        <span class="c1"># automatically add trainables</span>
        <span class="k">for</span> <span class="n">iname</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">updaters_</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainables_</span><span class="p">[</span><span class="n">iname</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;&#39;name&#39; (&#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;) already a second-order trainable key in &#39;</span><span class="si">{</span><span class="n">iname</span><span class="si">}</span><span class="s2">&#39;&quot;</span>
                <span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">trainables_</span><span class="p">[</span><span class="n">iname</span><span class="p">][</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">Trainable</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">updaters_</span><span class="p">[</span><span class="n">iname</span><span class="p">],</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">neurons_</span><span class="p">[</span><span class="n">name</span><span class="p">],</span>
                    <span class="n">partial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_add_monitor</span><span class="p">,</span> <span class="n">inputn</span><span class="o">=</span><span class="n">iname</span><span class="p">,</span> <span class="n">outputn</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
                    <span class="n">partial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_del_monitor</span><span class="p">,</span> <span class="n">inputn</span><span class="o">=</span><span class="n">iname</span><span class="p">,</span> <span class="n">outputn</span><span class="o">=</span><span class="n">name</span><span class="p">),</span>
                <span class="p">)</span>

        <span class="c1"># return assigned value</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">neurons_</span><span class="p">[</span><span class="n">name</span><span class="p">]</span></div>


    <span class="k">def</span> <span class="nf">_add_monitor</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pool</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">target</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">attr</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">monitor</span><span class="p">:</span> <span class="n">MonitorConstructor</span><span class="p">,</span>
        <span class="n">inputn</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">outputn</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ManagedMonitor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Used as a callback to add monitors from a Trainable.</span>

<span class="sd">        This will create a monitor if it doesn&#39;t exist, otherwise it will create a</span>
<span class="sd">        reference to the existing monitor and return it.</span>

<span class="sd">        Args:</span>
<span class="sd">            pool (str): name of the pool to which the monitor will be added.</span>
<span class="sd">            name (str): name of the monitor.</span>
<span class="sd">            target (str): shorthand for the top-level attribute being targeted.</span>
<span class="sd">            attr (str): dot-seperated attribute to monitor.</span>
<span class="sd">            monitor (MonitorConstructor): partial constructor for managed monitor.</span>
<span class="sd">            inputn (str): name of the associated input.</span>
<span class="sd">            outputn (str): name of the associated output.</span>

<span class="sd">        Returns:</span>
<span class="sd">            ManagedMonitor: created or retrieved monitor.</span>

<span class="sd">        Note:</span>
<span class="sd">            Valid targets are &quot;neuron&quot; (with alias &quot;output&quot;), &quot;connection&quot; (with alias</span>
<span class="sd">            &quot;input&quot;), and &quot;trainable&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># check if input and output names exist</span>
        <span class="k">if</span> <span class="n">inputn</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">innames</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;input name (&#39;</span><span class="si">{</span><span class="n">inputn</span><span class="si">}</span><span class="s2">&#39;) is not an added input&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">outputn</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">outnames</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;output name (&#39;</span><span class="si">{</span><span class="n">outputn</span><span class="si">}</span><span class="s2">&#39;) is not an added output&quot;</span><span class="p">)</span>

        <span class="c1"># create the pool if it doesn&#39;t exist</span>
        <span class="k">if</span> <span class="n">pool</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">()</span>

        <span class="c1"># create input group if it doesn&#39;t exist</span>
        <span class="k">if</span> <span class="n">inputn</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">()</span>

        <span class="c1"># create input group if it doesn&#39;t exist</span>
        <span class="k">if</span> <span class="n">outputn</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">][</span><span class="n">outputn</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">()</span>

        <span class="c1"># alias the monitor</span>
        <span class="k">match</span> <span class="n">target</span><span class="p">:</span>

            <span class="k">case</span> <span class="s2">&quot;neuron&quot;</span> <span class="o">|</span> <span class="s2">&quot;output&quot;</span><span class="p">:</span>
                <span class="c1"># set correct attribute relative to the layer</span>
                <span class="n">attr</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;updaters_.connection.</span><span class="si">{</span><span class="n">outputn</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">attr</span><span class="si">}</span><span class="s2">&quot;</span>

                <span class="c1"># alias the monitor if it does not exist</span>
                <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">][</span><span class="n">outputn</span><span class="p">]:</span>
                    <span class="k">for</span> <span class="n">inkey</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">]:</span>
                        <span class="k">if</span> <span class="p">(</span>
                            <span class="n">outputn</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inkey</span><span class="p">]</span>
                            <span class="ow">and</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inkey</span><span class="p">][</span><span class="n">outputn</span><span class="p">]</span>
                        <span class="p">):</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">][</span><span class="n">outputn</span><span class="p">][</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inkey</span><span class="p">][</span><span class="n">outputn</span><span class="p">][</span><span class="n">name</span><span class="p">]</span>
                            <span class="p">)</span>
                            <span class="k">break</span>

            <span class="k">case</span> <span class="s2">&quot;connection&quot;</span> <span class="o">|</span> <span class="s2">&quot;input&quot;</span><span class="p">:</span>
                <span class="c1"># set correct attribute relative to the layer</span>
                <span class="n">attr</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;neurons_.</span><span class="si">{</span><span class="n">inputn</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">attr</span><span class="si">}</span><span class="s2">&quot;</span>

                <span class="c1"># alias the monitor if it does not exist</span>
                <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">][</span><span class="n">outputn</span><span class="p">]:</span>
                    <span class="k">for</span> <span class="n">outkey</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">]:</span>
                        <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">][</span><span class="n">outkey</span><span class="p">]:</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">][</span><span class="n">outputn</span><span class="p">][</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">][</span><span class="n">outkey</span><span class="p">][</span><span class="n">name</span><span class="p">]</span>
                            <span class="p">)</span>
                            <span class="k">break</span>

            <span class="k">case</span> <span class="s2">&quot;trainable&quot;</span><span class="p">:</span>
                <span class="c1"># set correct attribute relative to the layer</span>
                <span class="n">attr</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;trainables_.</span><span class="si">{</span><span class="n">inputn</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">outputn</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">attr</span><span class="si">}</span><span class="s2">&quot;</span>

            <span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;invalid &#39;target&#39; (&#39;</span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2">&#39;) specified, expected one of: &quot;</span>
                    <span class="s2">&quot;&#39;neuron&#39;, &#39;connection&#39;, &#39;trainable&#39;&quot;</span>
                <span class="p">)</span>

        <span class="c1"># create the monitor if it does not exist and could not be aliased</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">][</span><span class="n">outputn</span><span class="p">]:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">][</span><span class="n">outputn</span><span class="p">][</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">monitor</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span>

        <span class="c1"># return the monitor</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">][</span><span class="n">outputn</span><span class="p">][</span><span class="n">name</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_del_monitor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pool</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">inputn</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">outputn</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Used as a callback to free monitors from a Trainable.</span>

<span class="sd">        This will only delete the alias associated with that :py:class:`Trainable`.</span>
<span class="sd">        If the monitor has been aliased, that alias will persist and be accessible</span>
<span class="sd">        as normal.</span>

<span class="sd">        Args:</span>
<span class="sd">            pool (str): name of the pool to which the monitor will be added.</span>
<span class="sd">            name (str): name of the monitor.</span>
<span class="sd">            inputn (str): name of the associated input.</span>
<span class="sd">            outputn (str): name of the associated output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># check if the pool exists</span>
        <span class="k">if</span> <span class="n">pool</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">:</span>

            <span class="c1"># check if the input exists</span>
            <span class="k">if</span> <span class="n">inputn</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">]:</span>

                <span class="c1"># check if the output exists</span>
                <span class="k">if</span> <span class="n">outputn</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">]:</span>

                    <span class="c1"># delete the monitor if it exists</span>
                    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">][</span><span class="n">outputn</span><span class="p">]:</span>
                        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">][</span><span class="n">outputn</span><span class="p">][</span><span class="n">name</span><span class="p">]</span>

                    <span class="c1"># delete output container if empty</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">][</span><span class="n">outputn</span><span class="p">]):</span>
                        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">][</span><span class="n">outputn</span><span class="p">]</span>

                <span class="c1"># delete input container if empty</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">]):</span>
                    <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">][</span><span class="n">inputn</span><span class="p">]</span>

            <span class="c1"># delete pool container if empty</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">]):</span>
                <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitors_</span><span class="p">[</span><span class="n">pool</span><span class="p">]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">innames</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registered input names.</span>

<span class="sd">        Yields:</span>
<span class="sd">            str: name of a registered input.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">updaters_</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">outnames</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registered output names.</span>

<span class="sd">        Yields:</span>
<span class="sd">            str: name of a registered output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">neurons_</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">connections</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Proxy</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registred connections.</span>

<span class="sd">        For a given ``name`` registered with :py:meth:`add_input`, its corresponding</span>
<span class="sd">        :py:class:`Connection` can be accessed as.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            layer.connections.name</span>

<span class="sd">        And is equivalent to the following.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            layer.updaters.name.connection</span>

<span class="sd">        It can be modified in-place (including setting other attributes, adding</span>
<span class="sd">        monitors, etc), but it can neither be deleted nor reassigned.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Proxy: safe access to registered connections.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">Proxy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">updaters_</span><span class="p">,</span> <span class="s2">&quot;connection&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">named_connections</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Connection</span><span class="p">]]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Iterable of registered connections and their names.</span>

<span class="sd">        Yields:</span>
<span class="sd">            tuple[str, Connection]: tuple of a registered connection and its name.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">connection</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">updaters_</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">neurons</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Proxy</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registred neurons.</span>

<span class="sd">        For a given ``name`` registered with :py:meth:`add_output`, its corresponding</span>
<span class="sd">        :py:class:`Neuron` can be accessed as.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            layer.neurons.name</span>

<span class="sd">        It can be modified in-place (including setting other attributes, adding</span>
<span class="sd">        monitors, etc), but it can neither be deleted nor reassigned.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Proxy: safe access to registered neurons.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">Proxy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">neurons_</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">named_neurons</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Neuron</span><span class="p">]]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Iterable of registered neurons and their names.</span>

<span class="sd">        Yields:</span>
<span class="sd">            tuple[str, Neuron]: tuple of a registered neuron and its name.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">neurons_</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">synapses</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Proxy</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registred synapses.</span>

<span class="sd">        For a given ``name`` registered with :py:meth:`add_input`, its corresponding</span>
<span class="sd">        :py:class:`Synapse` can be accessed as.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            layer.synapses.name</span>

<span class="sd">        And is equivalent to the following.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            layer.updaters.name.connection.synapse</span>

<span class="sd">        It can be modified in-place (including setting other attributes, adding</span>
<span class="sd">        monitors, etc), but it can neither be deleted nor reassigned.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Proxy: safe access to registered synapses.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">Proxy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">updaters_</span><span class="p">,</span> <span class="s2">&quot;connection.synapse&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">named_synapses</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Synapse</span><span class="p">]]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Iterable of registered synapses and their names.</span>

<span class="sd">        Yields:</span>
<span class="sd">            tuple[str, Synapse]: tuple of a registered synapse and its name.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">connection</span><span class="o">.</span><span class="n">synapse</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">updaters_</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">trainables</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Proxy</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registered trainables.</span>

<span class="sd">        For a given ``input_name`` and ``output_name``, its corresponding</span>
<span class="sd">        :py:class:`Trainable` can be accessed as.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            layer.trainables.input_name.output_name</span>

<span class="sd">        Returns:</span>
<span class="sd">            Proxy: _description_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">Proxy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainables_</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">named_trainables</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">Trainable</span><span class="p">]]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Iterable of registered trainables and tuples of the input and output name.</span>

<span class="sd">        Yields:</span>
<span class="sd">            tuple[tuple[str, str], torch.Tensor]: tuple of a registered connection and</span>
<span class="sd">            a tuple of the input name and output name corresponding to it.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">connection</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">updaters_</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">updaters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Proxy</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registred updaters.</span>

<span class="sd">        For a given ``name`` registered with :py:meth:`add_input`, its corresponding</span>
<span class="sd">        :py:class:`Updater` can be accessed as.</span>

<span class="sd">        .. code-block:: python</span>

<span class="sd">            layer.updaters.name</span>

<span class="sd">        It can be modified in-place (including setting other attributes, adding</span>
<span class="sd">        monitors, etc), but it can neither be deleted nor reassigned.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Proxy: safe access to registered synapses.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">Proxy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">updaters_</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">named_updaters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Updater</span><span class="p">]]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Iterable of registered updaters and their names.</span>

<span class="sd">        Yields:</span>
<span class="sd">            tuple[str, Updater]: tuple of a registered updater and its name.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">updaters_</span><span class="o">.</span><span class="n">items</span><span class="p">())</span>

<div class="viewcode-block" id="Layer.wiring">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Layer.html#inferno.neural.Layer.wiring">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">wiring</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Connection logic between connection outputs and neuron inputs.</span>

<span class="sd">        The inputs are given as a dictionary where each key is a registered input name</span>
<span class="sd">        and the value is the tensor output from that connection. This is expected to</span>
<span class="sd">        return a dictionary where each key is the name of a registered output and the</span>
<span class="sd">        value is the tensor to be passed to its :py:meth:`~torch.nn.Module.__call__`.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (dict[str, torch.Tensor]): dictionary of input names to tensors.</span>

<span class="sd">        Raises:</span>
<span class="sd">            NotImplementedError: ``wiring`` must be implemented by the subclass.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict[str, torch.Tensor]: dictionary of output names to tensors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(Layer) must implement &quot;</span> <span class="s2">&quot;the method `wiring`.&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Layer.update">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Layer.html#inferno.neural.Layer.update">[docs]</a>
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Applies all cumulative updates.</span>

<span class="sd">        This calls every updated which applies cumulative updates and any updater</span>
<span class="sd">        hooks are automatically called (e.g. parameter clamping).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">updater</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">updaters_</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">updater</span><span class="p">()</span></div>


<div class="viewcode-block" id="Layer.forward">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Layer.html#inferno.neural.Layer.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]],</span>
        <span class="n">inkwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">outkwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">capture_intermediate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span>
        <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
        <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes a forward pass.</span>

<span class="sd">        The keys for ``inputs`` and ``inkwargs`` are the names of registered</span>
<span class="sd">        :py:class:`Updater` objects correspond to elements in :py:attr`innames`.</span>
<span class="sd">        The keys for ``outkwargs`` are the names of the registered :py:class`Neuron`</span>
<span class="sd">        objects and correspond to elements in :py:attr:`outnames`.</span>

<span class="sd">        Underlying :py:class:`Connection` and :py:class:`Neuron` objects are called</span>
<span class="sd">        using :py:meth:`~torch.nn.Module.__call__`, which in turn call</span>
<span class="sd">        :py:meth:`Connection.forward` and :py:meth:`Neuron.forward` respectively.</span>
<span class="sd">        The keyword argument dictionaries will be unpacked for each call automatically,</span>
<span class="sd">        and the inputs will be unpacked as positional arguments for each call.</span>

<span class="sd">        Only input modules which have keys in ``inputs`` will be run and added to</span>
<span class="sd">        the positional argument of :py:meth:`wiring`.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (dict[str, tuple[torch.Tensor, ...]]): inputs passed to the</span>
<span class="sd">                registered connections&#39; forward calls.</span>
<span class="sd">            inkwargs (dict[str, dict[str, Any]] | None, optional): keyword arguments</span>
<span class="sd">                passed to registered connections&#39; forward calls. Defaults to None.</span>
<span class="sd">            outkwargs (dict[str, dict[str, Any]] | None, optional): keyword arguments</span>
<span class="sd">                passed to registered neurons&#39; forward calls. Defaults to None.</span>
<span class="sd">            capture_intermediate (bool, optional): if output from the connections should</span>
<span class="sd">                also be returned. Defaults to False.</span>
<span class="sd">            **kwargs (Any): keyword arguments passed to :py:meth:`wiring`.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict[str, torch.Tensor] | tuple[dict[str, torch.Tensor], dict[str, torch.Tensor]]:</span>
<span class="sd">            tensors from neurons and the associated neuron names, if ``capture_intermediate``,</span>
<span class="sd">            this is the second element of a tuple, the first being a tuple of tensors from</span>
<span class="sd">            connections and the associated connection names.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># replace none with empty dictionaries</span>
        <span class="n">inkwargs</span> <span class="o">=</span> <span class="n">inkwargs</span> <span class="k">if</span> <span class="n">inkwargs</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="n">outkwargs</span> <span class="o">=</span> <span class="n">outkwargs</span> <span class="k">if</span> <span class="n">outkwargs</span> <span class="k">else</span> <span class="p">{}</span>

        <span class="c1"># get connection outputs</span>
        <span class="n">res</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">k</span><span class="p">:</span> <span class="n">rgetattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">updaters_</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">.connection&quot;</span><span class="p">)(</span><span class="o">*</span><span class="n">v</span><span class="p">,</span> <span class="o">**</span><span class="n">inkwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="p">{}))</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="n">capture_intermediate</span><span class="p">:</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wiring</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">k</span><span class="p">:</span> <span class="n">rgetattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">neurons_</span><span class="p">,</span> <span class="n">k</span><span class="p">)(</span><span class="o">*</span><span class="n">v</span><span class="p">,</span> <span class="o">**</span><span class="n">outkwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="p">{}))</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">outputs</span>
            <span class="p">}</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">res</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">wiring</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">res</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">k</span><span class="p">:</span> <span class="n">rgetattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">neurons_</span><span class="p">,</span> <span class="n">k</span><span class="p">)(</span><span class="o">*</span><span class="n">v</span><span class="p">,</span> <span class="o">**</span><span class="n">outkwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="p">{}))</span>
                <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">res</span>
            <span class="p">}</span>
            <span class="k">return</span> <span class="n">res</span></div>
</div>



<div class="viewcode-block" id="Biclique">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Biclique.html#inferno.neural.Biclique">[docs]</a>
<span class="k">class</span> <span class="nc">Biclique</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Layer structured as a complete bipartite graph.</span>

<span class="sd">    Each input is processed by its corresponding connection, with an optional</span>
<span class="sd">    transformation applied, before being combined with the results of all other</span>
<span class="sd">    connections. These are then, for each group of neurons, optionally transformed</span>
<span class="sd">    and then passed in.</span>

<span class="sd">    Each element of ``inputs`` and ``outputs`` must be a tuple with at least two</span>
<span class="sd">    elements and at most three. The first of these is a name, which must be a</span>
<span class="sd">    Python identifier and unique to the set of inputs or outputs respectively. The</span>
<span class="sd">    second is the module representing the input or output</span>
<span class="sd">    (:py:class:`Updater`/:py:class:`Connection` or :py:class:`Neuron` respectively).</span>
<span class="sd">    The third is optionally a function which takes a :py:class`~torch.Tensor` and</span>
<span class="sd">    returns a ``Tensor``. This will be applied to the output of, or input to, the</span>
<span class="sd">    modules, respectively. This may be used, for example, to reshape or pad a tensor.</span>

<span class="sd">    Either a function to combine the tensors from the modules in ``inputs`` to be passed</span>
<span class="sd">    into ``outputs`` or a string literal may be provided. These may be &quot;sum&quot;, &quot;mean&quot;,</span>
<span class="sd">    &quot;prod&quot;, &quot;min&quot;, &quot;max&quot;, or &quot;stack&quot;. All except for &quot;stack&quot; use ``einops`` to reduce</span>
<span class="sd">    them, &quot;stack&quot; will stack the tensors along a new final dimension. When providing</span>
<span class="sd">    a function, it must take a tuple of tensors (equal to the number of inputs) and</span>
<span class="sd">    produce a single tensor output.</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs (tuple[tuple[str, Updater | Connection] | tuple[str, Updater | Connection, Callable[[torch.Tensor], torch.Tensor]], ...]):</span>
<span class="sd">            modules which receive inputs given to the layer.</span>
<span class="sd">        outputs (tuple[tuple[str, Neuron] | tuple[str, Neuron, Callable[[torch.Tensor], torch.Tensor]], ...]):</span>
<span class="sd">            modules which produce output from the layer.</span>
<span class="sd">        combine (Callable[[dict[str, torch.Tensor]], torch.Tensor] | Literal[&quot;stack&quot;, &quot;sum&quot;, &quot;mean&quot;, &quot;prod&quot;, &quot;min&quot;, &quot;max&quot;], optional):</span>
<span class="sd">            function to combine tensors from inputs into a single tensor for ouputs.</span>
<span class="sd">            Defaults to &quot;stack&quot;.</span>

<span class="sd">    Caution:</span>
<span class="sd">        When a string literal is used as an argument for ``combine``, especially</span>
<span class="sd">        important when using ``stack``, the tensors are used in &quot;insertion order&quot; based</span>
<span class="sd">        on the dictionary passed into ``inputs`` in :py:meth:`Layer.forward`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span>
            <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Updater</span> <span class="o">|</span> <span class="n">Connection</span><span class="p">]</span>
            <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Updater</span> <span class="o">|</span> <span class="n">Connection</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
            <span class="o">...</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span>
            <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Neuron</span><span class="p">]</span>
            <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Neuron</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
            <span class="o">...</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="n">combine</span><span class="p">:</span> <span class="p">(</span>
            <span class="n">Callable</span><span class="p">[[</span><span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
            <span class="o">|</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;stack&quot;</span><span class="p">,</span> <span class="s2">&quot;sum&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;prod&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">]</span>
        <span class="p">)</span> <span class="o">=</span> <span class="s2">&quot;stack&quot;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># superclass constructor</span>
        <span class="n">Layer</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="c1"># callables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">post_input</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_output</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">match</span> <span class="p">(</span><span class="n">combine</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">combine</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">combine</span><span class="p">):</span>
            <span class="k">case</span> <span class="s2">&quot;stack&quot;</span><span class="p">:</span>

                <span class="k">def</span> <span class="nf">combinefn</span><span class="p">(</span><span class="n">tensors</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">tensors</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_combine</span> <span class="o">=</span> <span class="n">combinefn</span>

            <span class="k">case</span> <span class="s2">&quot;sum&quot;</span> <span class="o">|</span> <span class="s2">&quot;mean&quot;</span> <span class="o">|</span> <span class="s2">&quot;prod&quot;</span> <span class="o">|</span> <span class="s2">&quot;min&quot;</span> <span class="o">|</span> <span class="s2">&quot;max&quot;</span><span class="p">:</span>

                <span class="k">def</span> <span class="nf">combinefn</span><span class="p">(</span><span class="n">tensors</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">ein</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span>
                        <span class="nb">list</span><span class="p">(</span><span class="n">tensors</span><span class="o">.</span><span class="n">values</span><span class="p">()),</span> <span class="s2">&quot;s ... -&gt; () ...&quot;</span><span class="p">,</span> <span class="n">combine</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
                    <span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_combine</span> <span class="o">=</span> <span class="n">combinefn</span>

            <span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">combine</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;&#39;combine&#39; (&#39;</span><span class="si">{</span><span class="n">combine</span><span class="si">}</span><span class="s2">&#39;), when a string, must be one of: &quot;</span>
                        <span class="s2">&quot;&#39;stack&#39;, &#39;sum&#39;, &#39;mean&#39;, &#39;prod&#39;, &#39;min&#39;, &#39;max&#39;&quot;</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_combine</span> <span class="o">=</span> <span class="n">combine</span>

        <span class="c1"># add inputs</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">input_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
            <span class="k">match</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="nb">input</span><span class="k">_</span><span class="p">):</span>
                <span class="k">case</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="n">Layer</span><span class="o">.</span><span class="n">add_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">input_</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">post_input</span><span class="p">[</span><span class="n">input_</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span>
                <span class="k">case</span> <span class="mi">3</span><span class="p">:</span>
                    <span class="n">Layer</span><span class="o">.</span><span class="n">add_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">input_</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">post_input</span><span class="p">[</span><span class="n">input_</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">input_</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
                <span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;element at position </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> in &#39;inputs&#39; has invalid &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;number of elements </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

        <span class="c1"># add outputs</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">output_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">outputs</span><span class="p">):</span>
            <span class="k">match</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">output</span><span class="k">_</span><span class="p">):</span>
                <span class="k">case</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="n">Layer</span><span class="o">.</span><span class="n">add_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">output_</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">pre_output</span><span class="p">[</span><span class="n">output_</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span>
                <span class="k">case</span> <span class="mi">3</span><span class="p">:</span>
                    <span class="n">Layer</span><span class="o">.</span><span class="n">add_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">output_</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">pre_output</span><span class="p">[</span><span class="n">output_</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">output_</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
                <span class="k">case</span><span class="w"> </span><span class="k">_</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;element at position </span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2"> in &#39;outputs&#39; has invalid &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot;number of elements </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">output_</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

<div class="viewcode-block" id="Biclique.add_input">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Biclique.html#inferno.neural.Biclique.add_input">[docs]</a>
    <span class="k">def</span> <span class="nf">add_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Overrides function to add inputs.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: inputs for a biclique layer are fixed on construction.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;&#39;add_input&#39; of </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(Biclique) cannot be called.&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Biclique.add_output">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Biclique.html#inferno.neural.Biclique.add_output">[docs]</a>
    <span class="k">def</span> <span class="nf">add_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Overrides function to add outputs.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: outputs for a biclique layer are fixed on construction.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;&#39;add_output&#39; of </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(Biclique) cannot be called.&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Biclique.wiring">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Biclique.html#inferno.neural.Biclique.wiring">[docs]</a>
    <span class="k">def</span> <span class="nf">wiring</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Connection logic between connection outputs and neuron inputs.</span>

<span class="sd">        This implements the forward logic of the biclique topology where the tensors</span>
<span class="sd">        from the inputs are transformed, combined, and transformed again before</span>
<span class="sd">        being passed to the outputs. Transforms which were unspecified are assumed to</span>
<span class="sd">        be identity.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (dict[str, torch.Tensor]): dictionary of input names to tensors.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict[str, torch.Tensor]: dictionary of output names to tensors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_combine</span><span class="p">({</span><span class="n">k</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">post_input</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">()}))</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_output</span>
        <span class="p">}</span></div>
</div>



<div class="viewcode-block" id="Serial">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Serial.html#inferno.neural.Serial">[docs]</a>
<span class="k">class</span> <span class="nc">Serial</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Layer with a single connection and single neuron group.</span>

<span class="sd">    This wraps :py:class:`Layer` to provid</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs (Updater | Connection): module which receives input to the layer.</span>
<span class="sd">        outputs (Neuron): module which generates output from the layer.</span>
<span class="sd">        transform (Callable[[torch.Tensor], torch.Tensor] | None, optional): function</span>
<span class="sd">            to apply to connection output before passing into neurons. Defaults to None.</span>

<span class="sd">    Note:</span>
<span class="sd">        When ``transform`` is not specified, the identity function is used.</span>

<span class="sd">    Note:</span>
<span class="sd">        The :py:class:`Layer` object underlying a ``Serial`` object has the input</span>
<span class="sd">        and output (:py:class`Connection`/py:class:`Updater` and :py:class:`Neuron`</span>
<span class="sd">        respectively) registered with the name &quot;main&quot;.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Updater</span> <span class="o">|</span> <span class="n">Connection</span><span class="p">,</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="n">Neuron</span><span class="p">,</span>
        <span class="n">transform</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;_summary_</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (Updater | Connection): _description_</span>
<span class="sd">            outputs (Neuron): _description_</span>
<span class="sd">            transform (Callable[[torch.Tensor], torch.Tensor] | None, optional): _description_. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            _type_: _description_</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># call superclass constructor</span>
        <span class="n">Layer</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="c1"># add connection and neuron</span>
        <span class="n">Layer</span><span class="o">.</span><span class="n">add_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;main&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
        <span class="n">Layer</span><span class="o">.</span><span class="n">add_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;main&quot;</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>

        <span class="c1"># set transformation used</span>
        <span class="k">if</span> <span class="n">transform</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_transform</span> <span class="o">=</span> <span class="n">transform</span>
        <span class="k">else</span><span class="p">:</span>

            <span class="k">def</span> <span class="nf">transfn</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">tensor</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_transform</span> <span class="o">=</span> <span class="n">transfn</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">connection</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Connection</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registered connection.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Connection: registered connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">connections</span><span class="o">.</span><span class="n">main</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">neuron</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Neuron</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registered neuron.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Neuron: registered neuron.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">neuron</span><span class="o">.</span><span class="n">main</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">synapse</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Synapse</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registered synapse.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Synapse: registered synapse.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">synapse</span><span class="o">.</span><span class="n">main</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">trainable</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Trainable</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registered trainable.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Trainable: registered trainable.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable</span><span class="o">.</span><span class="n">main</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">updater</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Updater</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Registered updater.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Updater: registered updater.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">updater</span><span class="o">.</span><span class="n">main</span>

<div class="viewcode-block" id="Serial.add_input">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Serial.html#inferno.neural.Serial.add_input">[docs]</a>
    <span class="k">def</span> <span class="nf">add_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Overrides function to add inputs.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: inputs for a serial layer are fixed on construction.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;&#39;add_input&#39; of </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(Serial) cannot be called.&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Serial.add_output">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Serial.html#inferno.neural.Serial.add_output">[docs]</a>
    <span class="k">def</span> <span class="nf">add_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Overrides function to add outputs.</span>

<span class="sd">        Raises:</span>
<span class="sd">            RuntimeError: outputs for a serial layer are fixed on construction.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;&#39;add_output&#39; of </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(Serial) cannot be called.&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="Serial.wiring">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Serial.html#inferno.neural.Serial.wiring">[docs]</a>
    <span class="k">def</span> <span class="nf">wiring</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Connection logic between connection outputs and neuron inputs.</span>

<span class="sd">        This implements the forward logic of the serial topology. The ``transform`` is</span>
<span class="sd">        applied to the result of the connection before being passed to the neuron. If</span>
<span class="sd">        not specified, it is assumed to be identity.</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs (dict[str, torch.Tensor]): dictionary of input names to tensors.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict[str, torch.Tensor]: dictionary of output names to tensors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;main&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transform</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;main&quot;</span><span class="p">])}</span></div>


<div class="viewcode-block" id="Serial.forward">
<a class="viewcode-back" href="../../../reference/generated/inferno.neural.Serial.html#inferno.neural.Serial.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="n">inputs</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">inkwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">outkwargs</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">capture_intermediate</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">|</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Computes a forward pass.</span>

<span class="sd">        Args:</span>
<span class="sd">            *inputs (torch.Tensor): values passed to the connection.</span>
<span class="sd">            inkwargs (dict[str, dict[str, Any]] | None, optional): keyword arguments</span>
<span class="sd">                for the connection&#39;s forward call. Defaults to None.</span>
<span class="sd">            outkwargs (dict[str, dict[str, Any]] | None, optional): keyword arguments</span>
<span class="sd">                for the neuron&#39;s forward call. Defaults to None.</span>
<span class="sd">            capture_intermediate (bool, optional): if output from the connections should</span>
<span class="sd">                also be returned. Defaults to False.</span>

<span class="sd">        Returns:</span>
<span class="sd">            torch.Tensor | tuple[torch.Tensor, torch.Tensor]: output from the neurons,</span>
<span class="sd">            if ``capture_intermediate``, this is th second element of a tuple, the first</span>
<span class="sd">            being the output from the connection.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># call parent forward</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">Layer</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="p">{</span><span class="s2">&quot;main&quot;</span><span class="p">:</span> <span class="n">inputs</span><span class="p">},</span>
            <span class="n">inkwargs</span><span class="o">=</span><span class="n">inkwargs</span><span class="p">,</span>
            <span class="n">outkwargs</span><span class="o">=</span><span class="n">outkwargs</span><span class="p">,</span>
            <span class="n">capture_intermediate</span><span class="o">=</span><span class="n">capture_intermediate</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># unpack to sensible output</span>
        <span class="k">if</span> <span class="n">capture_intermediate</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;main&quot;</span><span class="p">],</span> <span class="n">res</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s2">&quot;main&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">res</span><span class="p">[</span><span class="s2">&quot;main&quot;</span><span class="p">]</span></div>
</div>

</pre></div>
        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, MD
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../../_static/doctools.js?v=888ff710"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/scripts/furo.js?v=32e29ea5"></script>
    <script src="../../../_static/design-tabs.js?v=36754332"></script>
    </body>
</html>